{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72fa882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc, pickle, datetime, scipy.sparse,random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from colorama import Fore, Back, Style\n",
    "\n",
    "from sklearn.model_selection import GroupKFold,train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD,PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import seaborn as sns\n",
    "from cycler import cycler\n",
    "from IPython.display import display\n",
    "\n",
    "import scipy.sparse\n",
    "\n",
    "DATA_DIR = \"./\"\n",
    "FP_CELL_METADATA = os.path.join(DATA_DIR,\"metadata.csv\")\n",
    "\n",
    "FP_CITE_TRAIN_INPUTS = os.path.join(DATA_DIR,\"train_cite_inputs.h5\")\n",
    "FP_CITE_TRAIN_TARGETS = os.path.join(DATA_DIR,\"train_cite_targets.h5\")\n",
    "FP_CITE_TEST_INPUTS = os.path.join(DATA_DIR,\"test_cite_inputs.h5\")\n",
    "\n",
    "FP_SUBMISSION = os.path.join(DATA_DIR,\"sample_submission.csv\")\n",
    "FP_EVALUATION_IDS = os.path.join(DATA_DIR,\"evaluation_ids.csv\")\n",
    "\n",
    "VERBOSE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83ebdf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37334300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_tensorflow(seed=1):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61e1f2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant cols: 1194\n",
      "important columns  84\n"
     ]
    }
   ],
   "source": [
    "# constant_cols = list(X.columns[(X == 0).all(axis=0).values]) + list(X_test.columns[(X_test == 0).all(axis=0).values])\n",
    "constant_cols = ['ENSG00000003137_CYP26B1', 'ENSG00000004848_ARX', 'ENSG00000006606_CCL26', 'ENSG00000010379_SLC6A13', 'ENSG00000010932_FMO1', 'ENSG00000017427_IGF1', 'ENSG00000022355_GABRA1', 'ENSG00000041982_TNC', 'ENSG00000060709_RIMBP2', 'ENSG00000064886_CHI3L2', 'ENSG00000065717_TLE2', 'ENSG00000067798_NAV3', 'ENSG00000069535_MAOB', 'ENSG00000073598_FNDC8', 'ENSG00000074219_TEAD2', 'ENSG00000074964_ARHGEF10L', 'ENSG00000077264_PAK3', 'ENSG00000078053_AMPH', 'ENSG00000082684_SEMA5B', 'ENSG00000083857_FAT1', 'ENSG00000084628_NKAIN1', 'ENSG00000084734_GCKR', 'ENSG00000086967_MYBPC2', 'ENSG00000087258_GNAO1', 'ENSG00000089505_CMTM1', 'ENSG00000091129_NRCAM', 'ENSG00000091986_CCDC80', 'ENSG00000092377_TBL1Y', 'ENSG00000092969_TGFB2', 'ENSG00000095397_WHRN', 'ENSG00000095970_TREM2', 'ENSG00000099715_PCDH11Y', 'ENSG00000100197_CYP2D6', 'ENSG00000100218_RSPH14', 'ENSG00000100311_PDGFB', 'ENSG00000100362_PVALB', 'ENSG00000100373_UPK3A', 'ENSG00000100625_SIX4', 'ENSG00000100867_DHRS2', 'ENSG00000100985_MMP9', 'ENSG00000101197_BIRC7', 'ENSG00000101298_SNPH', 'ENSG00000102387_TAF7L', 'ENSG00000103034_NDRG4', 'ENSG00000104059_FAM189A1', 'ENSG00000104112_SCG3', 'ENSG00000104313_EYA1', 'ENSG00000104892_KLC3', 'ENSG00000105088_OLFM2', 'ENSG00000105261_OVOL3', 'ENSG00000105290_APLP1', 'ENSG00000105507_CABP5', 'ENSG00000105642_KCNN1', 'ENSG00000105694_ELOCP28', 'ENSG00000105707_HPN', 'ENSG00000105894_PTN', 'ENSG00000106018_VIPR2', 'ENSG00000106541_AGR2', 'ENSG00000107317_PTGDS', 'ENSG00000108688_CCL7', 'ENSG00000108702_CCL1', 'ENSG00000108947_EFNB3', 'ENSG00000109193_SULT1E1', 'ENSG00000109794_FAM149A', 'ENSG00000109832_DDX25', 'ENSG00000110195_FOLR1', 'ENSG00000110375_UPK2', 'ENSG00000110436_SLC1A2', 'ENSG00000111339_ART4', 'ENSG00000111863_ADTRP', 'ENSG00000112761_WISP3', 'ENSG00000112852_PCDHB2', 'ENSG00000114251_WNT5A', 'ENSG00000114279_FGF12', 'ENSG00000114455_HHLA2', 'ENSG00000114757_PEX5L', 'ENSG00000115155_OTOF', 'ENSG00000115266_APC2', 'ENSG00000115297_TLX2', 'ENSG00000115590_IL1R2', 'ENSG00000115844_DLX2', 'ENSG00000116194_ANGPTL1', 'ENSG00000116661_FBXO2', 'ENSG00000116774_OLFML3', 'ENSG00000117322_CR2', 'ENSG00000117971_CHRNB4', 'ENSG00000118322_ATP10B', 'ENSG00000118402_ELOVL4', 'ENSG00000118520_ARG1', 'ENSG00000118946_PCDH17', 'ENSG00000118972_FGF23', 'ENSG00000119771_KLHL29', 'ENSG00000120549_KIAA1217', 'ENSG00000121316_PLBD1', 'ENSG00000121905_HPCA', 'ENSG00000122224_LY9', 'ENSG00000124194_GDAP1L1', 'ENSG00000124440_HIF3A', 'ENSG00000124657_OR2B6', 'ENSG00000125462_C1orf61', 'ENSG00000125895_TMEM74B', 'ENSG00000126838_PZP', 'ENSG00000128422_KRT17', 'ENSG00000128918_ALDH1A2', 'ENSG00000129170_CSRP3', 'ENSG00000129214_SHBG', 'ENSG00000129673_AANAT', 'ENSG00000129910_CDH15', 'ENSG00000130294_KIF1A', 'ENSG00000130307_USHBP1', 'ENSG00000130545_CRB3', 'ENSG00000131019_ULBP3', 'ENSG00000131044_TTLL9', 'ENSG00000131183_SLC34A1', 'ENSG00000131386_GALNT15', 'ENSG00000131400_NAPSA', 'ENSG00000131914_LIN28A', 'ENSG00000131941_RHPN2', 'ENSG00000131951_LRRC9', 'ENSG00000132170_PPARG', 'ENSG00000132681_ATP1A4', 'ENSG00000132958_TPTE2', 'ENSG00000133454_MYO18B', 'ENSG00000134545_KLRC1', 'ENSG00000134853_PDGFRA', 'ENSG00000135083_CCNJL', 'ENSG00000135100_HNF1A', 'ENSG00000135116_HRK', 'ENSG00000135312_HTR1B', 'ENSG00000135324_MRAP2', 'ENSG00000135436_FAM186B', 'ENSG00000135472_FAIM2', 'ENSG00000135898_GPR55', 'ENSG00000135929_CYP27A1', 'ENSG00000136002_ARHGEF4', 'ENSG00000136099_PCDH8', 'ENSG00000136274_NACAD', 'ENSG00000137078_SIT1', 'ENSG00000137142_IGFBPL1', 'ENSG00000137473_TTC29', 'ENSG00000137474_MYO7A', 'ENSG00000137491_SLCO2B1', 'ENSG00000137691_CFAP300', 'ENSG00000137731_FXYD2', 'ENSG00000137747_TMPRSS13', 'ENSG00000137878_GCOM1', 'ENSG00000138411_HECW2', 'ENSG00000138741_TRPC3', 'ENSG00000138769_CDKL2', 'ENSG00000138823_MTTP', 'ENSG00000139908_TSSK4', 'ENSG00000140832_MARVELD3', 'ENSG00000142178_SIK1', 'ENSG00000142538_PTH2', 'ENSG00000142910_TINAGL1', 'ENSG00000143217_NECTIN4', 'ENSG00000143858_SYT2', 'ENSG00000144130_NT5DC4', 'ENSG00000144214_LYG1', 'ENSG00000144290_SLC4A10', 'ENSG00000144366_GULP1', 'ENSG00000144583_MARCH4', 'ENSG00000144771_LRTM1', 'ENSG00000144891_AGTR1', 'ENSG00000145087_STXBP5L', 'ENSG00000145107_TM4SF19', 'ENSG00000146197_SCUBE3', 'ENSG00000146966_DENND2A', 'ENSG00000147082_CCNB3', 'ENSG00000147614_ATP6V0D2', 'ENSG00000147642_SYBU', 'ENSG00000147869_CER1', 'ENSG00000149403_GRIK4', 'ENSG00000149596_JPH2', 'ENSG00000150630_VEGFC', 'ENSG00000150722_PPP1R1C', 'ENSG00000151631_AKR1C6P', 'ENSG00000151704_KCNJ1', 'ENSG00000152154_TMEM178A', 'ENSG00000152292_SH2D6', 'ENSG00000152315_KCNK13', 'ENSG00000152503_TRIM36', 'ENSG00000153253_SCN3A', 'ENSG00000153902_LGI4', 'ENSG00000153930_ANKFN1', 'ENSG00000154040_CABYR', 'ENSG00000154118_JPH3', 'ENSG00000154175_ABI3BP', 'ENSG00000154645_CHODL', 'ENSG00000157060_SHCBP1L', 'ENSG00000157087_ATP2B2', 'ENSG00000157152_SYN2', 'ENSG00000157168_NRG1', 'ENSG00000157680_DGKI', 'ENSG00000158246_TENT5B', 'ENSG00000158477_CD1A', 'ENSG00000158481_CD1C', 'ENSG00000158488_CD1E', 'ENSG00000159189_C1QC', 'ENSG00000159217_IGF2BP1', 'ENSG00000160683_CXCR5', 'ENSG00000160801_PTH1R', 'ENSG00000160973_FOXH1', 'ENSG00000161594_KLHL10', 'ENSG00000162409_PRKAA2', 'ENSG00000162840_MT2P1', 'ENSG00000162873_KLHDC8A', 'ENSG00000162944_RFTN2', 'ENSG00000162949_CAPN13', 'ENSG00000163116_STPG2', 'ENSG00000163288_GABRB1', 'ENSG00000163531_NFASC', 'ENSG00000163618_CADPS', 'ENSG00000163637_PRICKLE2', 'ENSG00000163735_CXCL5', 'ENSG00000163873_GRIK3', 'ENSG00000163898_LIPH', 'ENSG00000164061_BSN', 'ENSG00000164078_MST1R', 'ENSG00000164123_C4orf45', 'ENSG00000164690_SHH', 'ENSG00000164761_TNFRSF11B', 'ENSG00000164821_DEFA4', 'ENSG00000164845_FAM86FP', 'ENSG00000164867_NOS3', 'ENSG00000166073_GPR176', 'ENSG00000166148_AVPR1A', 'ENSG00000166250_CLMP', 'ENSG00000166257_SCN3B', 'ENSG00000166268_MYRFL', 'ENSG00000166523_CLEC4E', 'ENSG00000166535_A2ML1', 'ENSG00000166819_PLIN1', 'ENSG00000166928_MS4A14', 'ENSG00000167210_LOXHD1', 'ENSG00000167306_MYO5B', 'ENSG00000167634_NLRP7', 'ENSG00000167748_KLK1', 'ENSG00000167889_MGAT5B', 'ENSG00000168140_VASN', 'ENSG00000168546_GFRA2', 'ENSG00000168646_AXIN2', 'ENSG00000168955_TM4SF20', 'ENSG00000168993_CPLX1', 'ENSG00000169075_Z99496.1', 'ENSG00000169194_IL13', 'ENSG00000169246_NPIPB3', 'ENSG00000169884_WNT10B', 'ENSG00000169900_PYDC1', 'ENSG00000170074_FAM153A', 'ENSG00000170075_GPR37L1', 'ENSG00000170289_CNGB3', 'ENSG00000170356_OR2A20P', 'ENSG00000170537_TMC7', 'ENSG00000170689_HOXB9', 'ENSG00000170827_CELP', 'ENSG00000171346_KRT15', 'ENSG00000171368_TPPP', 'ENSG00000171501_OR1N2', 'ENSG00000171532_NEUROD2', 'ENSG00000171611_PTCRA', 'ENSG00000171873_ADRA1D', 'ENSG00000171916_LGALS9C', 'ENSG00000172005_MAL', 'ENSG00000172987_HPSE2', 'ENSG00000173068_BNC2', 'ENSG00000173077_DEC1', 'ENSG00000173210_ABLIM3', 'ENSG00000173267_SNCG', 'ENSG00000173369_C1QB', 'ENSG00000173372_C1QA', 'ENSG00000173391_OLR1', 'ENSG00000173626_TRAPPC3L', 'ENSG00000173698_ADGRG2', 'ENSG00000173868_PHOSPHO1', 'ENSG00000174407_MIR1-1HG', 'ENSG00000174807_CD248', 'ENSG00000175206_NPPA', 'ENSG00000175746_C15orf54', 'ENSG00000175985_PLEKHD1', 'ENSG00000176043_AC007160.1', 'ENSG00000176399_DMRTA1', 'ENSG00000176510_OR10AC1', 'ENSG00000176697_BDNF', 'ENSG00000176826_FKBP9P1', 'ENSG00000176988_FMR1NB', 'ENSG00000177324_BEND2', 'ENSG00000177335_C8orf31', 'ENSG00000177535_OR2B11', 'ENSG00000177614_PGBD5', 'ENSG00000177707_NECTIN3', 'ENSG00000178033_CALHM5', 'ENSG00000178175_ZNF366', 'ENSG00000178462_TUBAL3', 'ENSG00000178732_GP5', 'ENSG00000178750_STX19', 'ENSG00000179058_C9orf50', 'ENSG00000179101_AL590139.1', 'ENSG00000179388_EGR3', 'ENSG00000179611_DGKZP1', 'ENSG00000179899_PHC1P1', 'ENSG00000179934_CCR8', 'ENSG00000180537_RNF182', 'ENSG00000180712_LINC02363', 'ENSG00000180988_OR52N2', 'ENSG00000181001_OR52N1', 'ENSG00000181616_OR52H1', 'ENSG00000181634_TNFSF15', 'ENSG00000182021_AL591379.1', 'ENSG00000182230_FAM153B', 'ENSG00000182853_VMO1', 'ENSG00000183090_FREM3', 'ENSG00000183562_AC131971.1', 'ENSG00000183615_FAM167B', 'ENSG00000183625_CCR3', 'ENSG00000183770_FOXL2', 'ENSG00000183779_ZNF703', 'ENSG00000183831_ANKRD45', 'ENSG00000183844_FAM3B', 'ENSG00000183960_KCNH8', 'ENSG00000184106_TREML3P', 'ENSG00000184227_ACOT1', 'ENSG00000184363_PKP3', 'ENSG00000184434_LRRC19', 'ENSG00000184454_NCMAP', 'ENSG00000184571_PIWIL3', 'ENSG00000184702_SEPT5', 'ENSG00000184908_CLCNKB', 'ENSG00000184923_NUTM2A', 'ENSG00000185070_FLRT2', 'ENSG00000185156_MFSD6L', 'ENSG00000185567_AHNAK2', 'ENSG00000185686_PRAME', 'ENSG00000186190_BPIFB3', 'ENSG00000186191_BPIFB4', 'ENSG00000186231_KLHL32', 'ENSG00000186431_FCAR', 'ENSG00000186715_MST1L', 'ENSG00000187116_LILRA5', 'ENSG00000187185_AC092118.1', 'ENSG00000187268_FAM9C', 'ENSG00000187554_TLR5', 'ENSG00000187867_PALM3', 'ENSG00000188153_COL4A5', 'ENSG00000188158_NHS', 'ENSG00000188163_FAM166A', 'ENSG00000188316_ENO4', 'ENSG00000188959_C9orf152', 'ENSG00000189013_KIR2DL4', 'ENSG00000189409_MMP23B', 'ENSG00000196092_PAX5', 'ENSG00000196260_SFTA2', 'ENSG00000197358_BNIP3P1', 'ENSG00000197446_CYP2F1', 'ENSG00000197540_GZMM', 'ENSG00000198049_AVPR1B', 'ENSG00000198134_AC007537.1', 'ENSG00000198156_NPIPB6', 'ENSG00000198221_AFDN-DT', 'ENSG00000198626_RYR2', 'ENSG00000198759_EGFL6', 'ENSG00000198822_GRM3', 'ENSG00000198963_RORB', 'ENSG00000199090_MIR326', 'ENSG00000199753_SNORD104', 'ENSG00000199787_RF00406', 'ENSG00000199872_RNU6-942P', 'ENSG00000200075_RF00402', 'ENSG00000200296_RNU1-83P', 'ENSG00000200683_RNU6-379P', 'ENSG00000201044_RNU6-268P', 'ENSG00000201343_RF00019', 'ENSG00000201564_RN7SKP50', 'ENSG00000201616_RNU1-91P', 'ENSG00000201737_RNU1-133P', 'ENSG00000202048_SNORD114-20', 'ENSG00000202415_RN7SKP269', 'ENSG00000203395_AC015969.1', 'ENSG00000203721_LINC00862', 'ENSG00000203727_SAMD5', 'ENSG00000203737_GPR52', 'ENSG00000203783_PRR9', 'ENSG00000203867_RBM20', 'ENSG00000203907_OOEP', 'ENSG00000203999_LINC01270', 'ENSG00000204010_IFIT1B', 'ENSG00000204044_SLC12A5-AS1', 'ENSG00000204091_TDRG1', 'ENSG00000204121_ECEL1P1', 'ENSG00000204165_CXorf65', 'ENSG00000204173_LRRC37A5P', 'ENSG00000204248_COL11A2', 'ENSG00000204424_LY6G6F', 'ENSG00000204539_CDSN', 'ENSG00000204583_LRCOL1', 'ENSG00000204677_FAM153C', 'ENSG00000204709_LINC01556', 'ENSG00000204711_C9orf135', 'ENSG00000204792_LINC01291', 'ENSG00000204850_AC011484.1', 'ENSG00000204851_PNMA8B', 'ENSG00000204909_SPINK9', 'ENSG00000205037_AC134312.1', 'ENSG00000205038_PKHD1L1', 'ENSG00000205089_CCNI2', 'ENSG00000205106_DKFZp779M0652', 'ENSG00000205364_MT1M', 'ENSG00000205502_C2CD4B', 'ENSG00000205746_AC126755.1', 'ENSG00000205856_C22orf42', 'ENSG00000206052_DOK6', 'ENSG00000206579_XKR4', 'ENSG00000206645_RF00019', 'ENSG00000206786_RNU6-701P', 'ENSG00000206846_RF00019', 'ENSG00000206848_RNU6-890P', 'ENSG00000207088_SNORA7B', 'ENSG00000207181_SNORA14B', 'ENSG00000207234_RNU6-125P', 'ENSG00000207326_RF00019', 'ENSG00000207359_RNU6-925P', 'ENSG00000211677_IGLC2', 'ENSG00000211699_TRGV3', 'ENSG00000211895_IGHA1', 'ENSG00000212385_RNU6-817P', 'ENSG00000212391_RF00554', 'ENSG00000212607_SNORA3B', 'ENSG00000212829_RPS26P3', 'ENSG00000213083_AC010731.1', 'ENSG00000213216_AC007066.1', 'ENSG00000213222_AC093724.1', 'ENSG00000213228_RPL12P38', 'ENSG00000213250_RBMS2P1', 'ENSG00000213272_RPL7AP9', 'ENSG00000213303_AC008481.1', 'ENSG00000213402_PTPRCAP', 'ENSG00000213471_TTLL13P', 'ENSG00000213588_ZBTB9', 'ENSG00000213609_RPL7AP50', 'ENSG00000213757_AC020898.1', 'ENSG00000213931_HBE1', 'ENSG00000213950_RPS10P2', 'ENSG00000213994_AL157395.1', 'ENSG00000214787_MS4A4E', 'ENSG00000214866_DCDC2C', 'ENSG00000214908_AL353678.1', 'ENSG00000214975_PPIAP29', 'ENSG00000215198_AL353795.1', 'ENSG00000215208_KRT18P60', 'ENSG00000215218_UBE2QL1', 'ENSG00000215297_AL354941.1', 'ENSG00000215464_AP000354.1', 'ENSG00000215483_LINC00598', 'ENSG00000215817_ZC3H11B', 'ENSG00000215861_AC245297.1', 'ENSG00000215910_C1orf167', 'ENSG00000216475_AL024474.1', 'ENSG00000217195_AL513475.1', 'ENSG00000217414_DDX18P3', 'ENSG00000217512_AL356776.1', 'ENSG00000218351_RPS3AP23', 'ENSG00000218418_AL591135.1', 'ENSG00000218749_AL033519.1', 'ENSG00000218766_AL450338.1', 'ENSG00000218792_HSPD1P16', 'ENSG00000219249_AMZ2P2', 'ENSG00000219395_HSPA8P15', 'ENSG00000219410_AC125494.1', 'ENSG00000219932_RPL12P8', 'ENSG00000220091_LAP3P1', 'ENSG00000220237_RPS24P12', 'ENSG00000220494_YAP1P1', 'ENSG00000221102_SNORA11B', 'ENSG00000221887_HMSD', 'ENSG00000222276_RNU2-33P', 'ENSG00000222370_SNORA36B', 'ENSG00000222421_RF00019', 'ENSG00000222431_RNU6-141P', 'ENSG00000223342_AL158817.1', 'ENSG00000223379_AL391987.3', 'ENSG00000223403_MEG9', 'ENSG00000223519_KIF28P', 'ENSG00000223576_AL355001.1', 'ENSG00000223668_EEF1A1P24', 'ENSG00000223741_PSMD4P1', 'ENSG00000223779_AC239800.1', 'ENSG00000223783_LINC01983', 'ENSG00000223784_LINP1', 'ENSG00000223855_HRAT92', 'ENSG00000223884_AC068481.1', 'ENSG00000223899_SEC13P1', 'ENSG00000224067_AL354877.1', 'ENSG00000224072_AL139811.1', 'ENSG00000224081_SLC44A3-AS1', 'ENSG00000224099_AC104823.1', 'ENSG00000224116_INHBA-AS1', 'ENSG00000224137_LINC01857', 'ENSG00000224155_AC073136.2', 'ENSG00000224321_RPL12P14', 'ENSG00000224402_OR6D1P', 'ENSG00000224479_AC104162.1', 'ENSG00000224599_BMS1P12', 'ENSG00000224689_ZNF812P', 'ENSG00000224848_AL589843.1', 'ENSG00000224908_TIMM8BP2', 'ENSG00000224957_LINC01266', 'ENSG00000224959_AC017002.1', 'ENSG00000224988_AL158207.1', 'ENSG00000224993_RPL29P12', 'ENSG00000225096_AL445250.1', 'ENSG00000225101_OR52K3P', 'ENSG00000225107_AC092484.1', 'ENSG00000225187_AC073283.1', 'ENSG00000225313_AL513327.1', 'ENSG00000225345_SNX18P3', 'ENSG00000225393_BX571846.1', 'ENSG00000225422_RBMS1P1', 'ENSG00000225423_TNPO1P1', 'ENSG00000225531_AL807761.2', 'ENSG00000225554_AL359764.1', 'ENSG00000225650_EIF2S2P5', 'ENSG00000225674_IPO7P2', 'ENSG00000225807_AC069281.1', 'ENSG00000226010_AL355852.1', 'ENSG00000226084_AC113935.1', 'ENSG00000226251_AL451060.1', 'ENSG00000226383_LINC01876', 'ENSG00000226491_FTOP1', 'ENSG00000226501_USF1P1', 'ENSG00000226545_AL357552.1', 'ENSG00000226564_FTH1P20', 'ENSG00000226617_RPL21P110', 'ENSG00000226647_AL365356.1', 'ENSG00000226800_CACTIN-AS1', 'ENSG00000226913_BSN-DT', 'ENSG00000226948_RPS4XP2', 'ENSG00000226970_AL450063.1', 'ENSG00000227006_AL136988.2', 'ENSG00000227051_C14orf132', 'ENSG00000227072_AL353706.1', 'ENSG00000227110_LMCD1-AS1', 'ENSG00000227192_AL023581.2', 'ENSG00000227198_C6orf47-AS1', 'ENSG00000227207_RPL31P12', 'ENSG00000227477_STK4-AS1', 'ENSG00000227541_SFR1P1', 'ENSG00000227590_ATP5MC1P5', 'ENSG00000227649_MTND6P32', 'ENSG00000227682_ATP5F1AP2', 'ENSG00000227740_AL513329.1', 'ENSG00000227742_CALR4P', 'ENSG00000228097_MTATP6P11', 'ENSG00000228140_AL031283.1', 'ENSG00000228175_GEMIN8P4', 'ENSG00000228212_OFD1P17', 'ENSG00000228232_GAPDHP1', 'ENSG00000228317_AL158070.1', 'ENSG00000228413_AC024937.1', 'ENSG00000228430_AL162726.3', 'ENSG00000228501_RPL15P18', 'ENSG00000228550_AC073583.1', 'ENSG00000228655_AC096558.1', 'ENSG00000228727_SAPCD1', 'ENSG00000228826_AL592494.1', 'ENSG00000228839_PIK3IP1-AS1', 'ENSG00000228863_AL121985.1', 'ENSG00000229066_AC093459.1', 'ENSG00000229150_CRYGEP', 'ENSG00000229154_KCNQ5-AS1', 'ENSG00000229163_NAP1L1P2', 'ENSG00000229236_TTTY10', 'ENSG00000229274_AL662860.1', 'ENSG00000229308_AC010737.1', 'ENSG00000229326_AC069154.1', 'ENSG00000229372_SZT2-AS1', 'ENSG00000229444_AL451062.1', 'ENSG00000229567_AL139421.1', 'ENSG00000229703_CR589904.1', 'ENSG00000229742_AC092809.1', 'ENSG00000229758_DYNLT3P2', 'ENSG00000229839_AC018462.1', 'ENSG00000229847_EMX2OS', 'ENSG00000229853_AL034418.1', 'ENSG00000229918_DOCK9-AS1', 'ENSG00000229953_AL590666.2', 'ENSG00000229992_HMGB3P9', 'ENSG00000230063_AL360091.2', 'ENSG00000230064_AL772161.1', 'ENSG00000230138_AC119428.2', 'ENSG00000230149_AL021707.3', 'ENSG00000230289_AL358781.2', 'ENSG00000230295_GTF2IP23', 'ENSG00000230479_AP000695.1', 'ENSG00000230508_RPL19P21', 'ENSG00000230519_HMGB1P49', 'ENSG00000230534_AL392046.1', 'ENSG00000230563_AL121757.1', 'ENSG00000230721_AL049597.1', 'ENSG00000230772_VN1R108P', 'ENSG00000230777_RPS29P5', 'ENSG00000230799_AC007279.1', 'ENSG00000230813_AL356583.3', 'ENSG00000230815_AL807757.1', 'ENSG00000230872_MFSD13B', 'ENSG00000230910_AL391807.1', 'ENSG00000230912_AL021707.4', 'ENSG00000230968_AC084149.2', 'ENSG00000230993_RPL12P15', 'ENSG00000231265_TRERNA1', 'ENSG00000231307_RPS3P2', 'ENSG00000231407_AL354732.1', 'ENSG00000231449_AC097359.1', 'ENSG00000231507_LINC01353', 'ENSG00000231531_HINT1P1', 'ENSG00000231548_OR55B1P', 'ENSG00000231731_AC010976.1', 'ENSG00000231742_LINC01273', 'ENSG00000231788_RPL31P50', 'ENSG00000231830_AC245140.1', 'ENSG00000231927_AC093734.1', 'ENSG00000231993_EP300-AS1', 'ENSG00000232027_AL671986.1', 'ENSG00000232028_AC007391.1', 'ENSG00000232065_LINC01063', 'ENSG00000232133_IMPDH1P10', 'ENSG00000232139_LINC00867', 'ENSG00000232273_FTH1P1', 'ENSG00000232333_RPS27AP2', 'ENSG00000232466_AL356133.1', 'ENSG00000232500_AP005273.1', 'ENSG00000232530_LIF-AS1', 'ENSG00000232568_RPL23AP35', 'ENSG00000232578_AC093311.1', 'ENSG00000232606_LINC01412', 'ENSG00000232654_FAM136BP', 'ENSG00000232656_IDI2-AS1', 'ENSG00000232719_AC007272.1', 'ENSG00000232803_SLCO4A1-AS1', 'ENSG00000232987_LINC01219', 'ENSG00000233025_CRYZP1', 'ENSG00000233093_LINC00892', 'ENSG00000233099_AC095030.1', 'ENSG00000233401_PRKAR1AP1', 'ENSG00000233427_AL009181.1', 'ENSG00000233540_DNM3-IT1', 'ENSG00000233674_AL451062.2', 'ENSG00000233825_AL391839.2', 'ENSG00000233862_AC016907.2', 'ENSG00000233994_GDI2P2', 'ENSG00000234026_AL157834.2', 'ENSG00000234106_SRP14P2', 'ENSG00000234145_NAP1L4P3', 'ENSG00000234174_AC016683.1', 'ENSG00000234271_Z98752.2', 'ENSG00000234425_AL138930.1', 'ENSG00000234488_AC096664.2', 'ENSG00000234630_AC245060.2', 'ENSG00000234645_YWHAEP5', 'ENSG00000234718_AC007161.1', 'ENSG00000234810_AL603840.1', 'ENSG00000235045_RPL7P8', 'ENSG00000235072_AC012074.1', 'ENSG00000235214_FAM83C-AS1', 'ENSG00000235288_AC099329.1', 'ENSG00000235376_RPEL1', 'ENSG00000235429_AC083875.1', 'ENSG00000235472_EIF4A1P7', 'ENSG00000235478_LINC01664', 'ENSG00000235531_MSC-AS1', 'ENSG00000235640_AC092646.2', 'ENSG00000235677_NPM1P26', 'ENSG00000235683_AC018442.1', 'ENSG00000235701_PCBP2P1', 'ENSG00000235740_PHACTR2-AS1', 'ENSG00000235774_AC023347.1', 'ENSG00000235802_HCFC1-AS1', 'ENSG00000235917_MTCO2P11', 'ENSG00000235958_UBOX5-AS1', 'ENSG00000236032_OR5H14', 'ENSG00000236180_AL445669.2', 'ENSG00000236254_MTND4P14', 'ENSG00000236283_AC019197.1', 'ENSG00000236290_EEF1GP7', 'ENSG00000236317_AC104333.2', 'ENSG00000236364_AL358115.1', 'ENSG00000236457_AC090617.1', 'ENSG00000236564_YWHAQP5', 'ENSG00000236671_PRKG1-AS1', 'ENSG00000236680_AL356000.1', 'ENSG00000236682_AC068282.1', 'ENSG00000236711_SMAD9-IT1', 'ENSG00000236806_RPL7AP15', 'ENSG00000236869_ZKSCAN7-AS1', 'ENSG00000236886_AC007563.2', 'ENSG00000236915_AL356270.1', 'ENSG00000236936_AL031005.1', 'ENSG00000237057_LINC02087', 'ENSG00000237101_AC092809.4', 'ENSG00000237276_ANO7L1', 'ENSG00000237317_AL022400.1', 'ENSG00000237387_AL022329.2', 'ENSG00000237618_BTBD7P2', 'ENSG00000237685_AL139039.3', 'ENSG00000237757_EEF1A1P30', 'ENSG00000237766_GGTA2P', 'ENSG00000237798_AC010894.4', 'ENSG00000238015_AC104837.2', 'ENSG00000238133_MAP3K20-AS1', 'ENSG00000238259_AC067940.1', 'ENSG00000238324_RN7SKP198', 'ENSG00000238358_AC004969.1', 'ENSG00000239219_AC008040.1', 'ENSG00000239316_RN7SL11P', 'ENSG00000239474_KLHL41', 'ENSG00000239527_RPS23P7', 'ENSG00000239642_MEIKIN', 'ENSG00000239650_GUSBP4', 'ENSG00000239686_AL158801.1', 'ENSG00000239701_AC006512.1', 'ENSG00000239705_AL354710.2', 'ENSG00000239797_RPL21P39', 'ENSG00000239830_RPS4XP22', 'ENSG00000239930_AP001625.3', 'ENSG00000240086_AC092969.1', 'ENSG00000240087_RPSAP12', 'ENSG00000240183_RN7SL297P', 'ENSG00000240219_AL512306.2', 'ENSG00000240498_CDKN2B-AS1', 'ENSG00000240809_AC026877.1', 'ENSG00000240993_RN7SL459P', 'ENSG00000241111_PRICKLE2-AS1', 'ENSG00000241135_LINC00881', 'ENSG00000241319_SETP6', 'ENSG00000241570_PAQR9-AS1', 'ENSG00000241631_RN7SL316P', 'ENSG00000241932_AC092324.1', 'ENSG00000241933_DENND6A-DT', 'ENSG00000242060_RPS3AP49', 'ENSG00000242107_LINC01100', 'ENSG00000242175_RN7SL127P', 'ENSG00000242431_AC107398.1', 'ENSG00000242551_POU5F1P6', 'ENSG00000242571_RPL21P11', 'ENSG00000242641_LINC00971', 'ENSG00000242747_AC090515.1', 'ENSG00000242992_FTH1P4', 'ENSG00000243055_GK-AS1', 'ENSG00000243498_UBA52P5', 'ENSG00000243592_RPL17P22', 'ENSG00000243709_LEFTY1', 'ENSG00000243830_AC092865.1', 'ENSG00000243836_WDR86-AS1', 'ENSG00000243961_PARAL1', 'ENSG00000244021_AC093591.1', 'ENSG00000244097_RPS4XP17', 'ENSG00000244151_AC010973.2', 'ENSG00000244183_PPIAP71', 'ENSG00000244242_IFITM10', 'ENSG00000244245_AC133134.1', 'ENSG00000244251_AC013356.1', 'ENSG00000244355_LY6G6D', 'ENSG00000244357_RN7SL145P', 'ENSG00000244476_ERVFRD-1', 'ENSG00000244482_LILRA6', 'ENSG00000244585_RPL12P33', 'ENSG00000244618_RN7SL334P', 'ENSG00000244703_CD46P1', 'ENSG00000245261_AL133375.1', 'ENSG00000245482_AC046130.1', 'ENSG00000246363_LINC02458', 'ENSG00000246863_AC012377.1', 'ENSG00000247199_AC091948.1', 'ENSG00000248121_SMURF2P1', 'ENSG00000248155_CR545473.1', 'ENSG00000248223_AC026785.2', 'ENSG00000248485_PCP4L1', 'ENSG00000248690_HAS2-AS1', 'ENSG00000248884_AC010280.2', 'ENSG00000248936_AC027607.1', 'ENSG00000249140_PRDX2P3', 'ENSG00000249363_AC011411.1', 'ENSG00000249381_LINC00500', 'ENSG00000249456_AL731577.2', 'ENSG00000249492_AC114956.3', 'ENSG00000249574_AC226118.1', 'ENSG00000249614_LINC02503', 'ENSG00000249691_AC026117.1', 'ENSG00000249695_AC026369.1', 'ENSG00000249803_AC112178.1', 'ENSG00000249825_CTD-2201I18.1', 'ENSG00000249848_AC112673.1', 'ENSG00000249850_KRT18P31', 'ENSG00000249884_RNF103-CHMP3', 'ENSG00000249978_TRGV7', 'ENSG00000250130_AC090519.1', 'ENSG00000250148_KRT8P31', 'ENSG00000250332_AC010460.3', 'ENSG00000250334_LINC00989', 'ENSG00000250539_KRT8P33', 'ENSG00000250548_LINC01303', 'ENSG00000250608_AC010210.1', 'ENSG00000250635_CXXC5-AS1', 'ENSG00000250645_AC010442.2', 'ENSG00000250733_C8orf17', 'ENSG00000250853_RNF138P1', 'ENSG00000250902_SMAD1-AS1', 'ENSG00000250950_AC093752.2', 'ENSG00000250982_GAPDHP35', 'ENSG00000251129_LINC02506', 'ENSG00000251152_AC025539.1', 'ENSG00000251250_AC091951.3', 'ENSG00000251288_AC018797.3', 'ENSG00000251468_AC135352.1', 'ENSG00000251537_AC005324.3', 'ENSG00000251538_LINC02201', 'ENSG00000251584_AC096751.2', 'ENSG00000251676_SNHG27', 'ENSG00000251916_RNU1-61P', 'ENSG00000252759_RF00019', 'ENSG00000253256_AC134043.1', 'ENSG00000253305_PCDHGB6', 'ENSG00000253394_LINC00534', 'ENSG00000253490_LINC02099', 'ENSG00000253537_PCDHGA7', 'ENSG00000253629_AP000426.1', 'ENSG00000253651_SOD1P3', 'ENSG00000253730_AC015909.2', 'ENSG00000253734_LINC01289', 'ENSG00000253767_PCDHGA8', 'ENSG00000253853_AC246817.1', 'ENSG00000253873_PCDHGA11', 'ENSG00000254028_AC083843.1', 'ENSG00000254048_AC105150.1', 'ENSG00000254054_AC087273.2', 'ENSG00000254122_PCDHGB7', 'ENSG00000254248_AC068189.1', 'ENSG00000254680_AC079329.1', 'ENSG00000254708_AL139174.1', 'ENSG00000254780_AC023232.1', 'ENSG00000254810_AP001189.3', 'ENSG00000254812_AC067930.3', 'ENSG00000254842_LINC02551', 'ENSG00000254846_AL355075.1', 'ENSG00000254862_AC100771.2', 'ENSG00000254897_AP003035.1', 'ENSG00000255002_LINC02324', 'ENSG00000255074_AC018523.1', 'ENSG00000255102_AP005436.1', 'ENSG00000255156_RNY1P9', 'ENSG00000255158_AC131934.1', 'ENSG00000255222_SETP17', 'ENSG00000255256_AL136146.2', 'ENSG00000255367_AC127526.2', 'ENSG00000255418_AC090092.1', 'ENSG00000255443_CD44-AS1', 'ENSG00000255446_AP003064.2', 'ENSG00000255479_AP001189.6', 'ENSG00000255487_AC087362.2', 'ENSG00000255867_DENND5B-AS1', 'ENSG00000255871_AC007529.1', 'ENSG00000256029_SNHG28', 'ENSG00000256571_AC079866.2', 'ENSG00000256588_AC027544.2', 'ENSG00000256712_AC134349.1', 'ENSG00000256746_AC018410.1', 'ENSG00000256813_AP000777.3', 'ENSG00000256967_AC018653.3', 'ENSG00000256968_SNRPEP2', 'ENSG00000257074_RPL29P33', 'ENSG00000257120_AL356756.1', 'ENSG00000257146_AC079905.2', 'ENSG00000257195_HNRNPA1P50', 'ENSG00000257327_AC012555.1', 'ENSG00000257345_LINC02413', 'ENSG00000257379_AC023509.1', 'ENSG00000257386_AC025257.1', 'ENSG00000257431_AC089998.1', 'ENSG00000257715_AC007298.1', 'ENSG00000257838_OTOAP1', 'ENSG00000257987_TEX49', 'ENSG00000258084_AC128707.1', 'ENSG00000258090_AC093014.1', 'ENSG00000258177_AC008149.1', 'ENSG00000258357_AC023161.2', 'ENSG00000258410_AC087386.1', 'ENSG00000258498_DIO3OS', 'ENSG00000258504_AL157871.1', 'ENSG00000258512_LINC00239', 'ENSG00000258867_LINC01146', 'ENSG00000258886_HIGD1AP17', 'ENSG00000259032_ENSAP2', 'ENSG00000259100_AL157791.1', 'ENSG00000259294_AC005096.1', 'ENSG00000259327_AC023906.3', 'ENSG00000259345_AC013652.1', 'ENSG00000259377_AC026770.1', 'ENSG00000259380_AC087473.1', 'ENSG00000259442_AC105339.3', 'ENSG00000259461_ANP32BP3', 'ENSG00000259556_AC090971.3', 'ENSG00000259569_AC013489.2', 'ENSG00000259617_AC020661.3', 'ENSG00000259684_AC084756.1', 'ENSG00000259719_LINC02284', 'ENSG00000259954_IL21R-AS1', 'ENSG00000259986_AC103876.1', 'ENSG00000260135_MMP2-AS1', 'ENSG00000260206_AC105020.2', 'ENSG00000260235_AC105020.3', 'ENSG00000260269_AC105036.3', 'ENSG00000260394_Z92544.1', 'ENSG00000260425_AL031709.1', 'ENSG00000260447_AC009065.3', 'ENSG00000260615_RPL23AP97', 'ENSG00000260871_AC093510.2', 'ENSG00000260877_AP005233.2', 'ENSG00000260979_AC022167.3', 'ENSG00000261051_AC107021.2', 'ENSG00000261113_AC009034.1', 'ENSG00000261168_AL592424.1', 'ENSG00000261253_AC137932.2', 'ENSG00000261269_AC093278.2', 'ENSG00000261552_AC109460.4', 'ENSG00000261572_AC097639.1', 'ENSG00000261602_AC092115.2', 'ENSG00000261630_AC007496.2', 'ENSG00000261644_AC007728.2', 'ENSG00000261734_AC116096.1', 'ENSG00000261773_AC244090.2', 'ENSG00000261837_AC046158.2', 'ENSG00000261838_AC092718.6', 'ENSG00000261888_AC144831.1', 'ENSG00000262061_AC129507.1', 'ENSG00000262097_LINC02185', 'ENSG00000262372_CR936218.1', 'ENSG00000262406_MMP12', 'ENSG00000262580_AC087741.1', 'ENSG00000262772_LINC01977', 'ENSG00000262833_AC016245.1', 'ENSG00000263006_ROCK1P1', 'ENSG00000263011_AC108134.4', 'ENSG00000263155_MYZAP', 'ENSG00000263393_AC011825.2', 'ENSG00000263426_RN7SL471P', 'ENSG00000263503_MAPK8IP1P2', 'ENSG00000263595_RN7SL823P', 'ENSG00000263878_DLGAP1-AS4', 'ENSG00000263940_RN7SL275P', 'ENSG00000264019_AC018521.2', 'ENSG00000264031_ABHD15-AS1', 'ENSG00000264044_AC005726.2', 'ENSG00000264070_DND1P1', 'ENSG00000264188_AC106037.1', 'ENSG00000264269_AC016866.1', 'ENSG00000264339_AP001020.1', 'ENSG00000264434_AC110603.1', 'ENSG00000264714_KIAA0895LP1', 'ENSG00000265010_AC087301.1', 'ENSG00000265073_AC010761.2', 'ENSG00000265107_GJA5', 'ENSG00000265179_AP000894.2', 'ENSG00000265218_AC103810.2', 'ENSG00000265334_AC130324.2', 'ENSG00000265439_RN7SL811P', 'ENSG00000265531_FCGR1CP', 'ENSG00000265845_AC024267.4', 'ENSG00000265907_AP000919.2', 'ENSG00000265942_RN7SL577P', 'ENSG00000266256_LINC00683', 'ENSG00000266456_AP001178.3', 'ENSG00000266733_TBC1D29', 'ENSG00000266835_GAPLINC', 'ENSG00000266844_AC093330.1', 'ENSG00000266903_AC243964.2', 'ENSG00000266944_AC005262.1', 'ENSG00000266946_MRPL37P1', 'ENSG00000266947_AC022916.1', 'ENSG00000267034_AC010980.2', 'ENSG00000267044_AC005757.1', 'ENSG00000267147_LINC01842', 'ENSG00000267175_AC105094.2', 'ENSG00000267191_AC006213.3', 'ENSG00000267275_AC020911.2', 'ENSG00000267288_AC138150.2', 'ENSG00000267313_KC6', 'ENSG00000267316_AC090409.2', 'ENSG00000267323_SLC25A1P5', 'ENSG00000267345_AC010632.1', 'ENSG00000267387_AC020931.1', 'ENSG00000267395_DM1-AS', 'ENSG00000267429_AC006116.6', 'ENSG00000267452_LINC02073', 'ENSG00000267491_AC100788.1', 'ENSG00000267529_AP005131.4', 'ENSG00000267554_AC015911.8', 'ENSG00000267601_AC022966.1', 'ENSG00000267638_AC023855.1', 'ENSG00000267665_AC021683.3', 'ENSG00000267681_AC135721.1', 'ENSG00000267703_AC020917.2', 'ENSG00000267731_AC005332.2', 'ENSG00000267733_AP005264.5', 'ENSG00000267750_RUNDC3A-AS1', 'ENSG00000267890_AC010624.2', 'ENSG00000267898_AC026803.2', 'ENSG00000267927_AC010320.1', 'ENSG00000268070_AC006539.2', 'ENSG00000268355_AC243960.3', 'ENSG00000268416_AC010329.1', 'ENSG00000268520_AC008750.5', 'ENSG00000268636_AC011495.2', 'ENSG00000268696_ZNF723', 'ENSG00000268777_AC020914.1', 'ENSG00000268849_SIGLEC22P', 'ENSG00000268903_AL627309.6', 'ENSG00000268983_AC005253.2', 'ENSG00000269019_HOMER3-AS1', 'ENSG00000269067_ZNF728', 'ENSG00000269103_RF00017', 'ENSG00000269274_AC078899.4', 'ENSG00000269288_AC092070.3', 'ENSG00000269352_PTOV1-AS2', 'ENSG00000269400_AC008734.2', 'ENSG00000269506_AC110792.2', 'ENSG00000269653_AC011479.3', 'ENSG00000269881_AC004754.1', 'ENSG00000269926_DDIT4-AS1', 'ENSG00000270048_AC068790.4', 'ENSG00000270050_AL035427.1', 'ENSG00000270503_YTHDF2P1', 'ENSG00000270706_PRMT1P1', 'ENSG00000270765_GAS2L2', 'ENSG00000270882_HIST2H4A', 'ENSG00000270906_MTND4P35', 'ENSG00000271013_LRRC37A9P', 'ENSG00000271129_AC009027.1', 'ENSG00000271259_AC010201.1', 'ENSG00000271524_BNIP3P17', 'ENSG00000271543_AC021443.1', 'ENSG00000271743_AF287957.1', 'ENSG00000271792_AC008667.4', 'ENSG00000271868_AC114810.1', 'ENSG00000271973_AC141002.1', 'ENSG00000271984_AL008726.1', 'ENSG00000271996_AC019080.4', 'ENSG00000272070_AC005618.1', 'ENSG00000272138_LINC01607', 'ENSG00000272150_NBPF25P', 'ENSG00000272265_AC034236.3', 'ENSG00000272279_AL512329.2', 'ENSG00000272473_AC006273.1', 'ENSG00000272510_AL121992.3', 'ENSG00000272582_AL031587.3', 'ENSG00000272695_GAS6-DT', 'ENSG00000272732_AC004982.1', 'ENSG00000272770_AC005696.2', 'ENSG00000272788_AP000864.1', 'ENSG00000272824_AC245100.7', 'ENSG00000272825_AL844908.1', 'ENSG00000272848_AL135910.1', 'ENSG00000272916_AC022400.6', 'ENSG00000273133_AC116651.1', 'ENSG00000273177_AC092954.2', 'ENSG00000273212_AC000068.2', 'ENSG00000273218_AC005776.2', 'ENSG00000273245_AC092653.1', 'ENSG00000273274_ZBTB8B', 'ENSG00000273312_AL121749.1', 'ENSG00000273325_AL008723.3', 'ENSG00000273369_AC096586.2', 'ENSG00000273474_AL157392.4', 'ENSG00000273599_AL731571.1', 'ENSG00000273724_AC106782.5', 'ENSG00000273870_AL138721.1', 'ENSG00000273920_AC103858.2', 'ENSG00000274023_AL360169.2', 'ENSG00000274029_AC069209.1', 'ENSG00000274114_ALOX15P1', 'ENSG00000274124_AC074029.3', 'ENSG00000274139_AC090164.2', 'ENSG00000274281_AC022929.2', 'ENSG00000274308_AC244093.1', 'ENSG00000274373_AC148476.1', 'ENSG00000274386_TMEM269', 'ENSG00000274403_AC090510.2', 'ENSG00000274570_SPDYE10P', 'ENSG00000274670_AC137590.2', 'ENSG00000274723_AC079906.1', 'ENSG00000274742_RF00017', 'ENSG00000274798_AC025166.1', 'ENSG00000274911_AL627230.2', 'ENSG00000275106_AC025594.2', 'ENSG00000275197_AC092794.2', 'ENSG00000275302_CCL4', 'ENSG00000275348_AC096861.1', 'ENSG00000275367_AC092111.1', 'ENSG00000275489_C17orf98', 'ENSG00000275527_AC100835.2', 'ENSG00000275995_AC109809.1', 'ENSG00000276070_CCL4L2', 'ENSG00000276255_AL136379.1', 'ENSG00000276282_AC022960.2', 'ENSG00000276547_PCDHGB5', 'ENSG00000276704_AL442067.2', 'ENSG00000276952_AL121772.3', 'ENSG00000276984_AL023881.1', 'ENSG00000276997_AL513314.2', 'ENSG00000277117_FP565260.3', 'ENSG00000277152_AC110048.2', 'ENSG00000277186_AC131212.1', 'ENSG00000277229_AC084781.1', 'ENSG00000277496_AL357033.4', 'ENSG00000277504_AC010536.3', 'ENSG00000277531_PNMA8C', 'ENSG00000278041_AL133325.3', 'ENSG00000278344_AC063943.1', 'ENSG00000278467_AC138393.3', 'ENSG00000278513_AC091046.2', 'ENSG00000278621_AC037198.2', 'ENSG00000278713_AC120114.2', 'ENSG00000278716_AC133540.1', 'ENSG00000278746_RN7SL660P', 'ENSG00000278774_RF00004', 'ENSG00000279091_AC026523.2', 'ENSG00000279130_AC091925.1', 'ENSG00000279141_LINC01451', 'ENSG00000279161_AC093503.3', 'ENSG00000279187_AC027601.5', 'ENSG00000279263_OR2L8', 'ENSG00000279315_AL158212.4', 'ENSG00000279319_AC105074.1', 'ENSG00000279332_AC090772.4', 'ENSG00000279339_AC100788.2', 'ENSG00000279365_AP000695.3', 'ENSG00000279378_AC009159.4', 'ENSG00000279384_AC080188.2', 'ENSG00000279404_AC008739.5', 'ENSG00000279417_AC019322.4', 'ENSG00000279444_AC135584.1', 'ENSG00000279486_OR2AG1', 'ENSG00000279530_AC092881.1', 'ENSG00000279590_AC005786.4', 'ENSG00000279619_AC020907.5', 'ENSG00000279633_AL137918.1', 'ENSG00000279636_LINC00216', 'ENSG00000279672_AP006621.5', 'ENSG00000279690_AP000280.1', 'ENSG00000279727_LINC02033', 'ENSG00000279861_AC073548.1', 'ENSG00000279913_AP001962.1', 'ENSG00000279970_AC023024.2', 'ENSG00000280055_TMEM75', 'ENSG00000280057_AL022069.2', 'ENSG00000280135_AL096816.1', 'ENSG00000280310_AC092437.1', 'ENSG00000280422_AC115284.2', 'ENSG00000280432_AP000962.2', 'ENSG00000280693_SH3PXD2A-AS1', 'ENSG00000281490_CICP14', 'ENSG00000281530_AC004461.2', 'ENSG00000281571_AC241585.2', 'ENSG00000282772_AL358790.1', 'ENSG00000282989_AP001206.1', 'ENSG00000282996_AC022021.1', 'ENSG00000283023_FRG1GP', 'ENSG00000283031_AC009242.1', 'ENSG00000283097_AL159152.1', 'ENSG00000283141_AL157832.3', 'ENSG00000283209_AC106858.1', 'ENSG00000283538_AC005972.3', 'ENSG00000284240_AC099062.1', 'ENSG00000284512_AC092718.8', 'ENSG00000284657_AL031432.5', 'ENSG00000284664_AL161756.3', 'ENSG00000284931_AC104389.5', 'ENSG00000285016_AC017002.6', 'ENSG00000285117_AC068724.4', 'ENSG00000285162_AC004593.3', 'ENSG00000285210_AL136382.1', 'ENSG00000285215_AC241377.4', 'ENSG00000285292_AC021097.2', 'ENSG00000285498_AC104389.6', 'ENSG00000285534_AL163541.1', 'ENSG00000285577_AC019127.1', 'ENSG00000285611_AC007132.1', 'ENSG00000285629_AL031847.2', 'ENSG00000285641_AL358472.6', 'ENSG00000285649_AL357079.2', 'ENSG00000285650_AL157827.2', 'ENSG00000285662_AL731733.1', 'ENSG00000285672_AL160396.2', 'ENSG00000285763_AL358777.1', 'ENSG00000285865_AC010285.3', 'ENSG00000285879_AC018628.2']\n",
    "print('Constant cols:', len(constant_cols))\n",
    "\n",
    "important_cols = ['ENSG00000135218_CD36',\n",
    " 'ENSG00000010278_CD9',\n",
    " 'ENSG00000204287_HLA-DRA',\n",
    " 'ENSG00000117091_CD48',\n",
    " 'ENSG00000004468_CD38',\n",
    " 'ENSG00000173762_CD7',\n",
    " 'ENSG00000137101_CD72',\n",
    " 'ENSG00000019582_CD74',\n",
    " 'ENSG00000169442_CD52',\n",
    " 'ENSG00000170458_CD14',\n",
    " 'ENSG00000272398_CD24',\n",
    " 'ENSG00000026508_CD44',\n",
    " 'ENSG00000114013_CD86',\n",
    " 'ENSG00000174059_CD34',\n",
    " 'ENSG00000139193_CD27',\n",
    " 'ENSG00000105383_CD33',\n",
    " 'ENSG00000085117_CD82',\n",
    " 'ENSG00000177455_CD19',\n",
    " 'ENSG00000002586_CD99',\n",
    " 'ENSG00000196126_HLA-DRB1',\n",
    " 'ENSG00000135404_CD63',\n",
    " 'ENSG00000012124_CD22',\n",
    " 'ENSG00000134061_CD180',\n",
    " 'ENSG00000105369_CD79A',\n",
    " 'ENSG00000116824_CD2',\n",
    " 'ENSG00000010610_CD4',\n",
    " 'ENSG00000139187_KLRG1',\n",
    " 'ENSG00000204592_HLA-E',\n",
    " 'ENSG00000090470_PDCD7',\n",
    " 'ENSG00000206531_CD200R1L',\n",
    "'ENSG00000166710_B2M',\n",
    " 'ENSG00000198034_RPS4X',\n",
    " 'ENSG00000188404_SELL',\n",
    " 'ENSG00000130303_BST2',\n",
    " 'ENSG00000128040_SPINK2',\n",
    " 'ENSG00000206503_HLA-A',\n",
    " 'ENSG00000108107_RPL28',\n",
    " 'ENSG00000143226_FCGR2A',\n",
    " 'ENSG00000133112_TPT1',\n",
    " 'ENSG00000166091_CMTM5',\n",
    " 'ENSG00000026025_VIM',\n",
    " 'ENSG00000205542_TMSB4X',\n",
    " 'ENSG00000109099_PMP22',\n",
    " 'ENSG00000145425_RPS3A',\n",
    " 'ENSG00000172247_C1QTNF4',\n",
    " 'ENSG00000072274_TFRC',\n",
    " 'ENSG00000234745_HLA-B',\n",
    " 'ENSG00000075340_ADD2',\n",
    " 'ENSG00000119865_CNRIP1',\n",
    " 'ENSG00000198938_MT-CO3',\n",
    " 'ENSG00000135046_ANXA1',\n",
    " 'ENSG00000235169_SMIM1',\n",
    " 'ENSG00000101200_AVP',\n",
    " 'ENSG00000167996_FTH1',\n",
    " 'ENSG00000163565_IFI16',\n",
    " 'ENSG00000117450_PRDX1',\n",
    " 'ENSG00000124570_SERPINB6',\n",
    " 'ENSG00000112077_RHAG',\n",
    " 'ENSG00000051523_CYBA',\n",
    " 'ENSG00000107130_NCS1',\n",
    " 'ENSG00000055118_KCNH2',\n",
    " 'ENSG00000029534_ANK1',\n",
    " 'ENSG00000169567_HINT1',\n",
    " 'ENSG00000142089_IFITM3',\n",
    " 'ENSG00000139278_GLIPR1',\n",
    " 'ENSG00000142227_EMP3',\n",
    " 'ENSG00000076662_ICAM3',\n",
    " 'ENSG00000143627_PKLR',\n",
    " 'ENSG00000130755_GMFG',\n",
    " 'ENSG00000160593_JAML',\n",
    " 'ENSG00000095932_SMIM24',\n",
    " 'ENSG00000197956_S100A6',\n",
    " 'ENSG00000171476_HOPX',\n",
    " 'ENSG00000116675_DNAJC6',\n",
    " 'ENSG00000100448_CTSG',\n",
    " 'ENSG00000100368_CSF2RB',\n",
    " 'ENSG00000047648_ARHGAP6',\n",
    " 'ENSG00000198918_RPL39',\n",
    " 'ENSG00000196154_S100A4',\n",
    " 'ENSG00000233968_AL157895.1',\n",
    " 'ENSG00000137642_SORL1',\n",
    " 'ENSG00000133816_MICAL2',\n",
    " 'ENSG00000130208_APOC1',\n",
    " 'ENSG00000105610_KLF1']\n",
    "print('important columns ',len(important_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a6f0154",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = 70988"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf73aea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1a653e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize\n",
    "def std(x):\n",
    "    empty_list = []\n",
    "    for item in x:\n",
    "        empty_list.append((item - np.mean(item)) / np.std(item))\n",
    "    return np.array(empty_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01edd537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata_df = pd.read_csv(FP_CELL_METADATA, index_col = 'cell_id')\n",
    "# metadata_df = metadata_df[metadata_df.technology == \"citeseq\"]\n",
    "\n",
    "# # Read train and convert to sparse matrix\n",
    "# # X = pd.read_hdf(FP_CITE_TEST_INPUTS)\n",
    "# X = pd.read_hdf(FP_CITE_TEST_INPUTS).drop(columns = constant_cols)\n",
    "# # X = pd.read_csv(\"/gpfs/ysm/home/tl688/scrnahpc/tl688/openproblems/scGNN/outputdir/train_protein_recon.csv\",index_col=0).T.drop(columns = constant_cols)\n",
    "# cell_index = X.index\n",
    "# meta = metadata_df.reindex(cell_index)\n",
    "# X0 = X[important_cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60780696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute_train = X[important_cols].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02904c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute_train.to_csv(\"cite_test_forimpute.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd806ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X0 shape (70988, 84) X0t shape (48663, 84)\n"
     ]
    }
   ],
   "source": [
    "metadata_df = pd.read_csv(FP_CELL_METADATA, index_col = 'cell_id')\n",
    "metadata_df = metadata_df[metadata_df.technology == \"citeseq\"]\n",
    "\n",
    "# Read train and convert to sparse matrix\n",
    "# X = pd.read_hdf(FP_CITE_TRAIN_INPUTS)\n",
    "X = pd.read_hdf(FP_CITE_TRAIN_INPUTS).drop(columns = constant_cols)\n",
    "# X = pd.read_csv(\"/gpfs/ysm/home/tl688/scrnahpc/tl688/openproblems/scGNN/outputdir/train_protein_recon.csv\",index_col=0).T.drop(columns = constant_cols)\n",
    "cell_index = X.index\n",
    "meta = metadata_df.reindex(cell_index)\n",
    "X0 = X[important_cols].values\n",
    "\n",
    "del X\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# Read test and convert to sparse matrix\n",
    "# Xt = pd.read_hdf(FP_CITE_TEST_INPUTS)\n",
    "Xt = pd.read_hdf(FP_CITE_TEST_INPUTS).drop(columns = constant_cols)\n",
    "cell_index_test = Xt.index\n",
    "meta_test = metadata_df.reindex(cell_index_test)\n",
    "X0t = Xt[important_cols].values\n",
    "\n",
    "del Xt\n",
    "gc.collect()\n",
    "\n",
    "st = StandardScaler()\n",
    "X0 = st.fit_transform(X0)\n",
    "X0t = st.transform(X0t)\n",
    "\n",
    "print(f'X0 shape {X0.shape} X0t shape {X0t.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc4dbd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0996dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9fe6f969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./magic_impute.pkl','rb') as f: X_magic = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a22ba12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X0 = X_magic.values[:train_len,:]\n",
    "# X0t = X_magic.values[train_len:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "29235be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70988"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(X0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9075fc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# st = StandardScaler()\n",
    "# X0 = st.fit_transform(X0)\n",
    "# X0t = st.transform(X0t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df23b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a800ca92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70988, 512), (48663, 512))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with open('./input/targets-multiome-sparse-scaled/train_Citeseq_truncated_512.pkl','rb') as f: X = pickle.load(f)\n",
    "# with open('./input/targets-multiome-sparse-scaled/test_Citeseq_truncated_512.pkl','rb') as f: Xt = pickle.load(f)\n",
    "\n",
    "# X.shape, Xt.shape\n",
    "\n",
    "with open('./input/targets-multiome-sparse-scaled/train_cite_512.pkl','rb') as f: X = pickle.load(f)\n",
    "with open('./input/targets-multiome-sparse-scaled/test_cite_512.pkl','rb') as f: Xt = pickle.load(f)\n",
    "\n",
    "X.shape, Xt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "62289009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70988,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X, axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "729f9b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   40.,   520.,  3277.,  9799., 14241., 11917.,  6165.,  2240.,\n",
       "          441.,    23.]),\n",
       " array([-1.11871433, -0.98903984, -0.85936534, -0.72969079, -0.6000163 ,\n",
       "        -0.4703418 , -0.34066731, -0.21099278, -0.08131828,  0.04835622,\n",
       "         0.17803073]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37a8f67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a32bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57a99501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70988, 140)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = pd.read_hdf(FP_CITE_TRAIN_TARGETS)\n",
    "Y = Y.values\n",
    "Y -= Y.mean(axis=1).reshape(-1, 1)\n",
    "Y /= Y.std(axis=1).reshape(-1, 1)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb044d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_number_pca = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "492e7ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70988, 159)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.hstack((X[:,:feature_number_pca],X0))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "45d07e8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>donor</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>technology</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45006fe3e4c8</th>\n",
       "      <td>2</td>\n",
       "      <td>32606</td>\n",
       "      <td>HSC</td>\n",
       "      <td>citeseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d02759a80ba2</th>\n",
       "      <td>2</td>\n",
       "      <td>32606</td>\n",
       "      <td>HSC</td>\n",
       "      <td>citeseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c016c6b0efa5</th>\n",
       "      <td>2</td>\n",
       "      <td>32606</td>\n",
       "      <td>EryP</td>\n",
       "      <td>citeseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ba7f733a4f75</th>\n",
       "      <td>2</td>\n",
       "      <td>32606</td>\n",
       "      <td>NeuP</td>\n",
       "      <td>citeseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fbcf2443ffb2</th>\n",
       "      <td>2</td>\n",
       "      <td>32606</td>\n",
       "      <td>EryP</td>\n",
       "      <td>citeseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650ee456f0f3</th>\n",
       "      <td>4</td>\n",
       "      <td>31800</td>\n",
       "      <td>HSC</td>\n",
       "      <td>citeseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cc506e7707f5</th>\n",
       "      <td>4</td>\n",
       "      <td>31800</td>\n",
       "      <td>EryP</td>\n",
       "      <td>citeseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a91f1b55a520</th>\n",
       "      <td>4</td>\n",
       "      <td>31800</td>\n",
       "      <td>EryP</td>\n",
       "      <td>citeseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3a9882c98205</th>\n",
       "      <td>4</td>\n",
       "      <td>31800</td>\n",
       "      <td>MasP</td>\n",
       "      <td>citeseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c91b6b2ccd3d</th>\n",
       "      <td>4</td>\n",
       "      <td>31800</td>\n",
       "      <td>EryP</td>\n",
       "      <td>citeseq</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70988 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              day  donor cell_type technology\n",
       "cell_id                                      \n",
       "45006fe3e4c8    2  32606       HSC    citeseq\n",
       "d02759a80ba2    2  32606       HSC    citeseq\n",
       "c016c6b0efa5    2  32606      EryP    citeseq\n",
       "ba7f733a4f75    2  32606      NeuP    citeseq\n",
       "fbcf2443ffb2    2  32606      EryP    citeseq\n",
       "...           ...    ...       ...        ...\n",
       "650ee456f0f3    4  31800       HSC    citeseq\n",
       "cc506e7707f5    4  31800      EryP    citeseq\n",
       "a91f1b55a520    4  31800      EryP    citeseq\n",
       "3a9882c98205    4  31800      MasP    citeseq\n",
       "c91b6b2ccd3d    4  31800      EryP    citeseq\n",
       "\n",
       "[70988 rows x 4 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e0f8089",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-15 08:18:10.742119: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-15 08:18:11.229870: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Input, Concatenate, Dropout, BatchNormalization\n",
    "import keras_tuner\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d62d1f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_score(y_true, y_pred):\n",
    "    if type(y_true) == pd.DataFrame: y_true = y_true.values\n",
    "    if type(y_pred) == pd.DataFrame: y_pred = y_pred.values\n",
    "    corrsum = 0\n",
    "    for i in range(len(y_true)):\n",
    "        corrsum += np.corrcoef(y_true[i], y_pred[i])[1, 0]\n",
    "    return corrsum / len(y_true)\n",
    "\n",
    "def negative_correlation_loss(y_true, y_pred):\n",
    "    my = K.mean(tf.convert_to_tensor(y_pred), axis=1)\n",
    "    my = tf.tile(tf.expand_dims(my, axis=1), (1, y_true.shape[1]))\n",
    "    ym = y_pred - my\n",
    "    r_num = K.sum(tf.multiply(y_true, ym), axis=1)\n",
    "    r_den = tf.sqrt(K.sum(K.square(ym), axis=1) * float(y_true.shape[-1]))\n",
    "    r = tf.reduce_mean(r_num / r_den)\n",
    "    return - r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a7223c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_START = 1e-2\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "def create_model():\n",
    "    \n",
    "    reg1 = 9.613e-06\n",
    "    reg2 = 1e-07\n",
    "    REG1 = tf.keras.regularizers.l2(reg1)\n",
    "    REG2 = tf.keras.regularizers.l2(reg2)\n",
    "    DROP = 0.1\n",
    "\n",
    "    activation = 'selu'\n",
    "    inputs = Input(shape =(X.shape[1],))\n",
    "\n",
    "    x0 = Dense(512, \n",
    "              kernel_regularizer = REG1,\n",
    "              activation = activation,\n",
    "             )(inputs)\n",
    "    \n",
    "\n",
    "    x0 = Dropout(DROP)(x0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    x1 = Dense(512, \n",
    "               kernel_regularizer = REG1,\n",
    "               activation = activation,\n",
    "             )(x0)\n",
    "\n",
    "    x1 = Dropout(DROP)(x1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    x2 = Dense(512, \n",
    "               kernel_regularizer = REG1,\n",
    "               activation = activation,\n",
    "             )(x1+x0) \n",
    "    \n",
    "\n",
    "    x2 = Dropout(DROP)(x2)\n",
    "\n",
    "    \n",
    "    x3 = Dense(512,\n",
    "               kernel_regularizer = REG1,\n",
    "               activation = activation,\n",
    "             )(x2+x1)\n",
    "    \n",
    "\n",
    "    x3 = Dropout(DROP)(x3)\n",
    "\n",
    "    x = Concatenate()([\n",
    "                x0, \n",
    "                x1, \n",
    "                x2, \n",
    "                x3\n",
    "                ])\n",
    "    \n",
    "    x = Dense(Y.shape[1], \n",
    "                kernel_regularizer = REG2,\n",
    "                activation='linear',\n",
    "                )(x)\n",
    "    \n",
    "    x_out = Dense(Y.shape[1], \n",
    "                kernel_regularizer = REG2,\n",
    "                activation=activation,\n",
    "                )(inputs)\n",
    "    \n",
    "    \n",
    "    x = x + x_out\n",
    "    \n",
    "    model = Model(inputs, x)\n",
    "    \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c6724384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "70/70 [==============================] - 3s 15ms/step - loss: -0.7383 - negative_correlation_loss: -0.7557 - val_loss: -0.8452 - val_negative_correlation_loss: -0.8600 - lr: 0.0100\n",
      "Epoch 2/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.8620 - negative_correlation_loss: -0.8758 - val_loss: -0.8783 - val_negative_correlation_loss: -0.8904 - lr: 0.0100\n",
      "Epoch 3/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.8808 - negative_correlation_loss: -0.8921 - val_loss: -0.8871 - val_negative_correlation_loss: -0.8972 - lr: 0.0100\n",
      "Epoch 4/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.8869 - negative_correlation_loss: -0.8964 - val_loss: -0.8910 - val_negative_correlation_loss: -0.8995 - lr: 0.0100\n",
      "Epoch 5/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.8902 - negative_correlation_loss: -0.8983 - val_loss: -0.8928 - val_negative_correlation_loss: -0.9000 - lr: 0.0100\n",
      "Epoch 6/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.8924 - negative_correlation_loss: -0.8993 - val_loss: -0.8945 - val_negative_correlation_loss: -0.9008 - lr: 0.0100\n",
      "Epoch 7/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.8942 - negative_correlation_loss: -0.9003 - val_loss: -0.8962 - val_negative_correlation_loss: -0.9017 - lr: 0.0100\n",
      "Epoch 8/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.8952 - negative_correlation_loss: -0.9007 - val_loss: -0.8971 - val_negative_correlation_loss: -0.9021 - lr: 0.0100\n",
      "Epoch 9/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.8961 - negative_correlation_loss: -0.9011 - val_loss: -0.8979 - val_negative_correlation_loss: -0.9025 - lr: 0.0100\n",
      "Epoch 10/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.8967 - negative_correlation_loss: -0.9013 - val_loss: -0.8977 - val_negative_correlation_loss: -0.9019 - lr: 0.0100\n",
      "Epoch 11/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.8970 - negative_correlation_loss: -0.9013 - val_loss: -0.8987 - val_negative_correlation_loss: -0.9027 - lr: 0.0100\n",
      "Epoch 12/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.8977 - negative_correlation_loss: -0.9019 - val_loss: -0.8986 - val_negative_correlation_loss: -0.9022 - lr: 0.0100\n",
      "Epoch 13/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.8978 - negative_correlation_loss: -0.9017 - val_loss: -0.8995 - val_negative_correlation_loss: -0.9030 - lr: 0.0100\n",
      "Epoch 14/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.8981 - negative_correlation_loss: -0.9018 - val_loss: -0.8988 - val_negative_correlation_loss: -0.9022 - lr: 0.0100\n",
      "Epoch 15/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.8985 - negative_correlation_loss: -0.9020 - val_loss: -0.8997 - val_negative_correlation_loss: -0.9030 - lr: 0.0100\n",
      "Epoch 16/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.8985 - negative_correlation_loss: -0.9021 - val_loss: -0.8998 - val_negative_correlation_loss: -0.9030 - lr: 0.0100\n",
      "Epoch 17/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.8987 - negative_correlation_loss: -0.9021 - val_loss: -0.8998 - val_negative_correlation_loss: -0.9029 - lr: 0.0100\n",
      "Epoch 18/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.8990 - negative_correlation_loss: -0.9023 - val_loss: -0.9001 - val_negative_correlation_loss: -0.9031 - lr: 0.0100\n",
      "Epoch 19/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.8990 - negative_correlation_loss: -0.9022 - val_loss: -0.9001 - val_negative_correlation_loss: -0.9032 - lr: 0.0100\n",
      "Epoch 20/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.8992 - negative_correlation_loss: -0.9023 - val_loss: -0.9003 - val_negative_correlation_loss: -0.9032 - lr: 0.0100\n",
      "Epoch 21/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.8991 - negative_correlation_loss: -0.9023 - val_loss: -0.9005 - val_negative_correlation_loss: -0.9034 - lr: 0.0100\n",
      "Epoch 22/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.8993 - negative_correlation_loss: -0.9024 - val_loss: -0.8997 - val_negative_correlation_loss: -0.9026 - lr: 0.0100\n",
      "Epoch 23/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.8993 - negative_correlation_loss: -0.9024 - val_loss: -0.9006 - val_negative_correlation_loss: -0.9035 - lr: 0.0100\n",
      "Epoch 24/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.8994 - negative_correlation_loss: -0.9025 - val_loss: -0.9004 - val_negative_correlation_loss: -0.9033 - lr: 0.0100\n",
      "Epoch 25/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.8994 - negative_correlation_loss: -0.9024 - val_loss: -0.9002 - val_negative_correlation_loss: -0.9031 - lr: 0.0100\n",
      "Epoch 26/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.8993 - negative_correlation_loss: -0.9023 - val_loss: -0.9001 - val_negative_correlation_loss: -0.9030 - lr: 0.0100\n",
      "Epoch 27/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.8994 - negative_correlation_loss: -0.9025 - val_loss: -0.9006 - val_negative_correlation_loss: -0.9034 - lr: 0.0100\n",
      "Epoch 28/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.8998 - negative_correlation_loss: -0.9028 - val_loss: -0.9008 - val_negative_correlation_loss: -0.9035 - lr: 0.0090\n",
      "Epoch 29/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.8997 - negative_correlation_loss: -0.9027 - val_loss: -0.9004 - val_negative_correlation_loss: -0.9032 - lr: 0.0090\n",
      "Epoch 30/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.8998 - negative_correlation_loss: -0.9027 - val_loss: -0.9005 - val_negative_correlation_loss: -0.9032 - lr: 0.0090\n",
      "Epoch 31/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.8998 - negative_correlation_loss: -0.9027 - val_loss: -0.9009 - val_negative_correlation_loss: -0.9037 - lr: 0.0090\n",
      "Epoch 32/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.8998 - negative_correlation_loss: -0.9028 - val_loss: -0.9009 - val_negative_correlation_loss: -0.9036 - lr: 0.0090\n",
      "Epoch 33/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.8996 - negative_correlation_loss: -0.9026 - val_loss: -0.9009 - val_negative_correlation_loss: -0.9037 - lr: 0.0090\n",
      "Epoch 34/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.8998 - negative_correlation_loss: -0.9027 - val_loss: -0.9011 - val_negative_correlation_loss: -0.9039 - lr: 0.0090\n",
      "Epoch 35/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.8997 - negative_correlation_loss: -0.9027 - val_loss: -0.9012 - val_negative_correlation_loss: -0.9039 - lr: 0.0090\n",
      "Epoch 36/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.8998 - negative_correlation_loss: -0.9028 - val_loss: -0.8999 - val_negative_correlation_loss: -0.9027 - lr: 0.0090\n",
      "Epoch 37/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.8998 - negative_correlation_loss: -0.9027 - val_loss: -0.9007 - val_negative_correlation_loss: -0.9035 - lr: 0.0090\n",
      "Epoch 38/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.8997 - negative_correlation_loss: -0.9027 - val_loss: -0.9005 - val_negative_correlation_loss: -0.9032 - lr: 0.0090\n",
      "Epoch 39/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9000 - negative_correlation_loss: -0.9029 - val_loss: -0.9009 - val_negative_correlation_loss: -0.9035 - lr: 0.0081\n",
      "Epoch 40/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9000 - negative_correlation_loss: -0.9029 - val_loss: -0.9014 - val_negative_correlation_loss: -0.9041 - lr: 0.0081\n",
      "Epoch 41/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9001 - negative_correlation_loss: -0.9030 - val_loss: -0.9013 - val_negative_correlation_loss: -0.9039 - lr: 0.0081\n",
      "Epoch 42/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.8999 - negative_correlation_loss: -0.9029 - val_loss: -0.9005 - val_negative_correlation_loss: -0.9032 - lr: 0.0081\n",
      "Epoch 43/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9000 - negative_correlation_loss: -0.9029 - val_loss: -0.9014 - val_negative_correlation_loss: -0.9040 - lr: 0.0081\n",
      "Epoch 44/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.8999 - negative_correlation_loss: -0.9029 - val_loss: -0.9012 - val_negative_correlation_loss: -0.9039 - lr: 0.0081\n",
      "Epoch 45/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9004 - negative_correlation_loss: -0.9033 - val_loss: -0.9015 - val_negative_correlation_loss: -0.9041 - lr: 0.0073\n",
      "Epoch 46/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9003 - negative_correlation_loss: -0.9031 - val_loss: -0.9015 - val_negative_correlation_loss: -0.9041 - lr: 0.0073\n",
      "Epoch 47/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9002 - negative_correlation_loss: -0.9031 - val_loss: -0.9014 - val_negative_correlation_loss: -0.9041 - lr: 0.0073\n",
      "Epoch 48/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9003 - negative_correlation_loss: -0.9031 - val_loss: -0.9016 - val_negative_correlation_loss: -0.9042 - lr: 0.0073\n",
      "Epoch 49/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9002 - negative_correlation_loss: -0.9031 - val_loss: -0.9014 - val_negative_correlation_loss: -0.9040 - lr: 0.0073\n",
      "Epoch 50/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9002 - negative_correlation_loss: -0.9031 - val_loss: -0.9013 - val_negative_correlation_loss: -0.9039 - lr: 0.0073\n",
      "Epoch 51/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9002 - negative_correlation_loss: -0.9030 - val_loss: -0.9013 - val_negative_correlation_loss: -0.9039 - lr: 0.0073\n",
      "Epoch 52/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9003 - negative_correlation_loss: -0.9031 - val_loss: -0.9015 - val_negative_correlation_loss: -0.9041 - lr: 0.0073\n",
      "Epoch 53/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9005 - negative_correlation_loss: -0.9033 - val_loss: -0.9016 - val_negative_correlation_loss: -0.9041 - lr: 0.0066\n",
      "Epoch 54/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9005 - negative_correlation_loss: -0.9033 - val_loss: -0.9015 - val_negative_correlation_loss: -0.9041 - lr: 0.0066\n",
      "Epoch 55/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9005 - negative_correlation_loss: -0.9033 - val_loss: -0.9014 - val_negative_correlation_loss: -0.9039 - lr: 0.0066\n",
      "Epoch 56/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9006 - negative_correlation_loss: -0.9034 - val_loss: -0.9016 - val_negative_correlation_loss: -0.9042 - lr: 0.0066\n",
      "Epoch 57/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9007 - negative_correlation_loss: -0.9034 - val_loss: -0.9017 - val_negative_correlation_loss: -0.9042 - lr: 0.0059\n",
      "Epoch 58/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9008 - negative_correlation_loss: -0.9036 - val_loss: -0.9019 - val_negative_correlation_loss: -0.9044 - lr: 0.0059\n",
      "Epoch 59/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9008 - negative_correlation_loss: -0.9035 - val_loss: -0.9017 - val_negative_correlation_loss: -0.9042 - lr: 0.0059\n",
      "Epoch 60/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9006 - negative_correlation_loss: -0.9033 - val_loss: -0.9020 - val_negative_correlation_loss: -0.9046 - lr: 0.0059\n",
      "Epoch 61/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9008 - negative_correlation_loss: -0.9036 - val_loss: -0.9022 - val_negative_correlation_loss: -0.9047 - lr: 0.0059\n",
      "Epoch 62/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9006 - negative_correlation_loss: -0.9034 - val_loss: -0.9020 - val_negative_correlation_loss: -0.9046 - lr: 0.0059\n",
      "Epoch 63/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9008 - negative_correlation_loss: -0.9035 - val_loss: -0.9018 - val_negative_correlation_loss: -0.9043 - lr: 0.0059\n",
      "Epoch 64/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9008 - negative_correlation_loss: -0.9035 - val_loss: -0.9015 - val_negative_correlation_loss: -0.9041 - lr: 0.0059\n",
      "Epoch 65/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9008 - negative_correlation_loss: -0.9036 - val_loss: -0.9016 - val_negative_correlation_loss: -0.9041 - lr: 0.0059\n",
      "Epoch 66/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9010 - negative_correlation_loss: -0.9036 - val_loss: -0.9014 - val_negative_correlation_loss: -0.9038 - lr: 0.0053\n",
      "Epoch 67/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9008 - negative_correlation_loss: -0.9036 - val_loss: -0.9023 - val_negative_correlation_loss: -0.9048 - lr: 0.0053\n",
      "Epoch 68/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9011 - negative_correlation_loss: -0.9037 - val_loss: -0.9018 - val_negative_correlation_loss: -0.9042 - lr: 0.0053\n",
      "Epoch 69/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9008 - negative_correlation_loss: -0.9035 - val_loss: -0.9016 - val_negative_correlation_loss: -0.9041 - lr: 0.0053\n",
      "Epoch 70/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9010 - negative_correlation_loss: -0.9037 - val_loss: -0.9018 - val_negative_correlation_loss: -0.9043 - lr: 0.0053\n",
      "Epoch 71/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9010 - negative_correlation_loss: -0.9037 - val_loss: -0.9016 - val_negative_correlation_loss: -0.9041 - lr: 0.0053\n",
      "Epoch 72/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9012 - negative_correlation_loss: -0.9038 - val_loss: -0.9025 - val_negative_correlation_loss: -0.9049 - lr: 0.0048\n",
      "Epoch 73/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9011 - negative_correlation_loss: -0.9037 - val_loss: -0.9022 - val_negative_correlation_loss: -0.9046 - lr: 0.0048\n",
      "Epoch 74/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9012 - negative_correlation_loss: -0.9038 - val_loss: -0.9023 - val_negative_correlation_loss: -0.9048 - lr: 0.0048\n",
      "Epoch 75/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9011 - negative_correlation_loss: -0.9038 - val_loss: -0.9022 - val_negative_correlation_loss: -0.9047 - lr: 0.0048\n",
      "Epoch 76/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9012 - negative_correlation_loss: -0.9039 - val_loss: -0.9024 - val_negative_correlation_loss: -0.9048 - lr: 0.0048\n",
      "Epoch 77/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9014 - negative_correlation_loss: -0.9040 - val_loss: -0.9029 - val_negative_correlation_loss: -0.9053 - lr: 0.0043\n",
      "Epoch 78/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9014 - negative_correlation_loss: -0.9040 - val_loss: -0.9027 - val_negative_correlation_loss: -0.9050 - lr: 0.0043\n",
      "Epoch 79/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9014 - negative_correlation_loss: -0.9040 - val_loss: -0.9027 - val_negative_correlation_loss: -0.9051 - lr: 0.0043\n",
      "Epoch 80/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9015 - negative_correlation_loss: -0.9040 - val_loss: -0.9023 - val_negative_correlation_loss: -0.9046 - lr: 0.0043\n",
      "Epoch 81/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9014 - negative_correlation_loss: -0.9039 - val_loss: -0.9028 - val_negative_correlation_loss: -0.9052 - lr: 0.0043\n",
      "Epoch 82/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9016 - negative_correlation_loss: -0.9042 - val_loss: -0.9030 - val_negative_correlation_loss: -0.9053 - lr: 0.0039\n",
      "Epoch 83/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9017 - negative_correlation_loss: -0.9042 - val_loss: -0.9029 - val_negative_correlation_loss: -0.9052 - lr: 0.0039\n",
      "Epoch 84/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9017 - negative_correlation_loss: -0.9042 - val_loss: -0.9026 - val_negative_correlation_loss: -0.9049 - lr: 0.0039\n",
      "Epoch 85/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9017 - negative_correlation_loss: -0.9042 - val_loss: -0.9029 - val_negative_correlation_loss: -0.9052 - lr: 0.0039\n",
      "Epoch 86/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9018 - negative_correlation_loss: -0.9042 - val_loss: -0.9032 - val_negative_correlation_loss: -0.9055 - lr: 0.0035\n",
      "Epoch 87/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9019 - negative_correlation_loss: -0.9044 - val_loss: -0.9033 - val_negative_correlation_loss: -0.9055 - lr: 0.0035\n",
      "Epoch 88/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9019 - negative_correlation_loss: -0.9043 - val_loss: -0.9031 - val_negative_correlation_loss: -0.9053 - lr: 0.0035\n",
      "Epoch 89/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9019 - negative_correlation_loss: -0.9044 - val_loss: -0.9031 - val_negative_correlation_loss: -0.9054 - lr: 0.0035\n",
      "Epoch 90/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9019 - negative_correlation_loss: -0.9044 - val_loss: -0.9030 - val_negative_correlation_loss: -0.9052 - lr: 0.0035\n",
      "Epoch 91/1000\n",
      "70/70 [==============================] - 1s 10ms/step - loss: -0.9021 - negative_correlation_loss: -0.9045 - val_loss: -0.9033 - val_negative_correlation_loss: -0.9055 - lr: 0.0031\n",
      "Epoch 92/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9022 - negative_correlation_loss: -0.9046 - val_loss: -0.9034 - val_negative_correlation_loss: -0.9056 - lr: 0.0031\n",
      "Epoch 93/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9022 - negative_correlation_loss: -0.9046 - val_loss: -0.9033 - val_negative_correlation_loss: -0.9055 - lr: 0.0031\n",
      "Epoch 94/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9022 - negative_correlation_loss: -0.9046 - val_loss: -0.9036 - val_negative_correlation_loss: -0.9059 - lr: 0.0031\n",
      "Epoch 95/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9021 - negative_correlation_loss: -0.9046 - val_loss: -0.9033 - val_negative_correlation_loss: -0.9055 - lr: 0.0031\n",
      "Epoch 96/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9021 - negative_correlation_loss: -0.9045 - val_loss: -0.9032 - val_negative_correlation_loss: -0.9055 - lr: 0.0031\n",
      "Epoch 97/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9021 - negative_correlation_loss: -0.9045 - val_loss: -0.9035 - val_negative_correlation_loss: -0.9057 - lr: 0.0031\n",
      "Epoch 98/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9021 - negative_correlation_loss: -0.9045 - val_loss: -0.9031 - val_negative_correlation_loss: -0.9053 - lr: 0.0031\n",
      "Epoch 99/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9023 - negative_correlation_loss: -0.9047 - val_loss: -0.9036 - val_negative_correlation_loss: -0.9059 - lr: 0.0028\n",
      "Epoch 100/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9023 - negative_correlation_loss: -0.9047 - val_loss: -0.9037 - val_negative_correlation_loss: -0.9059 - lr: 0.0028\n",
      "Epoch 101/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9023 - negative_correlation_loss: -0.9047 - val_loss: -0.9031 - val_negative_correlation_loss: -0.9053 - lr: 0.0028\n",
      "Epoch 102/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9023 - negative_correlation_loss: -0.9047 - val_loss: -0.9038 - val_negative_correlation_loss: -0.9061 - lr: 0.0028\n",
      "Epoch 103/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9023 - negative_correlation_loss: -0.9047 - val_loss: -0.9034 - val_negative_correlation_loss: -0.9056 - lr: 0.0028\n",
      "Epoch 104/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9023 - negative_correlation_loss: -0.9047 - val_loss: -0.9034 - val_negative_correlation_loss: -0.9056 - lr: 0.0028\n",
      "Epoch 105/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9023 - negative_correlation_loss: -0.9047 - val_loss: -0.9037 - val_negative_correlation_loss: -0.9059 - lr: 0.0028\n",
      "Epoch 106/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9023 - negative_correlation_loss: -0.9048 - val_loss: -0.9036 - val_negative_correlation_loss: -0.9059 - lr: 0.0028\n",
      "Epoch 107/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9025 - negative_correlation_loss: -0.9049 - val_loss: -0.9034 - val_negative_correlation_loss: -0.9056 - lr: 0.0025\n",
      "Epoch 108/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9025 - negative_correlation_loss: -0.9049 - val_loss: -0.9037 - val_negative_correlation_loss: -0.9059 - lr: 0.0025\n",
      "Epoch 109/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9025 - negative_correlation_loss: -0.9049 - val_loss: -0.9038 - val_negative_correlation_loss: -0.9060 - lr: 0.0025\n",
      "Epoch 110/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9026 - negative_correlation_loss: -0.9049 - val_loss: -0.9038 - val_negative_correlation_loss: -0.9060 - lr: 0.0025\n",
      "Epoch 111/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9026 - negative_correlation_loss: -0.9050 - val_loss: -0.9041 - val_negative_correlation_loss: -0.9062 - lr: 0.0023\n",
      "Epoch 112/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9027 - negative_correlation_loss: -0.9050 - val_loss: -0.9040 - val_negative_correlation_loss: -0.9062 - lr: 0.0023\n",
      "Epoch 113/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9027 - negative_correlation_loss: -0.9051 - val_loss: -0.9040 - val_negative_correlation_loss: -0.9062 - lr: 0.0023\n",
      "Epoch 114/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9027 - negative_correlation_loss: -0.9051 - val_loss: -0.9042 - val_negative_correlation_loss: -0.9064 - lr: 0.0023\n",
      "Epoch 115/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9027 - negative_correlation_loss: -0.9050 - val_loss: -0.9041 - val_negative_correlation_loss: -0.9063 - lr: 0.0023\n",
      "Epoch 116/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9028 - negative_correlation_loss: -0.9052 - val_loss: -0.9042 - val_negative_correlation_loss: -0.9064 - lr: 0.0023\n",
      "Epoch 117/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9027 - negative_correlation_loss: -0.9051 - val_loss: -0.9040 - val_negative_correlation_loss: -0.9062 - lr: 0.0023\n",
      "Epoch 118/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9027 - negative_correlation_loss: -0.9051 - val_loss: -0.9041 - val_negative_correlation_loss: -0.9063 - lr: 0.0023\n",
      "Epoch 119/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9029 - negative_correlation_loss: -0.9053 - val_loss: -0.9041 - val_negative_correlation_loss: -0.9062 - lr: 0.0021\n",
      "Epoch 120/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9028 - negative_correlation_loss: -0.9052 - val_loss: -0.9040 - val_negative_correlation_loss: -0.9061 - lr: 0.0021\n",
      "Epoch 121/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9029 - negative_correlation_loss: -0.9052 - val_loss: -0.9043 - val_negative_correlation_loss: -0.9065 - lr: 0.0021\n",
      "Epoch 122/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9030 - negative_correlation_loss: -0.9053 - val_loss: -0.9044 - val_negative_correlation_loss: -0.9065 - lr: 0.0021\n",
      "Epoch 123/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9030 - negative_correlation_loss: -0.9053 - val_loss: -0.9043 - val_negative_correlation_loss: -0.9064 - lr: 0.0021\n",
      "Epoch 124/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9029 - negative_correlation_loss: -0.9052 - val_loss: -0.9043 - val_negative_correlation_loss: -0.9064 - lr: 0.0021\n",
      "Epoch 125/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9029 - negative_correlation_loss: -0.9052 - val_loss: -0.9041 - val_negative_correlation_loss: -0.9063 - lr: 0.0021\n",
      "Epoch 126/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9030 - negative_correlation_loss: -0.9053 - val_loss: -0.9044 - val_negative_correlation_loss: -0.9065 - lr: 0.0021\n",
      "Epoch 127/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9031 - negative_correlation_loss: -0.9054 - val_loss: -0.9046 - val_negative_correlation_loss: -0.9067 - lr: 0.0019\n",
      "Epoch 128/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9031 - negative_correlation_loss: -0.9055 - val_loss: -0.9045 - val_negative_correlation_loss: -0.9066 - lr: 0.0019\n",
      "Epoch 129/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9032 - negative_correlation_loss: -0.9055 - val_loss: -0.9047 - val_negative_correlation_loss: -0.9068 - lr: 0.0019\n",
      "Epoch 130/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9032 - negative_correlation_loss: -0.9055 - val_loss: -0.9046 - val_negative_correlation_loss: -0.9067 - lr: 0.0019\n",
      "Epoch 131/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9031 - negative_correlation_loss: -0.9055 - val_loss: -0.9046 - val_negative_correlation_loss: -0.9067 - lr: 0.0019\n",
      "Epoch 132/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9031 - negative_correlation_loss: -0.9054 - val_loss: -0.9044 - val_negative_correlation_loss: -0.9066 - lr: 0.0019\n",
      "Epoch 133/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9032 - negative_correlation_loss: -0.9055 - val_loss: -0.9048 - val_negative_correlation_loss: -0.9069 - lr: 0.0019\n",
      "Epoch 134/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9032 - negative_correlation_loss: -0.9055 - val_loss: -0.9046 - val_negative_correlation_loss: -0.9067 - lr: 0.0017\n",
      "Epoch 135/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9032 - negative_correlation_loss: -0.9055 - val_loss: -0.9047 - val_negative_correlation_loss: -0.9068 - lr: 0.0017\n",
      "Epoch 136/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9034 - negative_correlation_loss: -0.9057 - val_loss: -0.9048 - val_negative_correlation_loss: -0.9069 - lr: 0.0017\n",
      "Epoch 137/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9033 - negative_correlation_loss: -0.9056 - val_loss: -0.9048 - val_negative_correlation_loss: -0.9069 - lr: 0.0017\n",
      "Epoch 138/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9034 - negative_correlation_loss: -0.9056 - val_loss: -0.9047 - val_negative_correlation_loss: -0.9068 - lr: 0.0017\n",
      "Epoch 139/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9033 - negative_correlation_loss: -0.9056 - val_loss: -0.9046 - val_negative_correlation_loss: -0.9067 - lr: 0.0017\n",
      "Epoch 140/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9034 - negative_correlation_loss: -0.9057 - val_loss: -0.9045 - val_negative_correlation_loss: -0.9066 - lr: 0.0017\n",
      "Epoch 141/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9034 - negative_correlation_loss: -0.9057 - val_loss: -0.9050 - val_negative_correlation_loss: -0.9071 - lr: 0.0015\n",
      "Epoch 142/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9035 - negative_correlation_loss: -0.9057 - val_loss: -0.9049 - val_negative_correlation_loss: -0.9070 - lr: 0.0015\n",
      "Epoch 143/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9035 - negative_correlation_loss: -0.9057 - val_loss: -0.9048 - val_negative_correlation_loss: -0.9069 - lr: 0.0015\n",
      "Epoch 144/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9035 - negative_correlation_loss: -0.9058 - val_loss: -0.9043 - val_negative_correlation_loss: -0.9064 - lr: 0.0015\n",
      "Epoch 145/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9035 - negative_correlation_loss: -0.9057 - val_loss: -0.9050 - val_negative_correlation_loss: -0.9071 - lr: 0.0015\n",
      "Epoch 146/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9036 - negative_correlation_loss: -0.9058 - val_loss: -0.9047 - val_negative_correlation_loss: -0.9068 - lr: 0.0014\n",
      "Epoch 147/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9037 - negative_correlation_loss: -0.9059 - val_loss: -0.9051 - val_negative_correlation_loss: -0.9072 - lr: 0.0014\n",
      "Epoch 148/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9036 - negative_correlation_loss: -0.9059 - val_loss: -0.9051 - val_negative_correlation_loss: -0.9072 - lr: 0.0014\n",
      "Epoch 149/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9037 - negative_correlation_loss: -0.9060 - val_loss: -0.9051 - val_negative_correlation_loss: -0.9072 - lr: 0.0014\n",
      "Epoch 150/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9037 - negative_correlation_loss: -0.9060 - val_loss: -0.9050 - val_negative_correlation_loss: -0.9071 - lr: 0.0012\n",
      "Epoch 151/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9037 - negative_correlation_loss: -0.9060 - val_loss: -0.9053 - val_negative_correlation_loss: -0.9074 - lr: 0.0012\n",
      "Epoch 152/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9038 - negative_correlation_loss: -0.9061 - val_loss: -0.9052 - val_negative_correlation_loss: -0.9073 - lr: 0.0012\n",
      "Epoch 153/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9038 - negative_correlation_loss: -0.9060 - val_loss: -0.9050 - val_negative_correlation_loss: -0.9070 - lr: 0.0012\n",
      "Epoch 154/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9037 - negative_correlation_loss: -0.9060 - val_loss: -0.9054 - val_negative_correlation_loss: -0.9075 - lr: 0.0012\n",
      "Epoch 155/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9038 - negative_correlation_loss: -0.9059 - val_loss: -0.9054 - val_negative_correlation_loss: -0.9074 - lr: 0.0012\n",
      "Epoch 156/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9039 - negative_correlation_loss: -0.9062 - val_loss: -0.9053 - val_negative_correlation_loss: -0.9074 - lr: 0.0011\n",
      "Epoch 157/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9039 - negative_correlation_loss: -0.9061 - val_loss: -0.9052 - val_negative_correlation_loss: -0.9073 - lr: 0.0011\n",
      "Epoch 158/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9039 - negative_correlation_loss: -0.9061 - val_loss: -0.9055 - val_negative_correlation_loss: -0.9076 - lr: 0.0011\n",
      "Epoch 159/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9040 - negative_correlation_loss: -0.9063 - val_loss: -0.9056 - val_negative_correlation_loss: -0.9076 - lr: 0.0011\n",
      "Epoch 160/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9040 - negative_correlation_loss: -0.9062 - val_loss: -0.9055 - val_negative_correlation_loss: -0.9075 - lr: 0.0011\n",
      "Epoch 161/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9039 - negative_correlation_loss: -0.9061 - val_loss: -0.9054 - val_negative_correlation_loss: -0.9075 - lr: 0.0011\n",
      "Epoch 162/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9040 - negative_correlation_loss: -0.9062 - val_loss: -0.9055 - val_negative_correlation_loss: -0.9075 - lr: 0.0011\n",
      "Epoch 163/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9040 - negative_correlation_loss: -0.9063 - val_loss: -0.9056 - val_negative_correlation_loss: -0.9076 - lr: 9.8477e-04\n",
      "Epoch 164/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9041 - negative_correlation_loss: -0.9064 - val_loss: -0.9056 - val_negative_correlation_loss: -0.9076 - lr: 9.8477e-04\n",
      "Epoch 165/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9041 - negative_correlation_loss: -0.9064 - val_loss: -0.9057 - val_negative_correlation_loss: -0.9077 - lr: 9.8477e-04\n",
      "Epoch 166/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9041 - negative_correlation_loss: -0.9063 - val_loss: -0.9057 - val_negative_correlation_loss: -0.9078 - lr: 9.8477e-04\n",
      "Epoch 167/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9041 - negative_correlation_loss: -0.9063 - val_loss: -0.9056 - val_negative_correlation_loss: -0.9077 - lr: 9.8477e-04\n",
      "Epoch 168/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9041 - negative_correlation_loss: -0.9062 - val_loss: -0.9054 - val_negative_correlation_loss: -0.9075 - lr: 9.8477e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9041 - negative_correlation_loss: -0.9063 - val_loss: -0.9056 - val_negative_correlation_loss: -0.9076 - lr: 9.8477e-04\n",
      "Epoch 170/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9042 - negative_correlation_loss: -0.9065 - val_loss: -0.9057 - val_negative_correlation_loss: -0.9077 - lr: 8.8629e-04\n",
      "Epoch 171/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9042 - negative_correlation_loss: -0.9065 - val_loss: -0.9057 - val_negative_correlation_loss: -0.9078 - lr: 8.8629e-04\n",
      "Epoch 172/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9042 - negative_correlation_loss: -0.9065 - val_loss: -0.9057 - val_negative_correlation_loss: -0.9078 - lr: 8.8629e-04\n",
      "Epoch 173/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9042 - negative_correlation_loss: -0.9065 - val_loss: -0.9057 - val_negative_correlation_loss: -0.9078 - lr: 8.8629e-04\n",
      "Epoch 174/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9043 - negative_correlation_loss: -0.9066 - val_loss: -0.9057 - val_negative_correlation_loss: -0.9077 - lr: 7.9766e-04\n",
      "Epoch 175/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9043 - negative_correlation_loss: -0.9065 - val_loss: -0.9058 - val_negative_correlation_loss: -0.9079 - lr: 7.9766e-04\n",
      "Epoch 176/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9043 - negative_correlation_loss: -0.9066 - val_loss: -0.9058 - val_negative_correlation_loss: -0.9079 - lr: 7.9766e-04\n",
      "Epoch 177/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9044 - negative_correlation_loss: -0.9066 - val_loss: -0.9059 - val_negative_correlation_loss: -0.9080 - lr: 7.9766e-04\n",
      "Epoch 178/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9043 - negative_correlation_loss: -0.9066 - val_loss: -0.9059 - val_negative_correlation_loss: -0.9080 - lr: 7.9766e-04\n",
      "Epoch 179/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9043 - negative_correlation_loss: -0.9065 - val_loss: -0.9059 - val_negative_correlation_loss: -0.9080 - lr: 7.9766e-04\n",
      "Epoch 180/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9044 - negative_correlation_loss: -0.9066 - val_loss: -0.9059 - val_negative_correlation_loss: -0.9079 - lr: 7.9766e-04\n",
      "Epoch 181/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9044 - negative_correlation_loss: -0.9066 - val_loss: -0.9059 - val_negative_correlation_loss: -0.9079 - lr: 7.9766e-04\n",
      "Epoch 182/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9045 - negative_correlation_loss: -0.9067 - val_loss: -0.9061 - val_negative_correlation_loss: -0.9081 - lr: 7.1790e-04\n",
      "Epoch 183/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9044 - negative_correlation_loss: -0.9067 - val_loss: -0.9059 - val_negative_correlation_loss: -0.9080 - lr: 7.1790e-04\n",
      "Epoch 184/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9045 - negative_correlation_loss: -0.9067 - val_loss: -0.9061 - val_negative_correlation_loss: -0.9081 - lr: 7.1790e-04\n",
      "Epoch 185/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9045 - negative_correlation_loss: -0.9067 - val_loss: -0.9060 - val_negative_correlation_loss: -0.9081 - lr: 7.1790e-04\n",
      "Epoch 186/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9045 - negative_correlation_loss: -0.9067 - val_loss: -0.9061 - val_negative_correlation_loss: -0.9082 - lr: 7.1790e-04\n",
      "Epoch 187/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9046 - negative_correlation_loss: -0.9067 - val_loss: -0.9061 - val_negative_correlation_loss: -0.9081 - lr: 6.4611e-04\n",
      "Epoch 188/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9045 - negative_correlation_loss: -0.9068 - val_loss: -0.9061 - val_negative_correlation_loss: -0.9082 - lr: 6.4611e-04\n",
      "Epoch 189/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9046 - negative_correlation_loss: -0.9068 - val_loss: -0.9062 - val_negative_correlation_loss: -0.9082 - lr: 6.4611e-04\n",
      "Epoch 190/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9046 - negative_correlation_loss: -0.9068 - val_loss: -0.9062 - val_negative_correlation_loss: -0.9083 - lr: 6.4611e-04\n",
      "Epoch 191/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9045 - negative_correlation_loss: -0.9067 - val_loss: -0.9061 - val_negative_correlation_loss: -0.9081 - lr: 6.4611e-04\n",
      "Epoch 192/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9045 - negative_correlation_loss: -0.9067 - val_loss: -0.9062 - val_negative_correlation_loss: -0.9082 - lr: 6.4611e-04\n",
      "Epoch 193/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9046 - negative_correlation_loss: -0.9068 - val_loss: -0.9059 - val_negative_correlation_loss: -0.9080 - lr: 6.4611e-04\n",
      "Epoch 194/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9046 - negative_correlation_loss: -0.9069 - val_loss: -0.9062 - val_negative_correlation_loss: -0.9083 - lr: 5.8150e-04\n",
      "Epoch 195/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9047 - negative_correlation_loss: -0.9069 - val_loss: -0.9063 - val_negative_correlation_loss: -0.9083 - lr: 5.8150e-04\n",
      "Epoch 196/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9046 - negative_correlation_loss: -0.9069 - val_loss: -0.9063 - val_negative_correlation_loss: -0.9084 - lr: 5.8150e-04\n",
      "Epoch 197/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9047 - negative_correlation_loss: -0.9070 - val_loss: -0.9063 - val_negative_correlation_loss: -0.9083 - lr: 5.8150e-04\n",
      "Epoch 198/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9047 - negative_correlation_loss: -0.9069 - val_loss: -0.9064 - val_negative_correlation_loss: -0.9084 - lr: 5.8150e-04\n",
      "Epoch 199/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9047 - negative_correlation_loss: -0.9070 - val_loss: -0.9063 - val_negative_correlation_loss: -0.9084 - lr: 5.8150e-04\n",
      "Epoch 200/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9047 - negative_correlation_loss: -0.9069 - val_loss: -0.9064 - val_negative_correlation_loss: -0.9084 - lr: 5.8150e-04\n",
      "Epoch 201/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9047 - negative_correlation_loss: -0.9069 - val_loss: -0.9063 - val_negative_correlation_loss: -0.9084 - lr: 5.8150e-04\n",
      "Epoch 202/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9047 - negative_correlation_loss: -0.9070 - val_loss: -0.9065 - val_negative_correlation_loss: -0.9085 - lr: 5.8150e-04\n",
      "Epoch 203/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9047 - negative_correlation_loss: -0.9070 - val_loss: -0.9064 - val_negative_correlation_loss: -0.9085 - lr: 5.2335e-04\n",
      "Epoch 204/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9048 - negative_correlation_loss: -0.9070 - val_loss: -0.9064 - val_negative_correlation_loss: -0.9085 - lr: 5.2335e-04\n",
      "Epoch 205/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9048 - negative_correlation_loss: -0.9070 - val_loss: -0.9063 - val_negative_correlation_loss: -0.9084 - lr: 5.2335e-04\n",
      "Epoch 206/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9048 - negative_correlation_loss: -0.9071 - val_loss: -0.9064 - val_negative_correlation_loss: -0.9085 - lr: 5.2335e-04\n",
      "Epoch 207/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9049 - negative_correlation_loss: -0.9072 - val_loss: -0.9065 - val_negative_correlation_loss: -0.9085 - lr: 4.7101e-04\n",
      "Epoch 208/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9049 - negative_correlation_loss: -0.9071 - val_loss: -0.9065 - val_negative_correlation_loss: -0.9086 - lr: 4.7101e-04\n",
      "Epoch 209/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9049 - negative_correlation_loss: -0.9071 - val_loss: -0.9065 - val_negative_correlation_loss: -0.9085 - lr: 4.7101e-04\n",
      "Epoch 210/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9049 - negative_correlation_loss: -0.9071 - val_loss: -0.9065 - val_negative_correlation_loss: -0.9086 - lr: 4.7101e-04\n",
      "Epoch 211/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9049 - negative_correlation_loss: -0.9071 - val_loss: -0.9066 - val_negative_correlation_loss: -0.9087 - lr: 4.7101e-04\n",
      "Epoch 212/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9049 - negative_correlation_loss: -0.9072 - val_loss: -0.9066 - val_negative_correlation_loss: -0.9087 - lr: 4.7101e-04\n",
      "Epoch 213/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9049 - negative_correlation_loss: -0.9072 - val_loss: -0.9064 - val_negative_correlation_loss: -0.9085 - lr: 4.2391e-04\n",
      "Epoch 214/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9050 - negative_correlation_loss: -0.9071 - val_loss: -0.9066 - val_negative_correlation_loss: -0.9087 - lr: 4.2391e-04\n",
      "Epoch 215/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9049 - negative_correlation_loss: -0.9072 - val_loss: -0.9066 - val_negative_correlation_loss: -0.9087 - lr: 4.2391e-04\n",
      "Epoch 216/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9050 - negative_correlation_loss: -0.9072 - val_loss: -0.9067 - val_negative_correlation_loss: -0.9087 - lr: 4.2391e-04\n",
      "Epoch 217/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9050 - negative_correlation_loss: -0.9073 - val_loss: -0.9067 - val_negative_correlation_loss: -0.9088 - lr: 4.2391e-04\n",
      "Epoch 218/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9050 - negative_correlation_loss: -0.9073 - val_loss: -0.9067 - val_negative_correlation_loss: -0.9087 - lr: 4.2391e-04\n",
      "Epoch 219/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9051 - negative_correlation_loss: -0.9073 - val_loss: -0.9066 - val_negative_correlation_loss: -0.9087 - lr: 3.8152e-04\n",
      "Epoch 220/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9051 - negative_correlation_loss: -0.9073 - val_loss: -0.9067 - val_negative_correlation_loss: -0.9087 - lr: 3.8152e-04\n",
      "Epoch 221/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9050 - negative_correlation_loss: -0.9073 - val_loss: -0.9067 - val_negative_correlation_loss: -0.9088 - lr: 3.8152e-04\n",
      "Epoch 222/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9050 - negative_correlation_loss: -0.9072 - val_loss: -0.9067 - val_negative_correlation_loss: -0.9088 - lr: 3.8152e-04\n",
      "Epoch 223/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9051 - negative_correlation_loss: -0.9073 - val_loss: -0.9067 - val_negative_correlation_loss: -0.9088 - lr: 3.8152e-04\n",
      "Epoch 224/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9050 - negative_correlation_loss: -0.9073 - val_loss: -0.9066 - val_negative_correlation_loss: -0.9087 - lr: 3.8152e-04\n",
      "Epoch 225/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9050 - negative_correlation_loss: -0.9073 - val_loss: -0.9068 - val_negative_correlation_loss: -0.9088 - lr: 3.8152e-04\n",
      "Epoch 226/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9050 - negative_correlation_loss: -0.9073 - val_loss: -0.9067 - val_negative_correlation_loss: -0.9088 - lr: 3.8152e-04\n",
      "Epoch 227/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9051 - negative_correlation_loss: -0.9073 - val_loss: -0.9068 - val_negative_correlation_loss: -0.9089 - lr: 3.4337e-04\n",
      "Epoch 228/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9052 - negative_correlation_loss: -0.9074 - val_loss: -0.9068 - val_negative_correlation_loss: -0.9089 - lr: 3.4337e-04\n",
      "Epoch 229/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9051 - negative_correlation_loss: -0.9074 - val_loss: -0.9067 - val_negative_correlation_loss: -0.9087 - lr: 3.4337e-04\n",
      "Epoch 230/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9051 - negative_correlation_loss: -0.9073 - val_loss: -0.9068 - val_negative_correlation_loss: -0.9089 - lr: 3.4337e-04\n",
      "Epoch 231/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9051 - negative_correlation_loss: -0.9074 - val_loss: -0.9069 - val_negative_correlation_loss: -0.9090 - lr: 3.0903e-04\n",
      "Epoch 232/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9052 - negative_correlation_loss: -0.9075 - val_loss: -0.9069 - val_negative_correlation_loss: -0.9090 - lr: 3.0903e-04\n",
      "Epoch 233/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9052 - negative_correlation_loss: -0.9074 - val_loss: -0.9069 - val_negative_correlation_loss: -0.9090 - lr: 3.0903e-04\n",
      "Epoch 234/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9052 - negative_correlation_loss: -0.9075 - val_loss: -0.9068 - val_negative_correlation_loss: -0.9089 - lr: 3.0903e-04\n",
      "Epoch 235/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9052 - negative_correlation_loss: -0.9074 - val_loss: -0.9069 - val_negative_correlation_loss: -0.9090 - lr: 3.0903e-04\n",
      "Epoch 236/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9053 - negative_correlation_loss: -0.9075 - val_loss: -0.9070 - val_negative_correlation_loss: -0.9090 - lr: 2.7813e-04\n",
      "Epoch 237/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9053 - negative_correlation_loss: -0.9075 - val_loss: -0.9069 - val_negative_correlation_loss: -0.9090 - lr: 2.7813e-04\n",
      "Epoch 238/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9053 - negative_correlation_loss: -0.9075 - val_loss: -0.9070 - val_negative_correlation_loss: -0.9090 - lr: 2.7813e-04\n",
      "Epoch 239/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9052 - negative_correlation_loss: -0.9075 - val_loss: -0.9069 - val_negative_correlation_loss: -0.9090 - lr: 2.7813e-04\n",
      "Epoch 240/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9053 - negative_correlation_loss: -0.9076 - val_loss: -0.9070 - val_negative_correlation_loss: -0.9091 - lr: 2.5032e-04\n",
      "Epoch 241/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9053 - negative_correlation_loss: -0.9076 - val_loss: -0.9070 - val_negative_correlation_loss: -0.9091 - lr: 2.5032e-04\n",
      "Epoch 242/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9053 - negative_correlation_loss: -0.9075 - val_loss: -0.9070 - val_negative_correlation_loss: -0.9091 - lr: 2.5032e-04\n",
      "Epoch 243/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9053 - negative_correlation_loss: -0.9075 - val_loss: -0.9070 - val_negative_correlation_loss: -0.9090 - lr: 2.5032e-04\n",
      "Epoch 244/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9053 - negative_correlation_loss: -0.9075 - val_loss: -0.9070 - val_negative_correlation_loss: -0.9091 - lr: 2.5032e-04\n",
      "Epoch 245/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9053 - negative_correlation_loss: -0.9075 - val_loss: -0.9071 - val_negative_correlation_loss: -0.9092 - lr: 2.2528e-04\n",
      "Epoch 246/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9054 - negative_correlation_loss: -0.9076 - val_loss: -0.9071 - val_negative_correlation_loss: -0.9092 - lr: 2.2528e-04\n",
      "Epoch 247/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9053 - negative_correlation_loss: -0.9076 - val_loss: -0.9070 - val_negative_correlation_loss: -0.9091 - lr: 2.2528e-04\n",
      "Epoch 248/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9054 - negative_correlation_loss: -0.9077 - val_loss: -0.9071 - val_negative_correlation_loss: -0.9091 - lr: 2.2528e-04\n",
      "Epoch 249/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9054 - negative_correlation_loss: -0.9076 - val_loss: -0.9071 - val_negative_correlation_loss: -0.9091 - lr: 2.0276e-04\n",
      "Epoch 250/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9054 - negative_correlation_loss: -0.9077 - val_loss: -0.9071 - val_negative_correlation_loss: -0.9092 - lr: 2.0276e-04\n",
      "Epoch 251/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9054 - negative_correlation_loss: -0.9077 - val_loss: -0.9072 - val_negative_correlation_loss: -0.9092 - lr: 2.0276e-04\n",
      "Epoch 252/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9054 - negative_correlation_loss: -0.9076 - val_loss: -0.9072 - val_negative_correlation_loss: -0.9092 - lr: 2.0276e-04\n",
      "Epoch 253/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9054 - negative_correlation_loss: -0.9076 - val_loss: -0.9072 - val_negative_correlation_loss: -0.9092 - lr: 2.0276e-04\n",
      "Epoch 254/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9054 - negative_correlation_loss: -0.9077 - val_loss: -0.9070 - val_negative_correlation_loss: -0.9091 - lr: 2.0276e-04\n",
      "Epoch 255/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9054 - negative_correlation_loss: -0.9077 - val_loss: -0.9071 - val_negative_correlation_loss: -0.9092 - lr: 2.0276e-04\n",
      "Epoch 256/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9054 - negative_correlation_loss: -0.9077 - val_loss: -0.9072 - val_negative_correlation_loss: -0.9093 - lr: 1.8248e-04\n",
      "Epoch 257/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9055 - negative_correlation_loss: -0.9077 - val_loss: -0.9072 - val_negative_correlation_loss: -0.9093 - lr: 1.8248e-04\n",
      "Epoch 258/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9054 - negative_correlation_loss: -0.9077 - val_loss: -0.9072 - val_negative_correlation_loss: -0.9093 - lr: 1.8248e-04\n",
      "Epoch 259/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9054 - negative_correlation_loss: -0.9077 - val_loss: -0.9072 - val_negative_correlation_loss: -0.9093 - lr: 1.8248e-04\n",
      "Epoch 260/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9055 - negative_correlation_loss: -0.9077 - val_loss: -0.9073 - val_negative_correlation_loss: -0.9093 - lr: 1.6423e-04\n",
      "Epoch 261/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9055 - negative_correlation_loss: -0.9078 - val_loss: -0.9072 - val_negative_correlation_loss: -0.9092 - lr: 1.6423e-04\n",
      "Epoch 262/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9055 - negative_correlation_loss: -0.9078 - val_loss: -0.9073 - val_negative_correlation_loss: -0.9093 - lr: 1.6423e-04\n",
      "Epoch 263/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9055 - negative_correlation_loss: -0.9077 - val_loss: -0.9073 - val_negative_correlation_loss: -0.9093 - lr: 1.6423e-04\n",
      "Epoch 264/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9055 - negative_correlation_loss: -0.9077 - val_loss: -0.9073 - val_negative_correlation_loss: -0.9093 - lr: 1.6423e-04\n",
      "Epoch 265/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9055 - negative_correlation_loss: -0.9077 - val_loss: -0.9073 - val_negative_correlation_loss: -0.9093 - lr: 1.6423e-04\n",
      "Epoch 266/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9055 - negative_correlation_loss: -0.9078 - val_loss: -0.9073 - val_negative_correlation_loss: -0.9093 - lr: 1.6423e-04\n",
      "Epoch 267/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9056 - negative_correlation_loss: -0.9077 - val_loss: -0.9073 - val_negative_correlation_loss: -0.9094 - lr: 1.4781e-04\n",
      "Epoch 268/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9055 - negative_correlation_loss: -0.9078 - val_loss: -0.9073 - val_negative_correlation_loss: -0.9094 - lr: 1.4781e-04\n",
      "Epoch 269/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9055 - negative_correlation_loss: -0.9077 - val_loss: -0.9073 - val_negative_correlation_loss: -0.9094 - lr: 1.4781e-04\n",
      "Epoch 270/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9056 - negative_correlation_loss: -0.9078 - val_loss: -0.9073 - val_negative_correlation_loss: -0.9094 - lr: 1.4781e-04\n",
      "Epoch 271/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9056 - negative_correlation_loss: -0.9078 - val_loss: -0.9073 - val_negative_correlation_loss: -0.9094 - lr: 1.3303e-04\n",
      "Epoch 272/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9056 - negative_correlation_loss: -0.9078 - val_loss: -0.9073 - val_negative_correlation_loss: -0.9094 - lr: 1.3303e-04\n",
      "Epoch 273/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9056 - negative_correlation_loss: -0.9078 - val_loss: -0.9074 - val_negative_correlation_loss: -0.9094 - lr: 1.3303e-04\n",
      "Epoch 274/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9056 - negative_correlation_loss: -0.9078 - val_loss: -0.9073 - val_negative_correlation_loss: -0.9094 - lr: 1.3303e-04\n",
      "Epoch 275/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9056 - negative_correlation_loss: -0.9079 - val_loss: -0.9074 - val_negative_correlation_loss: -0.9094 - lr: 1.1973e-04\n",
      "Epoch 276/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9056 - negative_correlation_loss: -0.9078 - val_loss: -0.9074 - val_negative_correlation_loss: -0.9094 - lr: 1.1973e-04\n",
      "Epoch 277/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9056 - negative_correlation_loss: -0.9079 - val_loss: -0.9074 - val_negative_correlation_loss: -0.9095 - lr: 1.1973e-04\n",
      "Epoch 278/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9056 - negative_correlation_loss: -0.9078 - val_loss: -0.9074 - val_negative_correlation_loss: -0.9095 - lr: 1.1973e-04\n",
      "Epoch 279/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9056 - negative_correlation_loss: -0.9078 - val_loss: -0.9074 - val_negative_correlation_loss: -0.9095 - lr: 1.1973e-04\n",
      "Epoch 280/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9056 - negative_correlation_loss: -0.9079 - val_loss: -0.9074 - val_negative_correlation_loss: -0.9095 - lr: 1.1973e-04\n",
      "Epoch 281/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9056 - negative_correlation_loss: -0.9078 - val_loss: -0.9074 - val_negative_correlation_loss: -0.9095 - lr: 1.0775e-04\n",
      "Epoch 282/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9056 - negative_correlation_loss: -0.9079 - val_loss: -0.9074 - val_negative_correlation_loss: -0.9095 - lr: 1.0775e-04\n",
      "Epoch 283/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9056 - negative_correlation_loss: -0.9079 - val_loss: -0.9074 - val_negative_correlation_loss: -0.9095 - lr: 1.0775e-04\n",
      "Epoch 284/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9057 - negative_correlation_loss: -0.9079 - val_loss: -0.9074 - val_negative_correlation_loss: -0.9095 - lr: 1.0775e-04\n",
      "Epoch 285/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9057 - negative_correlation_loss: -0.9079 - val_loss: -0.9074 - val_negative_correlation_loss: -0.9095 - lr: 9.6977e-05\n",
      "Epoch 286/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9056 - negative_correlation_loss: -0.9079 - val_loss: -0.9074 - val_negative_correlation_loss: -0.9095 - lr: 9.6977e-05\n",
      "Epoch 287/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9057 - negative_correlation_loss: -0.9079 - val_loss: -0.9075 - val_negative_correlation_loss: -0.9095 - lr: 9.6977e-05\n",
      "Epoch 288/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9056 - negative_correlation_loss: -0.9080 - val_loss: -0.9075 - val_negative_correlation_loss: -0.9096 - lr: 9.6977e-05\n",
      "Epoch 289/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9057 - negative_correlation_loss: -0.9079 - val_loss: -0.9075 - val_negative_correlation_loss: -0.9095 - lr: 9.6977e-05\n",
      "Epoch 290/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9057 - negative_correlation_loss: -0.9080 - val_loss: -0.9074 - val_negative_correlation_loss: -0.9095 - lr: 9.6977e-05\n",
      "Epoch 291/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9057 - negative_correlation_loss: -0.9080 - val_loss: -0.9075 - val_negative_correlation_loss: -0.9095 - lr: 9.6977e-05\n",
      "Epoch 292/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9057 - negative_correlation_loss: -0.9080 - val_loss: -0.9075 - val_negative_correlation_loss: -0.9096 - lr: 9.6977e-05\n",
      "Epoch 293/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9057 - negative_correlation_loss: -0.9080 - val_loss: -0.9075 - val_negative_correlation_loss: -0.9096 - lr: 8.7280e-05\n",
      "Epoch 294/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9057 - negative_correlation_loss: -0.9079 - val_loss: -0.9075 - val_negative_correlation_loss: -0.9096 - lr: 8.7280e-05\n",
      "Epoch 295/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9057 - negative_correlation_loss: -0.9079 - val_loss: -0.9075 - val_negative_correlation_loss: -0.9096 - lr: 8.7280e-05\n",
      "Epoch 296/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9058 - negative_correlation_loss: -0.9081 - val_loss: -0.9075 - val_negative_correlation_loss: -0.9096 - lr: 8.7280e-05\n",
      "Epoch 297/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9057 - negative_correlation_loss: -0.9080 - val_loss: -0.9075 - val_negative_correlation_loss: -0.9096 - lr: 7.8552e-05\n",
      "Epoch 298/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9057 - negative_correlation_loss: -0.9080 - val_loss: -0.9075 - val_negative_correlation_loss: -0.9096 - lr: 7.8552e-05\n",
      "Epoch 299/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9057 - negative_correlation_loss: -0.9080 - val_loss: -0.9075 - val_negative_correlation_loss: -0.9095 - lr: 7.8552e-05\n",
      "Epoch 300/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9057 - negative_correlation_loss: -0.9080 - val_loss: -0.9075 - val_negative_correlation_loss: -0.9096 - lr: 7.8552e-05\n",
      "Epoch 301/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9058 - negative_correlation_loss: -0.9080 - val_loss: -0.9075 - val_negative_correlation_loss: -0.9096 - lr: 7.0697e-05\n",
      "Epoch 302/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9057 - negative_correlation_loss: -0.9080 - val_loss: -0.9075 - val_negative_correlation_loss: -0.9096 - lr: 7.0697e-05\n",
      "Epoch 303/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9057 - negative_correlation_loss: -0.9079 - val_loss: -0.9075 - val_negative_correlation_loss: -0.9096 - lr: 7.0697e-05\n",
      "Epoch 304/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9057 - negative_correlation_loss: -0.9080 - val_loss: -0.9075 - val_negative_correlation_loss: -0.9096 - lr: 7.0697e-05\n",
      "Epoch 305/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9057 - negative_correlation_loss: -0.9080 - val_loss: -0.9075 - val_negative_correlation_loss: -0.9096 - lr: 6.3627e-05\n",
      "Epoch 306/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9058 - negative_correlation_loss: -0.9080 - val_loss: -0.9075 - val_negative_correlation_loss: -0.9096 - lr: 6.3627e-05\n",
      "Epoch 307/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9058 - negative_correlation_loss: -0.9081 - val_loss: -0.9075 - val_negative_correlation_loss: -0.9096 - lr: 6.3627e-05\n",
      "Epoch 308/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9058 - negative_correlation_loss: -0.9080 - val_loss: -0.9076 - val_negative_correlation_loss: -0.9096 - lr: 6.3627e-05\n",
      "Epoch 309/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9057 - negative_correlation_loss: -0.9080 - val_loss: -0.9075 - val_negative_correlation_loss: -0.9096 - lr: 5.7264e-05\n",
      "Epoch 310/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9058 - negative_correlation_loss: -0.9080 - val_loss: -0.9076 - val_negative_correlation_loss: -0.9097 - lr: 5.7264e-05\n",
      "Epoch 311/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9058 - negative_correlation_loss: -0.9081 - val_loss: -0.9075 - val_negative_correlation_loss: -0.9096 - lr: 5.7264e-05\n",
      "Epoch 312/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9058 - negative_correlation_loss: -0.9080 - val_loss: -0.9076 - val_negative_correlation_loss: -0.9097 - lr: 5.7264e-05\n",
      "Epoch 313/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9058 - negative_correlation_loss: -0.9080 - val_loss: -0.9075 - val_negative_correlation_loss: -0.9096 - lr: 5.7264e-05\n",
      "Epoch 314/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9058 - negative_correlation_loss: -0.9080 - val_loss: -0.9075 - val_negative_correlation_loss: -0.9096 - lr: 5.7264e-05\n",
      "Epoch 315/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9058 - negative_correlation_loss: -0.9080 - val_loss: -0.9076 - val_negative_correlation_loss: -0.9097 - lr: 5.1538e-05\n",
      "Epoch 316/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9058 - negative_correlation_loss: -0.9080 - val_loss: -0.9076 - val_negative_correlation_loss: -0.9097 - lr: 5.1538e-05\n",
      "Epoch 317/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9058 - negative_correlation_loss: -0.9081 - val_loss: -0.9076 - val_negative_correlation_loss: -0.9097 - lr: 5.1538e-05\n",
      "Epoch 318/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9058 - negative_correlation_loss: -0.9081 - val_loss: -0.9076 - val_negative_correlation_loss: -0.9097 - lr: 5.1538e-05\n",
      "Epoch 319/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9058 - negative_correlation_loss: -0.9081 - val_loss: -0.9076 - val_negative_correlation_loss: -0.9097 - lr: 4.6384e-05\n",
      "Epoch 320/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9058 - negative_correlation_loss: -0.9080 - val_loss: -0.9076 - val_negative_correlation_loss: -0.9097 - lr: 4.6384e-05\n",
      "Epoch 321/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9058 - negative_correlation_loss: -0.9080 - val_loss: -0.9076 - val_negative_correlation_loss: -0.9097 - lr: 4.6384e-05\n",
      "Epoch 322/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9058 - negative_correlation_loss: -0.9081 - val_loss: -0.9076 - val_negative_correlation_loss: -0.9097 - lr: 4.6384e-05\n",
      "Epoch 323/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9058 - negative_correlation_loss: -0.9080 - val_loss: -0.9076 - val_negative_correlation_loss: -0.9097 - lr: 4.1746e-05\n",
      "Epoch 324/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9058 - negative_correlation_loss: -0.9080 - val_loss: -0.9076 - val_negative_correlation_loss: -0.9097 - lr: 4.1746e-05\n",
      "Epoch 325/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9058 - negative_correlation_loss: -0.9081 - val_loss: -0.9076 - val_negative_correlation_loss: -0.9097 - lr: 4.1746e-05\n",
      "Epoch 326/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9058 - negative_correlation_loss: -0.9081 - val_loss: -0.9076 - val_negative_correlation_loss: -0.9097 - lr: 4.1746e-05\n",
      "Epoch 327/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9058 - negative_correlation_loss: -0.9081 - val_loss: -0.9076 - val_negative_correlation_loss: -0.9097 - lr: 3.7571e-05\n",
      "Epoch 328/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9059 - negative_correlation_loss: -0.9081 - val_loss: -0.9076 - val_negative_correlation_loss: -0.9097 - lr: 3.7571e-05\n",
      "Epoch 329/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9058 - negative_correlation_loss: -0.9081 - val_loss: -0.9076 - val_negative_correlation_loss: -0.9097 - lr: 3.7571e-05\n",
      "Epoch 330/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9058 - negative_correlation_loss: -0.9080 - val_loss: -0.9076 - val_negative_correlation_loss: -0.9097 - lr: 3.7571e-05\n",
      "Epoch 331/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9058 - negative_correlation_loss: -0.9081 - val_loss: -0.9076 - val_negative_correlation_loss: -0.9097 - lr: 3.3814e-05\n",
      "Epoch 332/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9058 - negative_correlation_loss: -0.9081 - val_loss: -0.9076 - val_negative_correlation_loss: -0.9097 - lr: 3.3814e-05\n",
      "Epoch 333/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9081 - val_loss: -0.9076 - val_negative_correlation_loss: -0.9097 - lr: 3.3814e-05\n",
      "Epoch 334/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9058 - negative_correlation_loss: -0.9080 - val_loss: -0.9076 - val_negative_correlation_loss: -0.9097 - lr: 3.3814e-05\n",
      "Epoch 335/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9058 - negative_correlation_loss: -0.9081 - val_loss: -0.9076 - val_negative_correlation_loss: -0.9097 - lr: 3.0433e-05\n",
      "Epoch 336/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9059 - negative_correlation_loss: -0.9081 - val_loss: -0.9076 - val_negative_correlation_loss: -0.9097 - lr: 3.0433e-05\n",
      "Epoch 337/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9097 - lr: 3.0433e-05\n",
      "Epoch 338/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9058 - negative_correlation_loss: -0.9081 - val_loss: -0.9076 - val_negative_correlation_loss: -0.9097 - lr: 3.0433e-05\n",
      "Epoch 339/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9058 - negative_correlation_loss: -0.9081 - val_loss: -0.9076 - val_negative_correlation_loss: -0.9097 - lr: 2.7389e-05\n",
      "Epoch 340/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9059 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.7389e-05\n",
      "Epoch 341/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9058 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.7389e-05\n",
      "Epoch 342/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9076 - val_negative_correlation_loss: -0.9097 - lr: 2.7389e-05\n",
      "Epoch 343/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9081 - val_loss: -0.9076 - val_negative_correlation_loss: -0.9097 - lr: 2.4650e-05\n",
      "Epoch 344/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9058 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9097 - lr: 2.4650e-05\n",
      "Epoch 345/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9081 - val_loss: -0.9076 - val_negative_correlation_loss: -0.9097 - lr: 2.4650e-05\n",
      "Epoch 346/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9059 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.4650e-05\n",
      "Epoch 347/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.2185e-05\n",
      "Epoch 348/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9076 - val_negative_correlation_loss: -0.9097 - lr: 2.2185e-05\n",
      "Epoch 349/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9058 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.2185e-05\n",
      "Epoch 350/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.2185e-05\n",
      "Epoch 351/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9059 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.9967e-05\n",
      "Epoch 352/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9059 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.9967e-05\n",
      "Epoch 353/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.9967e-05\n",
      "Epoch 354/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.9967e-05\n",
      "Epoch 355/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9097 - lr: 1.9967e-05\n",
      "Epoch 356/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.9967e-05\n",
      "Epoch 357/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.7970e-05\n",
      "Epoch 358/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.7970e-05\n",
      "Epoch 359/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.7970e-05\n",
      "Epoch 360/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.7970e-05\n",
      "Epoch 361/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.6173e-05\n",
      "Epoch 362/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.6173e-05\n",
      "Epoch 363/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.6173e-05\n",
      "Epoch 364/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.6173e-05\n",
      "Epoch 365/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.4556e-05\n",
      "Epoch 366/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.4556e-05\n",
      "Epoch 367/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.4556e-05\n",
      "Epoch 368/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.4556e-05\n",
      "Epoch 369/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.3100e-05\n",
      "Epoch 370/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.3100e-05\n",
      "Epoch 371/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.3100e-05\n",
      "Epoch 372/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.3100e-05\n",
      "Epoch 373/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.1790e-05\n",
      "Epoch 374/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.1790e-05\n",
      "Epoch 375/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.1790e-05\n",
      "Epoch 376/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.1790e-05\n",
      "Epoch 377/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.0611e-05\n",
      "Epoch 378/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.0611e-05\n",
      "Epoch 379/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.0611e-05\n",
      "Epoch 380/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.0611e-05\n",
      "Epoch 381/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 9.5501e-06\n",
      "Epoch 382/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 9.5501e-06\n",
      "Epoch 383/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 9.5501e-06\n",
      "Epoch 384/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 9.5501e-06\n",
      "Epoch 385/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 8.5950e-06\n",
      "Epoch 386/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 8.5950e-06\n",
      "Epoch 387/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 8.5950e-06\n",
      "Epoch 388/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 8.5950e-06\n",
      "Epoch 389/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 7.7355e-06\n",
      "Epoch 390/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 7.7355e-06\n",
      "Epoch 391/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 7.7355e-06\n",
      "Epoch 392/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 7.7355e-06\n",
      "Epoch 393/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 6.9620e-06\n",
      "Epoch 394/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 6.9620e-06\n",
      "Epoch 395/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 6.9620e-06\n",
      "Epoch 396/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 6.9620e-06\n",
      "Epoch 397/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 6.2658e-06\n",
      "Epoch 398/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 6.2658e-06\n",
      "Epoch 399/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 6.2658e-06\n",
      "Epoch 400/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 6.2658e-06\n",
      "Epoch 401/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 5.6392e-06\n",
      "Epoch 402/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 5.6392e-06\n",
      "Epoch 403/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 5.6392e-06\n",
      "Epoch 404/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 5.6392e-06\n",
      "Epoch 405/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 5.0753e-06\n",
      "Epoch 406/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 5.0753e-06\n",
      "Epoch 407/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 5.0753e-06\n",
      "Epoch 408/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 5.0753e-06\n",
      "Epoch 409/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 4.5678e-06\n",
      "Epoch 410/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 4.5678e-06\n",
      "Epoch 411/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 4.5678e-06\n",
      "Epoch 412/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 4.5678e-06\n",
      "Epoch 413/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 4.1110e-06\n",
      "Epoch 414/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 4.1110e-06\n",
      "Epoch 415/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 4.1110e-06\n",
      "Epoch 416/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 4.1110e-06\n",
      "Epoch 417/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 3.6999e-06\n",
      "Epoch 418/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 3.6999e-06\n",
      "Epoch 419/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 3.6999e-06\n",
      "Epoch 420/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 3.6999e-06\n",
      "Epoch 421/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 3.3299e-06\n",
      "Epoch 422/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 3.3299e-06\n",
      "Epoch 423/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 3.3299e-06\n",
      "Epoch 424/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 3.3299e-06\n",
      "Epoch 425/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.9969e-06\n",
      "Epoch 426/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.9969e-06\n",
      "Epoch 427/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.9969e-06\n",
      "Epoch 428/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.9969e-06\n",
      "Epoch 429/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9083 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.6972e-06\n",
      "Epoch 430/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.6972e-06\n",
      "Epoch 431/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.6972e-06\n",
      "Epoch 432/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.6972e-06\n",
      "Epoch 433/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.4275e-06\n",
      "Epoch 434/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.4275e-06\n",
      "Epoch 435/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9083 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.4275e-06\n",
      "Epoch 436/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.4275e-06\n",
      "Epoch 437/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.1847e-06\n",
      "Epoch 438/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.1847e-06\n",
      "Epoch 439/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.1847e-06\n",
      "Epoch 440/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.1847e-06\n",
      "Epoch 441/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.9663e-06\n",
      "Epoch 442/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.9663e-06\n",
      "Epoch 443/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.9663e-06\n",
      "Epoch 444/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.9663e-06\n",
      "Epoch 445/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.7696e-06\n",
      "Epoch 446/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9083 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.7696e-06\n",
      "Epoch 447/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.7696e-06\n",
      "Epoch 448/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9083 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.7696e-06\n",
      "Epoch 449/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.5927e-06\n",
      "Epoch 450/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.5927e-06\n",
      "Epoch 451/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9083 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.5927e-06\n",
      "Epoch 452/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.5927e-06\n",
      "Epoch 453/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.4334e-06\n",
      "Epoch 454/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.4334e-06\n",
      "Epoch 455/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.4334e-06\n",
      "Epoch 456/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.4334e-06\n",
      "Epoch 457/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.2901e-06\n",
      "Epoch 458/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.2901e-06\n",
      "Epoch 459/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.2901e-06\n",
      "Epoch 460/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.2901e-06\n",
      "Epoch 461/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.1611e-06\n",
      "Epoch 462/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.1611e-06\n",
      "Epoch 463/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.1611e-06\n",
      "Epoch 464/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.1611e-06\n",
      "Epoch 465/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.0450e-06\n",
      "Epoch 466/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.0450e-06\n",
      "Epoch 467/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.0450e-06\n",
      "Epoch 468/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.0450e-06\n",
      "Epoch 469/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 9.4046e-07\n",
      "Epoch 470/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 9.4046e-07\n",
      "Epoch 471/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 9.4046e-07\n",
      "Epoch 472/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 9.4046e-07\n",
      "Epoch 473/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 8.4642e-07\n",
      "Epoch 474/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9083 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 8.4642e-07\n",
      "Epoch 475/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 8.4642e-07\n",
      "Epoch 476/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 8.4642e-07\n",
      "Epoch 477/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 7.6177e-07\n",
      "Epoch 478/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 7.6177e-07\n",
      "Epoch 479/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 7.6177e-07\n",
      "Epoch 480/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 7.6177e-07\n",
      "Epoch 481/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 6.8560e-07\n",
      "Epoch 482/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 6.8560e-07\n",
      "Epoch 483/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 6.8560e-07\n",
      "Epoch 484/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 6.8560e-07\n",
      "Epoch 485/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 6.1704e-07\n",
      "Epoch 486/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 6.1704e-07\n",
      "Epoch 487/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9083 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 6.1704e-07\n",
      "Epoch 488/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9083 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 6.1704e-07\n",
      "Epoch 489/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 5.5533e-07\n",
      "Epoch 490/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9083 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 5.5533e-07\n",
      "Epoch 491/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 5.5533e-07\n",
      "Epoch 492/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 5.5533e-07\n",
      "Epoch 493/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9083 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 4.9980e-07\n",
      "Epoch 494/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 4.9980e-07\n",
      "Epoch 495/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 4.9980e-07\n",
      "Epoch 496/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 4.9980e-07\n",
      "Epoch 497/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 4.4982e-07\n",
      "Epoch 498/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 4.4982e-07\n",
      "Epoch 499/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 4.4982e-07\n",
      "Epoch 500/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 4.4982e-07\n",
      "Epoch 501/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 4.0484e-07\n",
      "Epoch 502/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 4.0484e-07\n",
      "Epoch 503/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9083 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 4.0484e-07\n",
      "Epoch 504/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 4.0484e-07\n",
      "Epoch 505/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 3.6435e-07\n",
      "Epoch 506/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 3.6435e-07\n",
      "Epoch 507/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 3.6435e-07\n",
      "Epoch 508/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 3.6435e-07\n",
      "Epoch 509/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 3.2792e-07\n",
      "Epoch 510/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 3.2792e-07\n",
      "Epoch 511/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 3.2792e-07\n",
      "Epoch 512/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 3.2792e-07\n",
      "Epoch 513/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9060 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.9513e-07\n",
      "Epoch 514/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.9513e-07\n",
      "Epoch 515/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.9513e-07\n",
      "Epoch 516/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.9513e-07\n",
      "Epoch 517/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.6561e-07\n",
      "Epoch 518/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.6561e-07\n",
      "Epoch 519/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.6561e-07\n",
      "Epoch 520/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.6561e-07\n",
      "Epoch 521/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.3905e-07\n",
      "Epoch 522/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.3905e-07\n",
      "Epoch 523/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.3905e-07\n",
      "Epoch 524/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.3905e-07\n",
      "Epoch 525/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.1515e-07\n",
      "Epoch 526/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.1515e-07\n",
      "Epoch 527/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.1515e-07\n",
      "Epoch 528/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.1515e-07\n",
      "Epoch 529/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.9363e-07\n",
      "Epoch 530/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.9363e-07\n",
      "Epoch 531/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.9363e-07\n",
      "Epoch 532/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.9363e-07\n",
      "Epoch 533/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.7427e-07\n",
      "Epoch 534/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.7427e-07\n",
      "Epoch 535/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.7427e-07\n",
      "Epoch 536/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.7427e-07\n",
      "Epoch 537/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9083 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.5684e-07\n",
      "Epoch 538/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.5684e-07\n",
      "Epoch 539/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.5684e-07\n",
      "Epoch 540/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.5684e-07\n",
      "Epoch 541/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.4116e-07\n",
      "Epoch 542/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.4116e-07\n",
      "Epoch 543/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.4116e-07\n",
      "Epoch 544/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.4116e-07\n",
      "Epoch 545/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.2704e-07\n",
      "Epoch 546/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.2704e-07\n",
      "Epoch 547/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.2704e-07\n",
      "Epoch 548/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9060 - negative_correlation_loss: -0.9083 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.2704e-07\n",
      "Epoch 549/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9083 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.1434e-07\n",
      "Epoch 550/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9083 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.1434e-07\n",
      "Epoch 551/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.1434e-07\n",
      "Epoch 552/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.1434e-07\n",
      "Epoch 553/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.0290e-07\n",
      "Epoch 554/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.0290e-07\n",
      "Epoch 555/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.0290e-07\n",
      "Epoch 556/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.0290e-07\n",
      "Epoch 557/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 9.2614e-08\n",
      "Epoch 558/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9060 - negative_correlation_loss: -0.9083 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 9.2614e-08\n",
      "Epoch 559/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 9.2614e-08\n",
      "Epoch 560/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 9.2614e-08\n",
      "Epoch 561/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 8.3352e-08\n",
      "Epoch 562/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 8.3352e-08\n",
      "Epoch 563/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 8.3352e-08\n",
      "Epoch 564/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 8.3352e-08\n",
      "Epoch 565/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 7.5017e-08\n",
      "Epoch 566/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 7.5017e-08\n",
      "Epoch 567/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 7.5017e-08\n",
      "Epoch 568/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 7.5017e-08\n",
      "Epoch 569/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 6.7516e-08\n",
      "Epoch 570/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 6.7516e-08\n",
      "Epoch 571/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 6.7516e-08\n",
      "Epoch 572/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 6.7516e-08\n",
      "Epoch 573/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9083 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 6.0764e-08\n",
      "Epoch 574/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 6.0764e-08\n",
      "Epoch 575/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 6.0764e-08\n",
      "Epoch 576/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 6.0764e-08\n",
      "Epoch 577/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 5.4688e-08\n",
      "Epoch 578/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9083 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 5.4688e-08\n",
      "Epoch 579/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 5.4688e-08\n",
      "Epoch 580/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 5.4688e-08\n",
      "Epoch 581/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 4.9219e-08\n",
      "Epoch 582/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 4.9219e-08\n",
      "Epoch 583/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9083 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 4.9219e-08\n",
      "Epoch 584/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 4.9219e-08\n",
      "Epoch 585/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9083 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 4.4297e-08\n",
      "Epoch 586/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 4.4297e-08\n",
      "Epoch 587/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9059 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 4.4297e-08\n",
      "Epoch 588/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 4.4297e-08\n",
      "Epoch 589/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 3.9867e-08\n",
      "Epoch 590/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 3.9867e-08\n",
      "Epoch 591/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 3.9867e-08\n",
      "Epoch 592/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 3.9867e-08\n",
      "Epoch 593/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 3.5881e-08\n",
      "Epoch 594/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 3.5881e-08\n",
      "Epoch 595/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9083 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 3.5881e-08\n",
      "Epoch 596/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 3.5881e-08\n",
      "Epoch 597/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 3.2292e-08\n",
      "Epoch 598/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 3.2292e-08\n",
      "Epoch 599/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 3.2292e-08\n",
      "Epoch 600/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 3.2292e-08\n",
      "Epoch 601/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.9063e-08\n",
      "Epoch 602/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.9063e-08\n",
      "Epoch 603/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.9063e-08\n",
      "Epoch 604/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.9063e-08\n",
      "Epoch 605/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9083 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.6157e-08\n",
      "Epoch 606/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9083 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.6157e-08\n",
      "Epoch 607/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.6157e-08\n",
      "Epoch 608/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.6157e-08\n",
      "Epoch 609/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9083 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.3541e-08\n",
      "Epoch 610/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.3541e-08\n",
      "Epoch 611/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9083 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.3541e-08\n",
      "Epoch 612/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.3541e-08\n",
      "Epoch 613/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.1187e-08\n",
      "Epoch 614/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.1187e-08\n",
      "Epoch 615/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.1187e-08\n",
      "Epoch 616/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 2.1187e-08\n",
      "Epoch 617/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.9068e-08\n",
      "Epoch 618/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.9068e-08\n",
      "Epoch 619/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.9068e-08\n",
      "Epoch 620/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9083 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.9068e-08\n",
      "Epoch 621/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.7162e-08\n",
      "Epoch 622/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.7162e-08\n",
      "Epoch 623/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9083 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.7162e-08\n",
      "Epoch 624/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9083 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.7162e-08\n",
      "Epoch 625/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.5445e-08\n",
      "Epoch 626/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.5445e-08\n",
      "Epoch 627/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.5445e-08\n",
      "Epoch 628/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.5445e-08\n",
      "Epoch 629/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.3901e-08\n",
      "Epoch 630/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.3901e-08\n",
      "Epoch 631/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.3901e-08\n",
      "Epoch 632/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.3901e-08\n",
      "Epoch 633/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.2511e-08\n",
      "Epoch 634/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.2511e-08\n",
      "Epoch 635/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.2511e-08\n",
      "Epoch 636/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.2511e-08\n",
      "Epoch 637/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.1260e-08\n",
      "Epoch 638/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.1260e-08\n",
      "Epoch 639/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.1260e-08\n",
      "Epoch 640/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.1260e-08\n",
      "Epoch 641/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.0134e-08\n",
      "Epoch 642/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.0134e-08\n",
      "Epoch 643/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9083 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.0134e-08\n",
      "Epoch 644/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 1.0134e-08\n",
      "Epoch 645/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 9.1203e-09\n",
      "Epoch 646/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 9.1203e-09\n",
      "Epoch 647/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 9.1203e-09\n",
      "Epoch 648/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 9.1203e-09\n",
      "Epoch 649/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9083 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 8.2083e-09\n",
      "Epoch 650/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 8.2083e-09\n",
      "Epoch 651/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 8.2083e-09\n",
      "Epoch 652/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9083 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 8.2083e-09\n",
      "Epoch 653/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9083 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 7.3875e-09\n",
      "Epoch 654/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9081 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 7.3875e-09\n",
      "Epoch 655/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9059 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 7.3875e-09\n",
      "Epoch 656/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 7.3875e-09\n",
      "Epoch 657/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 6.6487e-09\n",
      "Epoch 658/1000\n",
      "70/70 [==============================] - 1s 8ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 6.6487e-09\n",
      "Epoch 659/1000\n",
      "70/70 [==============================] - 1s 9ms/step - loss: -0.9060 - negative_correlation_loss: -0.9082 - val_loss: -0.9077 - val_negative_correlation_loss: -0.9098 - lr: 6.6487e-09\n",
      "INFO:tensorflow:Assets written to: ./submissions/model_overfit/assets\n",
      "model saved\n",
      "2219/2219 [==============================] - 2s 1ms/step\n",
      "CPU times: user 6min 24s, sys: 9.6 s, total: 6min 34s\n",
      "Wall time: 7min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "EPOCHS = 1000\n",
    "N_SPLITS = 3\n",
    "\n",
    "pred_train = np.zeros((Y.shape[0],Y.shape[1]))\n",
    "\n",
    "seed_tensorflow(1)\n",
    "score_list = []\n",
    "kf = GroupKFold(n_splits=N_SPLITS)\n",
    "score_list = []\n",
    "\n",
    "\n",
    "lr = ReduceLROnPlateau(\n",
    "                monitor = \"val_loss\",\n",
    "                factor = 0.9, \n",
    "                patience = 4, \n",
    "                verbose = VERBOSE)\n",
    "\n",
    "es = EarlyStopping(\n",
    "                monitor = \"val_loss\",\n",
    "                patience = 100, \n",
    "                verbose = VERBOSE,\n",
    "                mode = \"auto\", \n",
    "                restore_best_weights = True)\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "                filepath = './citeseq',\n",
    "                save_weights_only = True,\n",
    "                monitor = 'val_loss',\n",
    "                mode = 'min',\n",
    "                save_best_only = True)\n",
    "\n",
    "callbacks = [   lr, \n",
    "                es, \n",
    "                model_checkpoint_callback\n",
    "                ]\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.compile(\n",
    "            optimizer = tfa.optimizers.AdaBelief(LR_START),\n",
    "            metrics = [negative_correlation_loss],\n",
    "            loss = negative_correlation_loss\n",
    "             )\n",
    "# Training\n",
    "model.fit(\n",
    "            X,\n",
    "            Y, \n",
    "            validation_data=(\n",
    "                            X,\n",
    "                            Y), \n",
    "            epochs = EPOCHS,\n",
    "            verbose = 1,\n",
    "            batch_size = BATCH_SIZE,\n",
    "            shuffle = True,\n",
    "            callbacks = callbacks)\n",
    "\n",
    "\n",
    "model.load_weights('./citeseq')\n",
    "model.save(f\"./submissions/model_overfit\")\n",
    "print('model saved')\n",
    "\n",
    "#  Model validation\n",
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ea4a972c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2219/2219 [==============================] - 2s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ac93f6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mOof corr   = 0.90998\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "score_total = correlation_score(Y, std(y_pred))\n",
    "print(f\"{Fore.BLUE}{Style.BRIGHT}Oof corr   = {score_total:.5f}{Style.RESET_ALL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98cc203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f4a3a5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mOof corr   = 0.90998\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "score_total = correlation_score(Y, y_pred)\n",
    "print(f\"{Fore.BLUE}{Style.BRIGHT}Oof corr   = {score_total:.5f}{Style.RESET_ALL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c9eceb9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48663, 159)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xt = np.hstack((Xt[:,:feature_number_pca],X0t))\n",
    "Xt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "16d3ab17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70988, 159)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de73543c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1521/1521 [==============================] - 2s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_t = model.predict(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ab1b0c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_std = std(y_pred_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f98cbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leak data test\n",
      "0.9024454808047779\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"leak data test\")\n",
    "print(correlation_score(test_pred_std[:7476], Y[:7476]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "df4c1168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leak data test\n",
      "0.9024454808345322\n"
     ]
    }
   ],
   "source": [
    "print(\"leak data test\")\n",
    "print(correlation_score(y_pred_t[:7476], Y[:7476]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "81d500d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   33.,   346.,  2429.,  8588., 14300., 12513.,  6594.,  2913.,\n",
       "          868.,    79.]),\n",
       " array([-3.48455238, -3.10759401, -2.73063564, -2.35367751, -1.97671914,\n",
       "        -1.59976077, -1.2228024 , -0.84584409, -0.46888578, -0.09192745,\n",
       "         0.28503087]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.mean(X, axis=1))\n",
    "plt.hist(np.mean(Xt, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19876adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff62b20c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6757f0da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./submissions/model_0/assets\n",
      "model saved\n",
      "776/776 [==============================] - 1s 1ms/step\n",
      "Fold 0, correlation =  0.89002\n",
      "INFO:tensorflow:Assets written to: ./submissions/model_1/assets\n",
      "model saved\n",
      "750/750 [==============================] - 1s 1ms/step\n",
      "Fold 1, correlation =  0.89519\n",
      "INFO:tensorflow:Assets written to: ./submissions/model_2/assets\n",
      "model saved\n",
      "694/694 [==============================] - 1s 1ms/step\n",
      "Fold 2, correlation =  0.89154\n",
      "\u001b[32m\u001b[1mMean corr = 0.89225\u001b[0m\n",
      "\u001b[34m\u001b[1mOof corr   = 0.89224\u001b[0m\n",
      "CPU times: user 6min 2s, sys: 9.07 s, total: 6min 11s\n",
      "Wall time: 8min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "EPOCHS = 1100\n",
    "N_SPLITS = 3\n",
    "\n",
    "pred_train = np.zeros((Y.shape[0],Y.shape[1]))\n",
    "\n",
    "seed_tensorflow(20)\n",
    "score_list = []\n",
    "kf = GroupKFold(n_splits=N_SPLITS)\n",
    "score_list = []\n",
    "\n",
    "for fold, (idx_tr, idx_va) in enumerate(kf.split(X, groups=meta.donor)):\n",
    "    start_time = datetime.datetime.now()\n",
    "    model = None\n",
    "    gc.collect()\n",
    "    \n",
    "    X_tr = X[idx_tr]\n",
    "    y_tr = Y[idx_tr]\n",
    "    X_va = X[idx_va]\n",
    "    y_va = Y[idx_va]\n",
    "\n",
    "    lr = ReduceLROnPlateau(\n",
    "                    monitor = \"val_loss\",\n",
    "                    factor = 0.9, \n",
    "                    patience = 4, \n",
    "                    verbose = VERBOSE)\n",
    "\n",
    "    es = EarlyStopping(\n",
    "                    monitor = \"val_loss\",\n",
    "                    patience = 100, \n",
    "                    verbose = VERBOSE,\n",
    "                    mode = \"auto\", \n",
    "                    restore_best_weights = True)\n",
    "\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "                    filepath = './citeseq',\n",
    "                    save_weights_only = True,\n",
    "                    monitor = 'val_loss',\n",
    "                    mode = 'min',\n",
    "                    save_best_only = True)\n",
    "\n",
    "    callbacks = [   lr, \n",
    "                    es, \n",
    "                    model_checkpoint_callback\n",
    "                    ]\n",
    "    \n",
    "    model = create_model()\n",
    "    \n",
    "    model.compile(\n",
    "                optimizer = tfa.optimizers.AdaBelief(LR_START),\n",
    "                metrics = [negative_correlation_loss],\n",
    "                loss = negative_correlation_loss\n",
    "                 )\n",
    "    # Training\n",
    "    model.fit(\n",
    "                X_tr,\n",
    "                y_tr, \n",
    "                validation_data=(\n",
    "                                X_va,\n",
    "                                y_va), \n",
    "                epochs = EPOCHS,\n",
    "                verbose = VERBOSE,\n",
    "                batch_size = BATCH_SIZE,\n",
    "                shuffle = True,\n",
    "                callbacks = callbacks)\n",
    "\n",
    "    del X_tr, y_tr \n",
    "    gc.collect()\n",
    "    \n",
    "    model.load_weights('./citeseq')\n",
    "    model.save(f\"./submissions/model_{fold}\")\n",
    "    print('model saved')\n",
    "    \n",
    "    #  Model validation\n",
    "    y_va_pred = model.predict(X_va)\n",
    "    corrscore = correlation_score(y_va, y_va_pred)\n",
    "    pred_train[idx_va] = y_va_pred\n",
    "    \n",
    "    print(f\"Fold {fold}, correlation =  {corrscore:.5f}\")\n",
    "    del X_va, y_va, y_va_pred\n",
    "    gc.collect()\n",
    "    score_list.append(corrscore)\n",
    "\n",
    "# Show overall score\n",
    "\n",
    "print(f\"{Fore.GREEN}{Style.BRIGHT}Mean corr = {np.array(score_list).mean():.5f}{Style.RESET_ALL}\")\n",
    "score_total = correlation_score(Y, pred_train)\n",
    "print(f\"{Fore.BLUE}{Style.BRIGHT}Oof corr   = {score_total:.5f}{Style.RESET_ALL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bbae5a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize\n",
    "def std(x):\n",
    "    empty_list = []\n",
    "    for item in x:\n",
    "        empty_list.append((item - np.mean(item)) / np.std(item))\n",
    "    return np.array(empty_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4716e797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6ad1d8b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48663, 159)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xt = np.hstack((Xt[:,:feature_number_pca],X0t))\n",
    "Xt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3450aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with fold 0\n",
      "1521/1521 [==============================] - 2s 1ms/step\n",
      "Predicting with fold 1\n",
      "1521/1521 [==============================] - 2s 1ms/step\n",
      "Predicting with fold 2\n",
      "1521/1521 [==============================] - 2s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "test_pred = np.zeros((len(Xt), 140), dtype=np.float32)\n",
    "for fold in range(N_SPLITS):\n",
    "    print(f\"Predicting with fold {fold}\")\n",
    "    model = load_model(f\"./submissions/model_{fold}\",\n",
    "                       custom_objects={'negative_correlation_loss': negative_correlation_loss})\n",
    "    test_pred += model.predict(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f3a47e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = std(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "34a39052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leak data test\n",
      "0.899392900022741\n"
     ]
    }
   ],
   "source": [
    "print(\"leak data test\")\n",
    "print(correlation_score(test_pred[:7476], Y[:7476]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1586c8c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fec91954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71106ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.46045294e-02 -1.62362412e-01 -4.05331880e-01 ... -2.60497332e-01\n",
      "   3.83257687e-01 -1.97452575e-01]\n",
      " [-2.51250833e-01 -3.57970536e-01 -1.62689015e-01 ... -1.95552424e-01\n",
      "   4.02629942e-01  2.14246258e-01]\n",
      " [-5.04534721e-01 -5.27179182e-01 -6.66114271e-01 ... -7.89938033e-01\n",
      "   9.85862136e-01  6.09520316e-01]\n",
      " ...\n",
      " [-8.62916565e+01 -2.20725060e+01 -4.64350700e+01 ... -7.80430603e+01\n",
      "  -5.89678841e+01  7.87515030e+01]\n",
      " [-8.09841309e+01 -6.77171555e+01 -4.02865067e+01 ... -7.46594925e+01\n",
      "   2.32017578e+02  1.02085007e+02]\n",
      " [-7.74072113e+01 -6.09491806e+01 -3.83022118e+01 ... -7.22794113e+01\n",
      "   2.72235046e+02  1.15302826e+02]]\n",
      "[[ 0.09460448 -0.16236246 -0.40533194 ... -0.2604974   0.38325763\n",
      "  -0.19745262]\n",
      " [-0.2512508  -0.3579705  -0.16268899 ... -0.1955524   0.40262997\n",
      "   0.21424629]\n",
      " [-0.50453466 -0.5271791  -0.6661142  ... -0.789938    0.9858622\n",
      "   0.6095204 ]\n",
      " ...\n",
      " [-0.40628484 -0.06481007 -0.19435398 ... -0.36242428 -0.26099515\n",
      "   0.471305  ]\n",
      " [-0.5943697  -0.49119973 -0.2778867  ... -0.5451864   1.8396721\n",
      "   0.8292581 ]\n",
      " [-0.57534915 -0.44713783 -0.27071348 ... -0.5354026   2.1484332\n",
      "   0.92590004]]\n"
     ]
    }
   ],
   "source": [
    "test_pred[:7476] = Y[:7476]\n",
    "print(test_pred)\n",
    "test_pred = std(test_pred)\n",
    "print(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a935adbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fbe3a1d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_id\n",
       "0           0.094604\n",
       "1          -0.162362\n",
       "2          -0.405332\n",
       "3          -0.302582\n",
       "4           1.114355\n",
       "              ...   \n",
       "65744175    2.777528\n",
       "65744176   -0.369145\n",
       "65744177   -0.367802\n",
       "65744178    0.135783\n",
       "65744179    2.558738\n",
       "Name: target, Length: 65744180, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "submission = pd.read_csv(\"/ysm-gpfs/pi/zhao/tl688/openproblems/submission_testourcite.csv\",index_col='row_id', squeeze=True)\n",
    "submission.iloc[:len(test_pred.ravel())] = test_pred.ravel()\n",
    "assert not submission.isna().any()\n",
    "\n",
    "submission.to_csv('submission_onebestcite_cpu.csv')\n",
    "display(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc13f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb2785f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddebb5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with fold 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/gpfs/ysm/project/zhao/tl688/conda_envs/tf117/lib/python3.9/site-packages/keras/engine/training.py\", line 2041, in predict_function  *\n        return step_function(self, iterator)\n    File \"/gpfs/ysm/project/zhao/tl688/conda_envs/tf117/lib/python3.9/site-packages/keras/engine/training.py\", line 2027, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/gpfs/ysm/project/zhao/tl688/conda_envs/tf117/lib/python3.9/site-packages/keras/engine/training.py\", line 2015, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/gpfs/ysm/project/zhao/tl688/conda_envs/tf117/lib/python3.9/site-packages/keras/engine/training.py\", line 1983, in predict_step\n        return self(x, training=False)\n    File \"/gpfs/ysm/project/zhao/tl688/conda_envs/tf117/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/gpfs/ysm/project/zhao/tl688/conda_envs/tf117/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 159), found shape=(None, 512)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicting with fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m     model \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./submissions/model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m                        custom_objects\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative_correlation_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: negative_correlation_loss})\n\u001b[0;32m----> 6\u001b[0m     test_pred \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Copy the targets for the data leak but useless since the change in the public LB...\u001b[39;00m\n\u001b[1;32m      9\u001b[0m test_pred[:\u001b[38;5;241m7476\u001b[39m] \u001b[38;5;241m=\u001b[39m Y[:\u001b[38;5;241m7476\u001b[39m]\n",
      "File \u001b[0;32m/gpfs/ysm/project/zhao/tl688/conda_envs/tf117/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileij1mrqb4.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/gpfs/ysm/project/zhao/tl688/conda_envs/tf117/lib/python3.9/site-packages/keras/engine/training.py\", line 2041, in predict_function  *\n        return step_function(self, iterator)\n    File \"/gpfs/ysm/project/zhao/tl688/conda_envs/tf117/lib/python3.9/site-packages/keras/engine/training.py\", line 2027, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/gpfs/ysm/project/zhao/tl688/conda_envs/tf117/lib/python3.9/site-packages/keras/engine/training.py\", line 2015, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/gpfs/ysm/project/zhao/tl688/conda_envs/tf117/lib/python3.9/site-packages/keras/engine/training.py\", line 1983, in predict_step\n        return self(x, training=False)\n    File \"/gpfs/ysm/project/zhao/tl688/conda_envs/tf117/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/gpfs/ysm/project/zhao/tl688/conda_envs/tf117/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 159), found shape=(None, 512)\n"
     ]
    }
   ],
   "source": [
    "test_pred = np.zeros((len(Xt), 140), dtype=np.float32)\n",
    "for fold in range(N_SPLITS):\n",
    "    print(f\"Predicting with fold {fold}\")\n",
    "    model = load_model(f\"./submissions/model_{fold}\",\n",
    "                       custom_objects={'negative_correlation_loss': negative_correlation_loss})\n",
    "    test_pred += model.predict(Xt)\n",
    "\n",
    "# Copy the targets for the data leak but useless since the change in the public LB...\n",
    "test_pred[:7476] = Y[:7476]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6304474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fbc95b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb685357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23480eb5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "INFO:tensorflow:Assets written to: ./submissions/model_0_20/assets\n",
      "model saved\n",
      "776/776 [==============================] - 1s 1ms/step\n",
      "Fold 0, correlation =  0.89232\n",
      "INFO:tensorflow:Assets written to: ./submissions/model_1_20/assets\n",
      "model saved\n",
      "750/750 [==============================] - 1s 1ms/step\n",
      "Fold 1, correlation =  0.89699\n",
      "INFO:tensorflow:Assets written to: ./submissions/model_2_20/assets\n",
      "model saved\n",
      "694/694 [==============================] - 1s 1ms/step\n",
      "Fold 2, correlation =  0.89415\n",
      "\u001b[32m\u001b[1mMean corr = 0.89449\u001b[0m\n",
      "\u001b[34m\u001b[1mOof corr   = 0.89447\u001b[0m\n",
      "21\n",
      "INFO:tensorflow:Assets written to: ./submissions/model_0_21/assets\n",
      "model saved\n",
      "776/776 [==============================] - 1s 1ms/step\n",
      "Fold 0, correlation =  0.89192\n",
      "INFO:tensorflow:Assets written to: ./submissions/model_1_21/assets\n",
      "model saved\n",
      "750/750 [==============================] - 1s 999us/step\n",
      "Fold 1, correlation =  0.89730\n",
      "INFO:tensorflow:Assets written to: ./submissions/model_2_21/assets\n",
      "model saved\n",
      "694/694 [==============================] - 1s 999us/step\n",
      "Fold 2, correlation =  0.89336\n",
      "\u001b[32m\u001b[1mMean corr = 0.89419\u001b[0m\n",
      "\u001b[34m\u001b[1mOof corr   = 0.89419\u001b[0m\n",
      "22\n",
      "INFO:tensorflow:Assets written to: ./submissions/model_0_22/assets\n",
      "model saved\n",
      "776/776 [==============================] - 1s 987us/step\n",
      "Fold 0, correlation =  0.89198\n",
      "INFO:tensorflow:Assets written to: ./submissions/model_1_22/assets\n",
      "model saved\n",
      "750/750 [==============================] - 1s 989us/step\n",
      "Fold 1, correlation =  0.89723\n",
      "INFO:tensorflow:Assets written to: ./submissions/model_2_22/assets\n",
      "model saved\n",
      "694/694 [==============================] - 1s 988us/step\n",
      "Fold 2, correlation =  0.89359\n",
      "\u001b[32m\u001b[1mMean corr = 0.89426\u001b[0m\n",
      "\u001b[34m\u001b[1mOof corr   = 0.89426\u001b[0m\n",
      "23\n",
      "INFO:tensorflow:Assets written to: ./submissions/model_0_23/assets\n",
      "model saved\n",
      "776/776 [==============================] - 1s 993us/step\n",
      "Fold 0, correlation =  0.89227\n",
      "INFO:tensorflow:Assets written to: ./submissions/model_1_23/assets\n",
      "model saved\n",
      "750/750 [==============================] - 1s 991us/step\n",
      "Fold 1, correlation =  0.89710\n",
      "INFO:tensorflow:Assets written to: ./submissions/model_2_23/assets\n",
      "model saved\n",
      "694/694 [==============================] - 1s 992us/step\n",
      "Fold 2, correlation =  0.89386\n",
      "\u001b[32m\u001b[1mMean corr = 0.89441\u001b[0m\n",
      "\u001b[34m\u001b[1mOof corr   = 0.89440\u001b[0m\n",
      "24\n",
      "INFO:tensorflow:Assets written to: ./submissions/model_0_24/assets\n",
      "model saved\n",
      "776/776 [==============================] - 1s 995us/step\n",
      "Fold 0, correlation =  0.89190\n",
      "INFO:tensorflow:Assets written to: ./submissions/model_1_24/assets\n",
      "model saved\n",
      "750/750 [==============================] - 1s 989us/step\n",
      "Fold 1, correlation =  0.89706\n",
      "INFO:tensorflow:Assets written to: ./submissions/model_2_24/assets\n",
      "model saved\n",
      "694/694 [==============================] - 1s 989us/step\n",
      "Fold 2, correlation =  0.89418\n",
      "\u001b[32m\u001b[1mMean corr = 0.89438\u001b[0m\n",
      "\u001b[34m\u001b[1mOof corr   = 0.89436\u001b[0m\n",
      "25\n",
      "INFO:tensorflow:Assets written to: ./submissions/model_0_25/assets\n",
      "model saved\n",
      "776/776 [==============================] - 1s 999us/step\n",
      "Fold 0, correlation =  0.89209\n",
      "INFO:tensorflow:Assets written to: ./submissions/model_1_25/assets\n",
      "model saved\n",
      "750/750 [==============================] - 1s 1ms/step\n",
      "Fold 1, correlation =  0.89696\n",
      "INFO:tensorflow:Assets written to: ./submissions/model_2_25/assets\n",
      "model saved\n",
      "694/694 [==============================] - 1s 993us/step\n",
      "Fold 2, correlation =  0.89355\n",
      "\u001b[32m\u001b[1mMean corr = 0.89420\u001b[0m\n",
      "\u001b[34m\u001b[1mOof corr   = 0.89419\u001b[0m\n",
      "26\n",
      "INFO:tensorflow:Assets written to: ./submissions/model_0_26/assets\n",
      "model saved\n",
      "776/776 [==============================] - 1s 998us/step\n",
      "Fold 0, correlation =  0.89188\n",
      "INFO:tensorflow:Assets written to: ./submissions/model_1_26/assets\n",
      "model saved\n",
      "750/750 [==============================] - 1s 993us/step\n",
      "Fold 1, correlation =  0.89701\n",
      "INFO:tensorflow:Assets written to: ./submissions/model_2_26/assets\n",
      "model saved\n",
      "694/694 [==============================] - 1s 988us/step\n",
      "Fold 2, correlation =  0.89432\n",
      "\u001b[32m\u001b[1mMean corr = 0.89440\u001b[0m\n",
      "\u001b[34m\u001b[1mOof corr   = 0.89438\u001b[0m\n",
      "27\n",
      "INFO:tensorflow:Assets written to: ./submissions/model_0_27/assets\n",
      "model saved\n",
      "776/776 [==============================] - 1s 996us/step\n",
      "Fold 0, correlation =  0.89179\n",
      "INFO:tensorflow:Assets written to: ./submissions/model_1_27/assets\n",
      "model saved\n",
      "750/750 [==============================] - 1s 994us/step\n",
      "Fold 1, correlation =  0.89724\n",
      "INFO:tensorflow:Assets written to: ./submissions/model_2_27/assets\n",
      "model saved\n",
      "694/694 [==============================] - 1s 996us/step\n",
      "Fold 2, correlation =  0.89377\n",
      "\u001b[32m\u001b[1mMean corr = 0.89427\u001b[0m\n",
      "\u001b[34m\u001b[1mOof corr   = 0.89425\u001b[0m\n",
      "28\n",
      "INFO:tensorflow:Assets written to: ./submissions/model_0_28/assets\n",
      "model saved\n",
      "776/776 [==============================] - 1s 997us/step\n",
      "Fold 0, correlation =  0.89180\n",
      "INFO:tensorflow:Assets written to: ./submissions/model_1_28/assets\n",
      "model saved\n",
      "750/750 [==============================] - 1s 991us/step\n",
      "Fold 1, correlation =  0.89671\n",
      "INFO:tensorflow:Assets written to: ./submissions/model_2_28/assets\n",
      "model saved\n",
      "694/694 [==============================] - 1s 1ms/step\n",
      "Fold 2, correlation =  0.89371\n",
      "\u001b[32m\u001b[1mMean corr = 0.89407\u001b[0m\n",
      "\u001b[34m\u001b[1mOof corr   = 0.89406\u001b[0m\n",
      "29\n",
      "INFO:tensorflow:Assets written to: ./submissions/model_0_29/assets\n",
      "model saved\n",
      "776/776 [==============================] - 1s 998us/step\n",
      "Fold 0, correlation =  0.89220\n",
      "INFO:tensorflow:Assets written to: ./submissions/model_1_29/assets\n",
      "model saved\n",
      "750/750 [==============================] - 1s 997us/step\n",
      "Fold 1, correlation =  0.89662\n",
      "INFO:tensorflow:Assets written to: ./submissions/model_2_29/assets\n",
      "model saved\n",
      "694/694 [==============================] - 1s 999us/step\n",
      "Fold 2, correlation =  0.89390\n",
      "\u001b[32m\u001b[1mMean corr = 0.89424\u001b[0m\n",
      "\u001b[34m\u001b[1mOof corr   = 0.89422\u001b[0m\n",
      "CPU times: user 57min 25s, sys: 1min 24s, total: 58min 50s\n",
      "Wall time: 1h 17min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# test seed\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "EPOCHS = 1100\n",
    "N_SPLITS = 3\n",
    "\n",
    "for seed in range(20,30):\n",
    "    print(seed)\n",
    "    pred_train = np.zeros((Y.shape[0],Y.shape[1]))\n",
    "\n",
    "    seed_tensorflow(seed)\n",
    "    score_list = []\n",
    "    kf = GroupKFold(n_splits=N_SPLITS)\n",
    "    score_list = []\n",
    "\n",
    "    for fold, (idx_tr, idx_va) in enumerate(kf.split(X, groups=meta.donor)):\n",
    "        start_time = datetime.datetime.now()\n",
    "        model = None\n",
    "        gc.collect()\n",
    "\n",
    "        X_tr = X[idx_tr]\n",
    "        y_tr = Y[idx_tr]\n",
    "        X_va = X[idx_va]\n",
    "        y_va = Y[idx_va]\n",
    "\n",
    "        lr = ReduceLROnPlateau(\n",
    "                        monitor = \"val_loss\",\n",
    "                        factor = 0.9, \n",
    "                        patience = 4, \n",
    "                        verbose = VERBOSE)\n",
    "\n",
    "        es = EarlyStopping(\n",
    "                        monitor = \"val_loss\",\n",
    "                        patience = 100, \n",
    "                        verbose = VERBOSE,\n",
    "                        mode = \"auto\", \n",
    "                        restore_best_weights = True)\n",
    "\n",
    "        model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "                        filepath = './citeseq',\n",
    "                        save_weights_only = True,\n",
    "                        monitor = 'val_loss',\n",
    "                        mode = 'min',\n",
    "                        save_best_only = True)\n",
    "\n",
    "        callbacks = [   lr, \n",
    "                        es, \n",
    "                        model_checkpoint_callback\n",
    "                        ]\n",
    "\n",
    "        model = create_model()\n",
    "\n",
    "        model.compile(\n",
    "                    optimizer = tfa.optimizers.AdaBelief(LR_START),\n",
    "                    metrics = [negative_correlation_loss],\n",
    "                    loss = negative_correlation_loss\n",
    "                     )\n",
    "        # Training\n",
    "        model.fit(\n",
    "                    X_tr,\n",
    "                    y_tr, \n",
    "                    validation_data=(\n",
    "                                    X_va,\n",
    "                                    y_va), \n",
    "                    epochs = EPOCHS,\n",
    "                    verbose = VERBOSE,\n",
    "                    batch_size = BATCH_SIZE,\n",
    "                    shuffle = True,\n",
    "                    callbacks = callbacks)\n",
    "\n",
    "        del X_tr, y_tr \n",
    "        gc.collect()\n",
    "\n",
    "        model.load_weights('./citeseq')\n",
    "        model.save(f\"./submissions/model_{fold}_{seed}\")\n",
    "        print('model saved')\n",
    "\n",
    "        #  Model validation\n",
    "        y_va_pred = model.predict(X_va)\n",
    "        corrscore = correlation_score(y_va, y_va_pred)\n",
    "        pred_train[idx_va] = y_va_pred\n",
    "\n",
    "        print(f\"Fold {fold}, correlation =  {corrscore:.5f}\")\n",
    "        del X_va, y_va, y_va_pred\n",
    "        gc.collect()\n",
    "        score_list.append(corrscore)\n",
    "\n",
    "    # Show overall score\n",
    "\n",
    "    print(f\"{Fore.GREEN}{Style.BRIGHT}Mean corr = {np.array(score_list).mean():.5f}{Style.RESET_ALL}\")\n",
    "    score_total = correlation_score(Y, pred_train)\n",
    "    print(f\"{Fore.BLUE}{Style.BRIGHT}Oof corr   = {score_total:.5f}{Style.RESET_ALL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51589c55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d7333841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48663, 159)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xt = np.hstack((Xt[:,:feature_number_pca],X0t))\n",
    "Xt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce38bf3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67d3876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb43cf2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eaf6bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9db7afe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with fold 0\n",
      "1378/1521 [==========================>...] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pred = np.zeros((len(Xt), 140), dtype=np.float32)\n",
    "for fold in range(N_SPLITS):\n",
    "    print(f\"Predicting with fold {fold}\")\n",
    "    model = load_model(f\"./submissions/model_{fold}\",\n",
    "                       custom_objects={'negative_correlation_loss': negative_correlation_loss})\n",
    "    test_pred += model.predict(Xt)\n",
    "\n",
    "# Copy the targets for the data leak but useless since the change in the public LB...\n",
    "test_pred[:7476] = Y[:7476]\n",
    "\n",
    "# from Juan Smith Perera to complete with the Multiome part :\n",
    "# submission = pd.read_csv('submission_lolo_1.csv',index_col='row_id', squeeze=True)\n",
    "submission = pd.read_csv('submission.csv',index_col='row_id', squeeze=True)\n",
    "submission.iloc[:len(test_pred.ravel())] = test_pred.ravel()\n",
    "assert not submission.isna().any()\n",
    "\n",
    "submission.to_csv('submission.csv')\n",
    "display(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d4caa9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48663"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c7cbfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_atac = pd.read_csv(\"./openproblems/ensemble_eri812.csv\", index_col=0) #your result 0.812\n",
    "submit_cite = pd.read_csv(\"./openproblems/submission.csv\", index_col=0) #my result 0.813\n",
    "\n",
    "submit_atac.iloc[0:len(Xt)] = submit_cite.iloc[0:len(Xt)].copy()\n",
    "\n",
    "submit_atac.to_csv(\"submission_ensemble.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d17300",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9fb96d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./input/targets-multiome-sparse-scaled/INDEX_train_multiome.pkl','rb') as f: INDEX_train_multiome = pickle.load(f)\n",
    "with open('./input/targets-multiome-sparse-scaled/train_512.pkl','rb') as f: X = pickle.load(f)\n",
    "with open('./input/targets-multiome-sparse-scaled/pca_train_512.pkl','rb') as f: pca_train = pickle.load(f)\n",
    "with open('./input/targets-multiome-sparse-scaled/pca_target_512.pkl','rb') as f: pca_target = pickle.load(f)\n",
    "with open('./input/targets-multiome-sparse-scaled/Y_512.pkl','rb') as f: Y = pickle.load(f)\n",
    "    \n",
    "# # for ga\n",
    "# with open('./input/targets-multiome-sparse-scaled/INDEX_train_multiome.pkl','rb') as f: INDEX_train_multiome = pickle.load(f)\n",
    "# with open('./input/targets-multiome-sparse-scaled/train_ga_512.pkl','rb') as f: X = pickle.load(f)\n",
    "# with open('./input/targets-multiome-sparse-scaled/pca_train_ga_512.pkl','rb') as f: pca_train = pickle.load(f)\n",
    "# with open('./input/targets-multiome-sparse-scaled/pca_target_512.pkl','rb') as f: pca_target = pickle.load(f)\n",
    "# with open('./input/targets-multiome-sparse-scaled/Y_512.pkl','rb') as f: Y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b28547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0af4ad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_num_multi = 40 #original: 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48f40a00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105942, 40)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X[:,:feature_num_multi]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "60696e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.read_csv('metadata.csv',index_col='cell_id')\n",
    "metadata_df = metadata_df[metadata_df.technology==\"multiome\"]\n",
    "meta = metadata_df.reindex(INDEX_train_multiome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38a6bdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_START = 1e-3\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "def create_model():\n",
    "    \n",
    "    reg1 = 9.613e-06\n",
    "    reg2 = 1e-07\n",
    "    REG1 = tf.keras.regularizers.l2(reg1)\n",
    "    REG2 = tf.keras.regularizers.l2(reg2)\n",
    "    DROP = 0.1\n",
    "\n",
    "    activation = 'selu'\n",
    "    inputs = Input(shape =(X.shape[1],))\n",
    "\n",
    "    x0 = Dense(512, \n",
    "              kernel_regularizer = REG1,\n",
    "              activation = activation,\n",
    "             )(inputs)\n",
    "    \n",
    "\n",
    "    x0 = Dropout(DROP)(x0)\n",
    "    \n",
    "    \n",
    "    x1 = Dense(512, \n",
    "               kernel_regularizer = REG1,\n",
    "               activation = activation,\n",
    "             )(x0)\n",
    "    \n",
    "\n",
    "    x1 = Dropout(DROP)(x1)\n",
    "    \n",
    "    \n",
    "    x2 = Dense(512, \n",
    "               kernel_regularizer = REG1,\n",
    "               activation = activation,\n",
    "             )(x1+x0)\n",
    "    \n",
    "\n",
    "    x2= Dropout(DROP)(x2)\n",
    "    \n",
    "    x3 = Dense(Y.shape[1],\n",
    "               kernel_regularizer = REG1,\n",
    "               activation = activation,\n",
    "             )(x2+x1)\n",
    "    \n",
    "\n",
    "    x3 = Dropout(DROP)(x3)\n",
    "\n",
    "    x = Concatenate()([\n",
    "                x0, \n",
    "                x1, \n",
    "                x2, \n",
    "                x3\n",
    "                ])\n",
    "       \n",
    "    x = Dense(Y.shape[1], \n",
    "                kernel_regularizer = REG2,\n",
    "                activation='linear',\n",
    "                )(x)\n",
    "    \n",
    "    x_out = Dense(Y.shape[1], \n",
    "            kernel_regularizer = REG2,\n",
    "            activation='linear',\n",
    "            )(inputs)\n",
    "    \n",
    "    x = x + x_out\n",
    "    \n",
    "    \n",
    "    model = Model(inputs, x)\n",
    "    \n",
    "\n",
    "    return model\n",
    "\n",
    "# #original model\n",
    "# LR_START = 1e-3\n",
    "# BATCH_SIZE = 512\n",
    "\n",
    "# def create_model():\n",
    "    \n",
    "#     reg1 = 9.613e-06\n",
    "#     reg2 = 1e-07\n",
    "#     REG1 = tf.keras.regularizers.l2(reg1)\n",
    "#     REG2 = tf.keras.regularizers.l2(reg2)\n",
    "#     DROP = 0.1\n",
    "\n",
    "#     activation = 'selu'\n",
    "#     inputs = Input(shape =(X.shape[1],))\n",
    "\n",
    "#     x0 = Dense(256, \n",
    "#               kernel_regularizer = REG1,\n",
    "#               activation = activation,\n",
    "#              )(inputs)\n",
    "#     x0 = Dropout(DROP)(x0)\n",
    "    \n",
    "    \n",
    "#     x1 = Dense(512, \n",
    "#                kernel_regularizer = REG1,\n",
    "#                activation = activation,\n",
    "#              )(x0)\n",
    "#     x1 = Dropout(DROP)(x1)\n",
    "    \n",
    "    \n",
    "#     x2 = Dense(512, \n",
    "#                kernel_regularizer = REG1,\n",
    "#                activation = activation,\n",
    "#              )(x1) \n",
    "#     x2= Dropout(DROP)(x2)\n",
    "    \n",
    "#     x3 = Dense(Y.shape[1],\n",
    "#                kernel_regularizer = REG1,\n",
    "#                activation = activation,\n",
    "#              )(x2)\n",
    "#     x3 = Dropout(DROP)(x3)\n",
    "\n",
    "         \n",
    "#     x = Concatenate()([\n",
    "#                 x0, \n",
    "#                 x1, \n",
    "#                 x2, \n",
    "#                 x3\n",
    "#                 ])\n",
    "    \n",
    "#     x = Dense(Y.shape[1], \n",
    "#                 kernel_regularizer = REG2,\n",
    "#                 activation='linear',\n",
    "#                 )(x)\n",
    "    \n",
    "    \n",
    "#     model = Model(inputs, x)\n",
    "    \n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "36e4a8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_tuning(hp, n_inputs=X.shape[1]):\n",
    "    \n",
    "#     reg1 = 9.613e-06\n",
    "#     reg2 = 1e-07\n",
    "    reg1 = hp.Float(\"reg1\", min_value=1e-8, max_value=1e-4, sampling=\"log\")\n",
    "    reg2 = hp.Float(\"reg2\", min_value=1e-10, max_value=1e-5, sampling=\"log\")\n",
    "    REG1 = tf.keras.regularizers.l2(reg1)\n",
    "    REG2 = tf.keras.regularizers.l2(reg2)\n",
    "    DROP = 0.1\n",
    "\n",
    "    activation = 'selu'\n",
    "    inputs = Input(shape =(X.shape[1],))\n",
    "\n",
    "    x0 = Dense(512, \n",
    "              kernel_regularizer = REG1,\n",
    "              activation = activation,\n",
    "             )(inputs)\n",
    "    \n",
    "\n",
    "    x0 = Dropout(DROP)(x0)\n",
    "    \n",
    "    \n",
    "    x1 = Dense(512, \n",
    "               kernel_regularizer = REG1,\n",
    "               activation = activation,\n",
    "             )(x0)\n",
    "    \n",
    "\n",
    "    x1 = Dropout(DROP)(x1)\n",
    "    \n",
    "    \n",
    "    x2 = Dense(512, \n",
    "               kernel_regularizer = REG1,\n",
    "               activation = activation,\n",
    "             )(x1+x0)\n",
    "    \n",
    "\n",
    "    x2= Dropout(DROP)(x2)\n",
    "    \n",
    "    x3 = Dense(Y.shape[1],\n",
    "               kernel_regularizer = REG1,\n",
    "               activation = activation,\n",
    "             )(x2+x1)\n",
    "    \n",
    "\n",
    "    x3 = Dropout(DROP)(x3)\n",
    "\n",
    "    x = Concatenate()([\n",
    "                x0, \n",
    "                x1, \n",
    "                x2, \n",
    "                x3\n",
    "                ])\n",
    "       \n",
    "    x = Dense(Y.shape[1], \n",
    "                kernel_regularizer = REG2,\n",
    "                activation='linear',\n",
    "                )(x)\n",
    "    \n",
    "    x_out = Dense(Y.shape[1], \n",
    "            kernel_regularizer = REG2,\n",
    "            activation='linear',\n",
    "            )(inputs)\n",
    "    \n",
    "    x = Dense(Y.shape[1], \n",
    "            kernel_regularizer = REG2,\n",
    "            activation='linear',\n",
    "            )(x+x_out)\n",
    "    \n",
    "    model = Model(inputs, x)\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp.Choice('best_lr', [1e-2, 1e-3, 1e-4])),\n",
    "                    metrics=[negative_correlation_loss],\n",
    "                      loss=\"mse\")\n",
    "    \n",
    "    \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb4b1ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "81e6c50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TUNE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7c3a3b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15 µs, sys: 0 ns, total: 15 µs\n",
      "Wall time: 23.4 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if TUNE:\n",
    "    tuner = keras_tuner.BayesianOptimization(\n",
    "        create_model_tuning,\n",
    "        overwrite=True,\n",
    "        objective=keras_tuner.Objective(\"val_negative_correlation_loss\", direction=\"min\"),\n",
    "        max_trials=100,\n",
    "        directory='./temp_kaggle',\n",
    "        seed=1)\n",
    "    lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, \n",
    "                           patience=4, verbose=0)\n",
    "    es = EarlyStopping(monitor=\"val_loss\",\n",
    "                       patience=12, \n",
    "                       verbose=0,\n",
    "                       mode=\"min\", \n",
    "                       restore_best_weights=True)\n",
    "    callbacks = [lr, es, tf.keras.callbacks.TerminateOnNaN()]\n",
    "    X_tr, X_va, y_tr, y_va = train_test_split(X, Y, test_size=0.2, random_state=10)\n",
    "    tuner.search(X_tr, y_tr,\n",
    "                 epochs=500,\n",
    "                 validation_data=(X_va, y_va),\n",
    "                 batch_size=BATCH_SIZE,\n",
    "                 callbacks=callbacks, verbose=2)\n",
    "    del X_tr, X_va, y_tr, y_va, lr, es, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dae76972",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TUNE:\n",
    "    tuner.results_summary()\n",
    "    \n",
    "    # Table of the 10 best trials\n",
    "    display(pd.DataFrame([hp.values for hp in tuner.get_best_hyperparameters(10)]))\n",
    "    \n",
    "    # Keep the best hyperparameters\n",
    "    best_hp = tuner.get_best_hyperparameters(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "244214c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1152/1152 [==============================] - 1s 963us/step\n",
      "\n",
      " --------- FOLD 0 -----------\n",
      "Mean squared error = 3.299999952316284\n",
      "correlation value = 0.92\n",
      "INFO:tensorflow:Assets written to: model_0/assets\n",
      "model saved : model_0\n",
      "1107/1107 [==============================] - 1s 955us/step\n",
      "\n",
      " --------- FOLD 1 -----------\n",
      "Mean squared error = 3.1700000762939453\n",
      "correlation value = 0.93\n",
      "INFO:tensorflow:Assets written to: model_1/assets\n",
      "model saved : model_1\n",
      "1054/1054 [==============================] - 1s 963us/step\n",
      "\n",
      " --------- FOLD 2 -----------\n",
      "Mean squared error = 3.200000047683716\n",
      "correlation value = 0.93\n",
      "INFO:tensorflow:Assets written to: model_2/assets\n",
      "model saved : model_2\n",
      "CPU times: user 12min 32s, sys: 41.5 s, total: 13min 14s\n",
      "Wall time: 15min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "N_SPLIT = 3\n",
    "\n",
    "\n",
    "# np.random.seed(1)\n",
    "# tf.random.set_seed(1)\n",
    "seed_tensorflow()\n",
    "\n",
    "#kf = KFold(n_splits=N_SPLIT, shuffle=True, random_state=42)\n",
    "kf = GroupKFold(n_splits = N_SPLIT)\n",
    "\n",
    "for fold,(idx_tr, idx_va) in enumerate(kf.split(X,groups=meta.donor)):\n",
    "    \n",
    "    X_tr = X[idx_tr]\n",
    "    y_tr = Y[idx_tr]\n",
    "    \n",
    "    X_va = X[idx_va]\n",
    "    y_va = Y[idx_va] \n",
    "    \n",
    "    model = create_model()\n",
    "    \n",
    "    lr = ReduceLROnPlateau(\n",
    "                monitor = \"val_loss\",\n",
    "                factor = 0.9, \n",
    "                patience = 4, \n",
    "                verbose = VERBOSE)\n",
    "    \n",
    "    es = EarlyStopping(\n",
    "                monitor = \"val_loss\",\n",
    "                patience = 100, \n",
    "                verbose = VERBOSE,\n",
    "                mode = \"min\", \n",
    "                restore_best_weights = True)\n",
    "\n",
    "    model.compile(optimizer= tfa.optimizers.AdaBelief(learning_rate=LR_START),\n",
    "                  loss = 'mse',\n",
    "                  metrics=None)\n",
    "    model.fit(X_tr,\n",
    "              y_tr,\n",
    "              validation_data=(X_va,y_va),\n",
    "              epochs =3500, \n",
    "              verbose = VERBOSE,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              callbacks = [es,lr]\n",
    "             )\n",
    "    pred = model.predict(X_va)\n",
    "    \n",
    "    print(f'\\n --------- FOLD {fold} -----------')\n",
    "    print(f'Mean squared error = {np.round(mean_squared_error(y_va,pred),2)}')\n",
    "    print(f'correlation value = {np.round(correlation_score(y_va,pred),2)}')\n",
    "   \n",
    "    filename = f\"model_{fold}\"\n",
    "    model.save(filename)\n",
    "    print('model saved :',filename)\n",
    "        \n",
    "    del X_tr,X_va,y_tr,y_va\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90312c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_test_x = scipy.sparse.load_npz(\"./input/multimodal-single-cell-as-sparse-matrix/test_multi_inputs_values.sparse.npz\")\n",
    "multi_test_x = pca_train.transform(multi_test_x)\n",
    "multi_test_x = multi_test_x[:,:feature_num_multi]\n",
    "multi_test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0771efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adata = sc.read_h5ad(\"test_multi_ga.h5ad\")\n",
    "# multi_test_x = adata.X.copy()\n",
    "# multi_test_x = pca_train.transform(multi_test_x)\n",
    "# multi_test_x = multi_test_x[:,:feature_num_multi]\n",
    "# multi_test_x.shape\n",
    "\n",
    "# adata = pd.read_h5(\"./input/multimodal-single-cell-as-sparse-matrix/test_multi_geneactivity.h5\")\n",
    "# multi_test_x = adata.values\n",
    "# multi_test_x = pca_train.transform(multi_test_x)\n",
    "# multi_test_x = multi_test_x[:,:feature_num_multi]\n",
    "# multi_test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "28f6b022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 prediction\n",
      "1748/1748 [==============================] - 2s 1ms/step\n",
      "fold 1 prediction\n",
      "1748/1748 [==============================] - 2s 1ms/step\n",
      "fold 2 prediction\n",
      "1748/1748 [==============================] - 2s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = np.zeros((multi_test_x.shape[0], 23418), dtype='float16')\n",
    "\n",
    "for fold in range(N_SPLIT):\n",
    "    print(f'fold {fold} prediction')\n",
    "    model = tf.keras.models.load_model(f\"model_{fold}\")\n",
    "    preds += (model.predict(multi_test_x)@pca_target.components_)/N_SPLIT\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb0709d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyarrow fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7951135e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_id    cell_id       gene_id        \n",
       "0         c2150f55becb  CD86              NaN\n",
       "1         c2150f55becb  CD274             NaN\n",
       "2         c2150f55becb  CD270             NaN\n",
       "3         c2150f55becb  CD155             NaN\n",
       "4         c2150f55becb  CD112             NaN\n",
       "                                           ..\n",
       "65744175  2c53aa67933d  ENSG00000134419   NaN\n",
       "65744176  2c53aa67933d  ENSG00000186862   NaN\n",
       "65744177  2c53aa67933d  ENSG00000170959   NaN\n",
       "65744178  2c53aa67933d  ENSG00000107874   NaN\n",
       "65744179  2c53aa67933d  ENSG00000166012   NaN\n",
       "Name: target, Length: 65744180, dtype: float32"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_ids = pd.read_parquet(\"./input/multimodal-single-cell-as-sparse-matrix/evaluation.parquet\")\n",
    "eval_ids.cell_id = eval_ids.cell_id.astype(pd.CategoricalDtype())\n",
    "eval_ids.gene_id = eval_ids.gene_id.astype(pd.CategoricalDtype())\n",
    "\n",
    "submission = pd.Series(name='target',\n",
    "                       index=pd.MultiIndex.from_frame(eval_ids), \n",
    "                       dtype=np.float32)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9dcb573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_id    cell_id       gene_id        \n",
       "0         c2150f55becb  CD86                    NaN\n",
       "1         c2150f55becb  CD274                   NaN\n",
       "2         c2150f55becb  CD270                   NaN\n",
       "3         c2150f55becb  CD155                   NaN\n",
       "4         c2150f55becb  CD112                   NaN\n",
       "                                             ...   \n",
       "65744175  2c53aa67933d  ENSG00000134419    2.751953\n",
       "65744176  2c53aa67933d  ENSG00000186862   -0.379150\n",
       "65744177  2c53aa67933d  ENSG00000170959   -0.376465\n",
       "65744178  2c53aa67933d  ENSG00000107874    0.179321\n",
       "65744179  2c53aa67933d  ENSG00000166012    2.480469\n",
       "Name: target, Length: 65744180, dtype: float32"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_columns = np.load(\"./input/multimodal-single-cell-as-sparse-matrix/train_multi_targets_idxcol.npz\",\n",
    "                   allow_pickle=True)[\"columns\"]\n",
    "\n",
    "test_index = np.load(\"./input/multimodal-single-cell-as-sparse-matrix/test_multi_inputs_idxcol.npz\",\n",
    "                    allow_pickle=True)[\"index\"]\n",
    "\n",
    "cell_dict = dict((k,v) for v,k in enumerate(test_index)) \n",
    "assert len(cell_dict)  == len(test_index)\n",
    "\n",
    "gene_dict = dict((k,v) for v,k in enumerate(y_columns))\n",
    "assert len(gene_dict) == len(y_columns)\n",
    "\n",
    "eval_ids_cell_num = eval_ids.cell_id.apply(lambda x:cell_dict.get(x, -1))\n",
    "eval_ids_gene_num = eval_ids.gene_id.apply(lambda x:gene_dict.get(x, -1))\n",
    "valid_multi_rows = (eval_ids_gene_num !=-1) & (eval_ids_cell_num!=-1)\n",
    "\n",
    "submission.iloc[valid_multi_rows] = preds[eval_ids_cell_num[valid_multi_rows].to_numpy(),\n",
    "eval_ids_gene_num[valid_multi_rows].to_numpy()]\n",
    "\n",
    "del eval_ids_cell_num, eval_ids_gene_num, valid_multi_rows, eval_ids, test_index, y_columns\n",
    "gc.collect()\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8d283ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_id\n",
       "0           0.094605\n",
       "1          -0.162362\n",
       "2          -0.405332\n",
       "3          -0.302582\n",
       "4           1.114355\n",
       "              ...   \n",
       "65744175    2.751953\n",
       "65744176   -0.379150\n",
       "65744177   -0.376465\n",
       "65744178    0.179321\n",
       "65744179    2.480469\n",
       "Name: target, Length: 65744180, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.reset_index(drop=True, inplace=True)\n",
    "submission.index.name = 'row_id'\n",
    "\n",
    "# cite_submission = pd.read_csv(\"submission_lolo_1.csv\")\n",
    "cite_submission = pd.read_csv(\"submission.csv\")\n",
    "cite_submission = cite_submission.set_index(\"row_id\")\n",
    "cite_submission = cite_submission[\"target\"]\n",
    "submission[submission.isnull()] = cite_submission[submission.isnull()]\n",
    "submission\n",
    "# == > score 0.812"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a326767b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87231a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission1.to_csv(\"submission_emsemb_pre.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3dab03",
   "metadata": {},
   "source": [
    "# File submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8507454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submssion_sample = pd.read_csv(\"evaluation_ids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf962f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"submission_testourcite.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6021f2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_copy =submission.copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffa1e097",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_list = pd.read_csv(\"citeseq_worest_test_metadata.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5719f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein</th>\n",
       "      <th>index</th>\n",
       "      <th>correlation</th>\n",
       "      <th>index_protein</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CD272</td>\n",
       "      <td>0.540208</td>\n",
       "      <td>0.540208</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KLRG1</td>\n",
       "      <td>0.548423</td>\n",
       "      <td>0.548423</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CD72</td>\n",
       "      <td>0.500206</td>\n",
       "      <td>0.500206</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CD18</td>\n",
       "      <td>0.464988</td>\n",
       "      <td>0.464988</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CD107a</td>\n",
       "      <td>0.413140</td>\n",
       "      <td>0.413140</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Rat-IgG2b</td>\n",
       "      <td>0.331818</td>\n",
       "      <td>0.331818</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>CD11b</td>\n",
       "      <td>0.324618</td>\n",
       "      <td>0.324618</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Mouse-IgG2b</td>\n",
       "      <td>0.321988</td>\n",
       "      <td>0.321988</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>TCRVd2</td>\n",
       "      <td>0.320435</td>\n",
       "      <td>0.320435</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Mouse-IgG2a</td>\n",
       "      <td>0.324325</td>\n",
       "      <td>0.324325</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        protein     index  correlation  index_protein\n",
       "0         CD272  0.540208     0.540208             66\n",
       "1         KLRG1  0.548423     0.548423             52\n",
       "2          CD72  0.500206     0.500206            115\n",
       "3          CD18  0.464988     0.464988            102\n",
       "4        CD107a  0.413140     0.413140             54\n",
       "..          ...       ...          ...            ...\n",
       "95    Rat-IgG2b  0.331818     0.331818             34\n",
       "96        CD11b  0.324618     0.324618             59\n",
       "97  Mouse-IgG2b  0.321988     0.321988             33\n",
       "98       TCRVd2  0.320435     0.320435            123\n",
       "99  Mouse-IgG2a  0.324325     0.324325             32\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c629a05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission[0:6812820]\n",
    "submssion_sample = submssion_sample[0:6812820]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6e3b1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[\"cell_id\"] = submssion_sample[\"cell_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1d90217",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21802b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28c614c314b44d697481819c754ff56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Standardizing:   0%|          | 0/48663 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Standardize submission per cell_id\n",
    "loop_list          = submission.groupby('cell_id', sort=False)\n",
    "vals               = []\n",
    "\n",
    "for idx, g in tqdm(loop_list, desc=f'Standardizing', miniters=1000):\n",
    "    vals.append(g.target.values)\n",
    "\n",
    "to_save_norm = np.concatenate(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84f2b977",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = np.array(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5c6ad75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.46044826e-02, -1.62362460e-01, -4.05331930e-01, ...,\n",
       "        -2.60497381e-01,  3.83257642e-01, -1.97452624e-01],\n",
       "       [-2.51250784e-01, -3.57970479e-01, -1.62688971e-01, ...,\n",
       "        -1.95552378e-01,  4.02629948e-01,  2.14246277e-01],\n",
       "       [-5.04534627e-01, -5.27179086e-01, -6.66114169e-01, ...,\n",
       "        -7.89937925e-01,  9.85862162e-01,  6.09520360e-01],\n",
       "       ...,\n",
       "       [-4.25168289e-01, -7.80186930e-04, -2.21839650e-01, ...,\n",
       "        -3.80482556e-01, -2.60563119e-01,  4.08056145e-01],\n",
       "       [-6.14958595e-01, -5.03246575e-01, -2.44184170e-01, ...,\n",
       "        -5.44253405e-01,  2.02915635e+00,  9.25770420e-01],\n",
       "       [-5.89724067e-01, -4.47030269e-01, -2.50559143e-01, ...,\n",
       "        -5.40320414e-01,  2.24419000e+00,  1.06924650e+00]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56e1cb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_worst_prot = np.load(\"citeseq_generation_wor_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca811313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48663, 100)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_worst_prot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11c925f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_output = vals.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64c65eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09460448, -0.25125078, -0.50453463, ..., -0.42516829,\n",
       "       -0.61495859, -0.58972407])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2949c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09460448, -0.25125078, -0.50453463, ..., -0.42516829,\n",
       "       -0.61495859, -0.58972407])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals_output[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "430ac56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(test_worst_prot.shape[1]):\n",
    "    vals_output[:,cor_list[\"index_protein\"][i]] = test_worst_prot[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3b52768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.094604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.162362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.405332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.302582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.114355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744175</th>\n",
       "      <td>2.777528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744176</th>\n",
       "      <td>-0.369145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744177</th>\n",
       "      <td>-0.367802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744178</th>\n",
       "      <td>0.135783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744179</th>\n",
       "      <td>2.558738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65744180 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            target\n",
       "row_id            \n",
       "0         0.094604\n",
       "1        -0.162362\n",
       "2        -0.405332\n",
       "3        -0.302582\n",
       "4         1.114355\n",
       "...            ...\n",
       "65744175  2.777528\n",
       "65744176 -0.369145\n",
       "65744177 -0.367802\n",
       "65744178  0.135783\n",
       "65744179  2.558738\n",
       "\n",
       "[65744180 rows x 1 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6701a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_copy[\"target\"].iloc[:len(vals_output.ravel())] = vals_output.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "15443575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.677447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.788923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.051202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.302582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.114355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744175</th>\n",
       "      <td>2.777528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744176</th>\n",
       "      <td>-0.369145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744177</th>\n",
       "      <td>-0.367802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744178</th>\n",
       "      <td>0.135783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744179</th>\n",
       "      <td>2.558738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65744180 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            target\n",
       "row_id            \n",
       "0         1.677447\n",
       "1         0.788923\n",
       "2        -0.051202\n",
       "3        -0.302582\n",
       "4         1.114355\n",
       "...            ...\n",
       "65744175  2.777528\n",
       "65744176 -0.369145\n",
       "65744177 -0.367802\n",
       "65744178  0.135783\n",
       "65744179  2.558738\n",
       "\n",
       "[65744180 rows x 1 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ce7fa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_copy.to_csv(\"submission_update_worstprotein.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4196b969",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709b9d28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e49968a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_load = pd.read_csv(\"submission_update_worstprotein.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db070616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6812820, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_load.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ab812a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dcef0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[0:6812820] = submission[0:6812820]\n",
    "submssion_sample[0:6812820] = submssion_sample[0:6812820]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2068143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize submission per cell_id\n",
    "loop_list          = submission.groupby('cell_id', sort=False)\n",
    "vals               = []\n",
    "\n",
    "for idx, g in tqdm(loop_list, desc=f'Standardizing', miniters=1000):\n",
    "    vals.append(std(g.target).values)\n",
    "\n",
    "to_save_norm = np.concatenate(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fa5085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33320671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68ddb1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"./openproblems/submission_correct_multi.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b7630c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_cite = pd.read_csv(\"./openproblems/submission_10combine_wrongmulti.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35e3b565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.094604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.162362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.405332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.302582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.114355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744175</th>\n",
       "      <td>4.406590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744176</th>\n",
       "      <td>-0.603898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744177</th>\n",
       "      <td>-0.595424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744178</th>\n",
       "      <td>0.224828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744179</th>\n",
       "      <td>3.913553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65744180 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            target\n",
       "row_id            \n",
       "0         0.094604\n",
       "1        -0.162362\n",
       "2        -0.405332\n",
       "3        -0.302582\n",
       "4         1.114355\n",
       "...            ...\n",
       "65744175  4.406590\n",
       "65744176 -0.603898\n",
       "65744177 -0.595424\n",
       "65744178  0.224828\n",
       "65744179  3.913553\n",
       "\n",
       "[65744180 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_cite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1fac5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[0:6812820] = submission_cite[0:6812820]\n",
    "submission[0:6812820] = submission_cite[0:6812820]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9e4e48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission_10_combine.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8638bab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2d093e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[\"cell_id\"] = submssion_sample[\"cell_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "997cb272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>cell_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.104065</td>\n",
       "      <td>c2150f55becb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.178599</td>\n",
       "      <td>c2150f55becb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.445865</td>\n",
       "      <td>c2150f55becb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.332840</td>\n",
       "      <td>c2150f55becb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.225791</td>\n",
       "      <td>c2150f55becb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744175</th>\n",
       "      <td>4.847249</td>\n",
       "      <td>2c53aa67933d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744176</th>\n",
       "      <td>-0.664288</td>\n",
       "      <td>2c53aa67933d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744177</th>\n",
       "      <td>-0.654967</td>\n",
       "      <td>2c53aa67933d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744178</th>\n",
       "      <td>0.247310</td>\n",
       "      <td>2c53aa67933d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744179</th>\n",
       "      <td>4.304908</td>\n",
       "      <td>2c53aa67933d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65744180 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            target       cell_id\n",
       "row_id                          \n",
       "0         0.104065  c2150f55becb\n",
       "1        -0.178599  c2150f55becb\n",
       "2        -0.445865  c2150f55becb\n",
       "3        -0.332840  c2150f55becb\n",
       "4         1.225791  c2150f55becb\n",
       "...            ...           ...\n",
       "65744175  4.847249  2c53aa67933d\n",
       "65744176 -0.664288  2c53aa67933d\n",
       "65744177 -0.654967  2c53aa67933d\n",
       "65744178  0.247310  2c53aa67933d\n",
       "65744179  4.304908  2c53aa67933d\n",
       "\n",
       "[65744180 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc90498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a5a4a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1050ce1339e9485e89f76b869846335d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Standardizing:   0%|          | 0/65443 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Standardize submission per cell_id\n",
    "loop_list          = submission.groupby('cell_id', sort=False)\n",
    "vals               = []\n",
    "\n",
    "for idx, g in tqdm(loop_list, desc=f'Standardizing', miniters=1000):\n",
    "    vals.append(std(g.target).values)\n",
    "\n",
    "to_save_norm = np.concatenate(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1169f0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09460448, -0.16236246, -0.40533193, ..., -0.59542426,\n",
       "        0.2248275 ,  3.91355303])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_save_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a6e34c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce6b675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8496e77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = to_save_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12060a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del submission['cell_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75c5ee41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.094604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.162362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.405332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.302582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.114355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744175</th>\n",
       "      <td>4.406590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744176</th>\n",
       "      <td>-0.603898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744177</th>\n",
       "      <td>-0.595424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744178</th>\n",
       "      <td>0.224828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744179</th>\n",
       "      <td>3.913553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65744180 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            target\n",
       "row_id            \n",
       "0         0.094604\n",
       "1        -0.162362\n",
       "2        -0.405332\n",
       "3        -0.302582\n",
       "4         1.114355\n",
       "...            ...\n",
       "65744175  4.406590\n",
       "65744176 -0.603898\n",
       "65744177 -0.595424\n",
       "65744178  0.224828\n",
       "65744179  3.913553\n",
       "\n",
       "[65744180 rows x 1 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4f04c790",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission_10_pca_combine.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "00966131",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.094604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.162362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.405332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.302582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.114355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744175</th>\n",
       "      <td>4.406590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744176</th>\n",
       "      <td>-0.603898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744177</th>\n",
       "      <td>-0.595424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744178</th>\n",
       "      <td>0.224828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65744179</th>\n",
       "      <td>3.913553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65744180 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            target\n",
       "row_id            \n",
       "0         0.094604\n",
       "1        -0.162362\n",
       "2        -0.405332\n",
       "3        -0.302582\n",
       "4         1.114355\n",
       "...            ...\n",
       "65744175  4.406590\n",
       "65744176 -0.603898\n",
       "65744177 -0.595424\n",
       "65744178  0.224828\n",
       "65744179  3.913553\n",
       "\n",
       "[65744180 rows x 1 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8233c251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
